# EugenioB <eugeniob@racine.ra.it>, 2012.
# Beatrice Torracca <beatricet@libero.it>, 2014.
# Marco De Luca <marcodeluca@hotmail.it>, 2015.
msgid ""
msgstr "Project-Id-Version: 0\nPOT-Creation-Date: 2022-07-30 18:23+0200\nPO-Revision-Date: 2022-12-08 22:46+0000\nLast-Translator: Pierfrancesco Passerini <p.passerini@gmail.com>\nLanguage-Team: Italian <https://hosted.weblate.org/projects/debian-handbook/12_advanced-administration/it/>\nLanguage: it-IT\nMIME-Version: 1.0\nContent-Type: text/plain; charset=UTF-8\nContent-Transfer-Encoding: 8bit\nPlural-Forms: nplurals=2; plural=n != 1;\nX-Generator: Weblate 4.15-dev\n"

msgid "RAID"
msgstr "RAID"

msgid "LVM"
msgstr "LVM"

msgid "FAI"
msgstr "FAI"

msgid "Preseeding"
msgstr "Preimpostazione"

msgid "Monitoring"
msgstr "Monitoraggio"

msgid "Virtualization"
msgstr "Virtualizzazione"

msgid "Xen"
msgstr "Xen"

msgid "LXC"
msgstr "LXC"

msgid "Advanced Administration"
msgstr "Amministrazione avanzata"

msgid "This chapter revisits some aspects we already described, with a different perspective: instead of installing one single computer, we will study mass-deployment systems; instead of creating RAID or LVM volumes at install time, we'll learn to do it by hand so we can later revise our initial choices. Finally, we will discuss monitoring tools and virtualization techniques. As a consequence, this chapter is more particularly targeting professional administrators, and focuses somewhat less on individuals responsible for their home network."
msgstr "Questo capitolo rivede alcuni aspetti già descritti in precedenza, ma da una diversa prospettiva: invece di installare una singola macchina, si studiano sistemi di allestimento più vasti; invece di creare volumi RAID o LVM durante l'installazione, si descrive la procedura per farlo a mano in modo da poter rivedere in seguito le scelte iniziali. Infine, si discutono strumenti di monitoraggio e tecniche di virtualizzazione. Di conseguenza, questo capitolo è più orientato agli amministratori professionisti e meno ai singoli individui responsabili della rete di casa propria."

msgid "RAID and LVM"
msgstr "RAID e LVM"

msgid "<primary>RAID</primary>"
msgstr "<primary>RAID</primary>"

msgid "<primary>LVM</primary>"
msgstr "<primary>LVM</primary>"

msgid "<primary>Logical Volume Manager</primary><see>LVM</see>"
msgstr "<primary>Gestore Volume Logico</primary><see>LVM</see>"

msgid "<primary>volume</primary><secondary>logical volume</secondary>"
msgstr "<primary>volume</primary><secondary>volume logico</secondary>"

msgid "<primary>volume</primary><secondary>raid volume</secondary>"
msgstr "<primary>volume</primary><secondary>volume raid</secondary>"

msgid "<primary>filesystem</primary><secondary>redundancy</secondary>"
msgstr "<primary>filesystem</primary><secondary>ridondanza</secondary>"

msgid "<xref linkend=\"installation\" /> presented these technologies from the point of view of the installer, and how it integrated them to make their deployment easy from the start. After the initial installation, an administrator must be able to handle evolving storage space needs without having to resort to an expensive re-installation. They must therefore understand the required tools for manipulating RAID and LVM volumes."
msgstr "<xref linkend=\"installation\" /> ha presentato queste tecnologie dal punto di vista dell'installatore e di come questi li integrava per rendere il loro allestimento facile fin dall'inizio. Dopo l'installazione iniziale, un amministratore deve poter far fronte alle mutevoli necessità di spazio disco senza dover ricorrere a una re-installazione costosa. Deve pertanto padroneggiare gli strumenti richiesti per manipolare volumi RAID e LVM."

msgid "<primary>volume</primary><secondary>management</secondary>"
msgstr "<primary>volume</primary><secondary>gestione</secondary>"

msgid "RAID and LVM are both techniques to abstract the mounted volumes from their physical counterparts (actual hard-disk drives or partitions thereof); the former ensures the security and availability of the data in case of hardware failure by introducing redundancy, the latter makes volume management more flexible and independent of the actual size of the underlying disks. In both cases, the system ends up with new block devices, which can be used to create filesystems or swap space, without necessarily having them mapped to one physical disk. RAID and LVM come from quite different backgrounds, but their functionality can overlap somewhat, which is why they are often mentioned together."
msgstr "RAID e LVM sono entrambe tecniche per astrarre i volumi montati dalle loro controparti fisiche (gli effettivi dischi fissi o le loro partizioni); il primo garantisce la sicurezza e la disponibilità dei dati in caso di guasto hardware introducendo la ridondanza, l'ultimo rende la gestione dei dati più flessibile e indipendente dall'effettiva dimensione dei dischi sottostanti. In entrambi i casi, il sistema acquisisce nuovi dispositivi a blocchi, che possono essere usati per creare filesystem o spazio di swap, senza necessariamente essere mappati su un unico disco fisico. RAID e LVM provengono da ambienti molto diversi, ma le loro funzionalità spesso si possono sovrapporre, che è il motivo per cui spesso vengono menzionati insieme."

msgid "<emphasis>PERSPECTIVE</emphasis> Btrfs combines LVM and RAID"
msgstr "<emphasis>PROSPETTIVA</emphasis> Btrfs combina LVM and RAID"

msgid "<primary><command>mount</command></primary><secondary>Btrfs</secondary>"
msgstr "<primary><command>mount</command></primary><secondary>Btrfs</secondary>"

msgid "<primary>Btrfs</primary>"
msgstr "<primary>Btrfs</primary>"

msgid "While LVM and RAID are two distinct kernel subsystems that come between the disk block devices and their filesystems, <emphasis>btrfs</emphasis> is a filesystem, initially developed at Oracle, that purports to combine the feature sets of LVM and RAID and much more. <ulink type=\"block\" url=\"https://btrfs.wiki.kernel.org/\" />"
msgstr "Mentre LVM e RAID sono due sottosistemi distinti del kernel che si interpongono fra i dispositivi disco a blocchi e i loro file system, <emphasis>btrfs</emphasis> è un filesystem, sviluppato inizialmente da Oracle, che si propone di combinare le funzionalità di LVM e RAID e molto altro. <ulink type=\"block\" url=\"https://btrfs.wiki.kernel.org/\" />"

msgid "Among the noteworthy features are the ability to take a snapshot of a filesystem tree at any point in time. This snapshot copy doesn't initially use any disk space, the data only being duplicated when one of the copies is modified. The filesystem also handles transparent compression of files, and checksums ensure the integrity of all stored data."
msgstr "Fra le funzionalità degne di nota vi sono la capacità di fare un'istantanea di un file system in ogni momento. Questa copia istantanea all'inizio non occupa spazio su disco, in quanto i dati vengono duplicati solo quando una delle copie viene modificata. Il file system inoltre gestisce la compressione trasparente dei file e dei codici di controllo assicurano l'integrità di tutti i dati memorizzati."

msgid "<primary>filesystem</primary><secondary>snapshot</secondary>"
msgstr "<primary>filesystem</primary><secondary>instantanea</secondary>"

msgid "In both the RAID and LVM cases, the kernel provides a block device file, similar to the ones corresponding to a hard disk drive or a partition. When an application, or another part of the kernel, requires access to a block of such a device, the appropriate subsystem routes the block to the relevant physical layer. Depending on the configuration, this block can be stored on one or several physical disks, and its physical location may not be directly correlated to the location of the block in the logical device."
msgstr "Sia nel RAID che nell'LVM, il kernel fornisce un file di device a blocchi, simile a quelli corrispondenti a un disco fisso o a una partizione. Quando un'applicazione o un'altra parte del kernel richiede l'accesso a un blocco di questo device, il sottosistema appropriato dirige il blocco allo strato fisico di competenza. A seconda della configurazione, questo blocco può essere memorizzato su uno o più dischi fisici e la sua posizione fisica potrebbe non essere direttamente correlata alla posizione del blocco nel device logico."

msgid "Software RAID"
msgstr "RAID software"

msgid "<primary>RAID</primary><secondary>Software RAID</secondary>"
msgstr "<primary>RAID</primary><secondary>RAID software</secondary>"

msgid "<primary>Redundant Array of Independent Disks</primary><see>RAID</see>"
msgstr "<primary>Redundant Array of Independent Disks (insieme ridondante di dischi indipendenti)</primary><see>RAID</see>"

msgid "RAID means <emphasis>Redundant Array of Independent Disks</emphasis>. The goal of this system is to prevent data loss and ensure availability in case of hard disk failure. The general principle is quite simple: data are stored on several physical disks instead of only one, with a configurable level of redundancy. Depending on this amount of redundancy, and even in the event of an unexpected disk failure, data can be losslessly reconstructed from the remaining disks."
msgstr "RAID significa <emphasis>Redundant Array of Independent Disks</emphasis> (array ridondante di dischi indipendenti). Lo scopo di questo sistema è di impedire la perdita di dati e garantire la disponibilità in caso di guasto di un disco fisso. Il principio generale è molto semplice: i dati sono memorizzati su diversi dischi fisici piuttosto che su uno solo, con un livello di ridondanza configurabile. A seconda della quantità di ridondanza e anche in caso di guasto inatteso di un disco, i dati possono essere ricostruiti dai dischi rimanenti, senza alcuna perdita."

msgid "<emphasis>CULTURE</emphasis> <foreignphrase>Independent</foreignphrase> or <foreignphrase>inexpensive</foreignphrase>?"
msgstr "<emphasis>CULTURA</emphasis> <foreignphrase>Indipendente</foreignphrase> o <foreignphrase>a poco prezzo</foreignphrase>?"

msgid "The I in RAID initially stood for <emphasis>inexpensive</emphasis>, because RAID allowed a drastic increase in data safety without requiring investing in expensive high-end disks. Probably due to image concerns, however, it is now more customarily considered to stand for <emphasis>independent</emphasis>, which doesn't have the unsavory flavor of cheapness."
msgstr "La I in RAID all'inizio stava per <emphasis>inexpensive</emphasis> (a poco prezzo), perché il RAID permetteva un drastico aumento della sicurezza dei dati senza richiedere investimenti in costosi dischi di fascia alta. Tuttavia, probabilmente per questioni di immagine, oggi è più consueto riferirsi ad essa come <emphasis>independent</emphasis> (indipendente), che non ha quel sapore insipido di economicità."

msgid "<primary>RAID</primary><secondary>Hardware RAID</secondary>"
msgstr "<primary>RAID</primary><secondary>RAID hardware</secondary>"

msgid "<primary>RAID</primary><secondary>degraded</secondary>"
msgstr "<primary>RAID</primary><secondary>degradato</secondary>"

msgid "<primary>RAID</primary><secondary>reconstruction</secondary>"
msgstr "<primary>RAID</primary><secondary>ricostruzione</secondary>"

msgid "RAID can be implemented either by dedicated hardware (RAID modules integrated into SCSI or SATA controller cards) or by software abstraction (the kernel). Whether hardware or software, a RAID system with enough redundancy can transparently stay operational when a disk fails; the upper layers of the stack (applications) can even keep accessing the data in spite of the failure. Of course, this “degraded mode” can have an impact on performance, and redundancy is reduced, so a further disk failure can lead to data loss. In practice, therefore, one will strive to only stay in this degraded mode for as long as it takes to replace the failed disk. Once the new disk is in place, the RAID system can reconstruct the required data so as to return to a safe mode. The applications won't notice anything, apart from potentially reduced access speed, while the array is in degraded mode or during the reconstruction phase."
msgstr "Il RAID può essere implementato sia tramite hardware dedicato (moduli RAID integrati in schede con controllori SCSI o SATA) sia tramite astrazione software (il kernel). Che sia hardware o software, un sistema RAID con sufficiente ridondanza può rimanere operativo in modo trasparente quando un disco si guasta; gli strati superiori della pila (applicazioni) possono perfino continuare ad accedere ai dati nonostante il guasto. Ovviamente questa «modalità degradata» può avere un impatto sulle prestazioni e inoltre viene ridotta la ridondanza, quindi un ulteriore guasto di un disco può provocare perdita di dati. In pratica, perciò, si cerca di rimanere in questa modalità degradata solo per il tempo necessario a sostituire il disco guasto. Una volta che il nuovo disco è al suo posto, il sistema RAID può ricostruire i dati richiesti e così tornare in modalità sicura. Le applicazioni non si accorgeranno di alcunché, a parte per la velocità di accesso potenzialmente ridotta, mentre l'array è in modalità degradata o durante la fase di ricostruzione."

msgid "When RAID is implemented by hardware, its configuration generally happens within the BIOS setup tool, and the kernel will consider a RAID array as a single disk, which will work as a standard physical disk, although the device name may be different (depending on the driver)."
msgstr "Quando il RAID è implementato via hardware, la sua configurazione avviene generalmente all'interno dello strumento di configurazione del BIOS, ed il kernel considererà l'array RAID come un disco singolo, che funzionerà come un tradizionale disco singolo, anche il nome del dispositivo potrebbe essere differente (a seconda del driver)."

msgid "We only focus on software RAID in this book."
msgstr "In questo libro ci focalizzeremo sul RAID software."

msgid "Different RAID Levels"
msgstr "Diversi livelli di RAID"

msgid "<primary>RAID</primary><secondary>level</secondary>"
msgstr "<primary>RAID</primary><secondary>livello</secondary>"

msgid "RAID is actually not a single system, but a range of systems identified by their levels; the levels differ by their layout and the amount of redundancy they provide. The more redundant, the more failure-proof, since the system will be able to keep working with more failed disks. The counterpart is that the usable space shrinks for a given set of disks; seen the other way, more disks will be needed to store a given amount of data."
msgstr "Il RAID non è effettivamente un singolo sistema, ma una serie di sistemi identificati dai rispettivi livelli; che si distinguono per la loro disposizione e la quantità di ridondanza che forniscono. Più è ridondante, più è a prova di guasti, dal momento che il sistema sarà in grado di continuare a funzionare con più dischi rotti. Il rovescio della medaglia è che lo spazio utilizzabile diminuisce per un dato insieme di dischi; visto in un altro modo, servono più dischi per memorizzare la stessa quantità di dati."

msgid "Linear RAID"
msgstr "RAID lineare"

msgid "Even though the kernel's RAID subsystem allows creating “linear RAID”, this is not proper RAID, since this setup doesn't involve any redundancy. The kernel merely aggregates several disks end-to-end and provides the resulting aggregated volume as one virtual disk (one block device). That is about its only function. This setup is rarely used by itself (see later for the exceptions), especially since the lack of redundancy means that one disk failing makes the whole aggregate, and therefore all the data, unavailable."
msgstr "Anche se il sottosistema del kernel permette di creare un «RAID lineare», questo non è un RAID vero e proprio, poiché questa configurazione non prevede alcuna ridondanza. Il kernel semplicemente aggrega diversi dischi in fila e mette a disposizione il volume aggregato che ne risulta come un unico disco virtuale (un unico device a blocchi). Questa è praticamente la sua unica funzione. Questa configurazione è raramente usata da sola (vedere più avanti per le eccezioni), soprattutto in quanto la mancanza di ridondanza implica che basta un guasto a un singolo disco per rendere l'intero aggregato, e dunque tutti i dati, indisponibile."

msgid "<primary>RAID</primary><secondary>linear</secondary>"
msgstr "<primary>RAID</primary><secondary>lineare</secondary>"

msgid "RAID-0"
msgstr "RAID-0"

msgid "This level doesn't provide any redundancy either, but disks aren't simply stuck on end one after another: they are divided in <emphasis>stripes</emphasis>, and the blocks on the virtual device are stored on stripes on alternating physical disks. In a two-disk RAID-0 setup, for instance, even-numbered blocks of the virtual device will be stored on the first physical disk, while odd-numbered blocks will end up on the second physical disk."
msgstr "Anche questo livello non fornisce alcuna ridondanza, ma i dischi non sono semplicemente messi in fila uno dietro l'altro: sono divisi in <emphasis>strisce</emphasis> e i blocchi sul device virtuale sono memorizzati su strisce su dischi fisici alternati. In un'impostazione RAID-0 a due dischi, per esempio, i blocchi di numero pari del device virtuale saranno memorizzati sul primo disco fisico, mentre i blocchi di numero dispari finiranno sul secondo disco fisico."

msgid "<primary>RAID</primary><secondary>stripes</secondary>"
msgstr "<primary>RAID</primary><secondary>stripe</secondary>"

msgid "This system doesn't aim at increasing reliability, since (as in the linear case) the availability of all the data is jeopardized as soon as one disk fails, but at increasing performance: during sequential access to large amounts of contiguous data, the kernel will be able to read from both disks (or write to them) in parallel, which increases the data transfer rate. The disks are utilized entirely by the RAID device, so they should have the same size not to lose performance."
msgstr "Questo sistema non mira ad aumentare l'affidabilità, in quanto (come nel caso del lineare) la disponibilità di tutti i dati è a rischio non appena un disco si guasta, ma ad aumentare le prestazioni: durante l'accesso sequenziale a grandi quantità di dati contigui, il kernel potrà leggere da entrambi i dischi (o scrivere su di essi) in parallelo, il che aumenta la velocità di trasferimento dei dati. I dischi vengono utilizzati interamente dal dispositivo RAID, quindi dovrebbero avere le stesse dimensioni per non avere perdita di prestazioni."

msgid "RAID-0 use is shrinking, its niche being filled by LVM (see later)."
msgstr "L'uso del RAID-0 sta diminuendo a favore di LVM (vedere più avanti)."

msgid "<primary>RAID</primary><secondary>0</secondary>"
msgstr "<primary>RAID</primary><secondary>0</secondary>"

msgid "RAID-1"
msgstr "RAID-1"

msgid "This level, also known as “RAID mirroring”, is both the simplest and the most widely used setup. In its standard form, it uses two physical disks of the same size, and provides a logical volume of the same size again. Data are stored identically on both disks, hence the “mirror” nickname. When one disk fails, the data is still available on the other. For really critical data, RAID-1 can of course be set up on more than two disks, with a direct impact on the ratio of hardware cost versus available payload space."
msgstr "Questo livello, noto anche come «RAID mirroring», è la configurazione più semplice e più usata. Nella sua forma standard, usa due dischi fisici della stessa grandezza e fornisce un volume logico anch'esso della stessa grandezza. I dati sono memorizzati in modo identico su entrambi i dischi, da cui il soprannome «mirror». Quando un disco si guasta, i dati sono ancora disponibili sull'altro. Per dati veramente critici, il RAID-1 può ovviamente essere impostato su più di due dischi, il che ha delle conseguenze sul rapporto fra costo dell'hardware e spazio disponibile."

msgid "<primary>RAID</primary><secondary>1</secondary>"
msgstr "<primary>RAID</primary><secondary>1</secondary>"

msgid "<primary>RAID</primary><secondary>mirror</secondary>"
msgstr "<primary>RAID</primary><secondary>mirror</secondary>"

msgid "<emphasis>NOTE</emphasis> Disks and cluster sizes"
msgstr "<emphasis>NOTA</emphasis> Dischi e grandezze dei cluster"

msgid "If two disks of different sizes are set up in a mirror, the bigger one will not be fully used, since it will contain the same data as the smallest one and nothing more. The useful available space provided by a RAID-1 volume therefore matches the size of the smallest disk in the array. This still holds for RAID volumes with a higher RAID level, even though redundancy is stored differently."
msgstr "Se due dischi di dimensioni diverse vengono usati in mirror, il più grande non sarà usato completamente, in quanto conterrà gli stessi dati del più piccolo e nulla più. Lo spazio utile disponibile fornito da un volume RAID-1 perciò coincide con la dimensione del disco più piccolo nell'array. Ciò vale anche per volumi RAID con un diverso livello di RAID, anche se la ridondanza viene memorizzata diversamente."

msgid "It is therefore important, when setting up RAID arrays (except for RAID-0 and “linear RAID”), to only assemble disks of identical, or very close, sizes, to avoid wasting resources."
msgstr "È quindi importante, quando si configurano gli array RAID (eccetto il RAID-0 e il «RAID lineare»), assemblare solo dischi di dimensioni identiche, o molto vicine fra loro, per evitare di sprecare risorse."

msgid "<emphasis>NOTE</emphasis> Spare disks"
msgstr "<emphasis>NOTA</emphasis> Dischi di riserva"

msgid "<primary>spare disk</primary>"
msgstr "<primary>disco di riserva</primary>"

msgid "RAID levels that include redundancy allow assigning more disks than required to an array. The extra disks are used as spares when one of the main disks fails. For instance, in a mirror of two disks plus one spare, if one of the first two disks fails, the kernel will automatically (and immediately) reconstruct the mirror using the spare disk, so that redundancy stays assured after the reconstruction time. This can be used as another kind of safeguard for critical data."
msgstr "I livelli RAID che includono la ridondanza permettono di assegnare più dischi del necessario a un array. I dischi in più sono usati come riserva quando uno dei dischi principali si guasta. Per esempio, in un mirror di due dischi più una riserva, se uno dei primi due dischi si guasta, il kernel ricostruirà automaticamente (e immediatamente) il mirror usando il disco di riserva, cosicché la ridondanza resta assicurata dopo il tempo necessario alla ricostruzione. Ciò può essere usato come un'altra forma di salvaguardia per dati critici."

msgid "One would be forgiven for wondering how this is better than simply mirroring on three disks to start with. The advantage of the “spare disk” configuration is that the spare disk can be shared across several RAID volumes. For instance, one can have three mirrored volumes, with redundancy assured even in the event of one disk failure, with only seven disks (three pairs, plus one shared spare), instead of the nine disks that would be required by three triplets."
msgstr "Ci si può legittimamente chiedere perché questo sarebbe meglio di un semplice mirror su tre dischi. Il vantaggio della configurazione col disco di riserva è che il disco di riserva può essere condiviso fra più volumi RAID. Ad esempio, si possono avere tre volumi in mirror, con ridondanza assicurata anche in caso di guasto di un disco, con soli sette dischi (tre coppie più una riserva condivisa) invece dei nove dischi che servirebbero per formare tre terne."

msgid "This RAID level, although expensive (since only half of the physical storage space, at best, is useful), is widely used in practice. It is simple to understand, and it allows very simple backups: since both disks have identical contents, one of them can be temporarily extracted with no impact on the working system. Read performance is often increased since the kernel can read half of the data on each disk in parallel, while write performance isn't too severely degraded. In case of a RAID-1 array of N disks, the data stays available even with N-1 disk failures."
msgstr "Questo livello di RAID, sebbene costoso (dal momento che al massimo è disponibile metà dello spazio fisico dei dischi), è ampiamente usato in pratica. È semplice da capire e permette di fare dei backup in modo molto semplice: dal momento che entrambi i dischi hanno gli stessi contenuti, uno di essi può essere temporaneamente estratto senza conseguenze sul sistema in funzione. Inoltre, spesso le prestazioni in lettura aumentano in quanto il kernel può leggere metà dati da ciascun disco in parallelo, mentre le prestazioni in scrittura non ne risentono troppo. Nel caso di un array RAID-1 di N dischi, i dati restano disponibili anche in caso si guastino N-1 dischi."

msgid "<emphasis>CAUTION</emphasis> RAID is not Backup"
msgstr "<emphasis>ATTENZIONE</emphasis> Il RAID non è un backup"

msgid "<primary>backup</primary>"
msgstr "<primary>backup</primary>"

msgid "RAID systems are not backup mechanisms. While RAID increases the redundancy - and therefore the availability of a system - and protects against disk failures, backups are done to protect data from being altered, deleted, getting corrupted, etc., and to be able to restore them if necessary. To demonstrate this: If you remove one or all files by accident, a RAID will mirror this change, but it will not provide the means to restore the file(s). So while there is clearly an overlap, they are not the same and should be used in conjunction with each other."
msgstr "I sistemi RAID non sono meccanismi di backup. Benché i RAID aumentano la ridondanza - e quindi la disponibilità di un sistema - e proteggono contro i guasti dei dischi, i backup sono fatti per proteggere i dati dall'essere alterati, cancellati, corrotti, ecc. e per essere in grado di ripristinarli se necessario. Come dimostrazione di questo fatto: se si rimuovono accidentalmente uno o tutti i file, un RAID farà il mirror di questa modifica, ma non fornirà nessun mezzo per ripristinare il(i) file. Quindi, anche se c'è chiaramente una sovrapposizione, non sono la stessa cosa e dovrebbero essere utilizzati insieme."

msgid "RAID-4"
msgstr "RAID-4"

msgid "This RAID level, not widely used, uses N disks to store useful data, and an extra disk to store redundancy information. If that disk fails, the system can reconstruct its contents from the other N. If one of the N data disks fails, the remaining N-1 combined with the “parity” disk contain enough information to reconstruct the required data."
msgstr "Questo livello di RAID, non molto usato, usa N dischi per memorizzare dati utili e un disco in più per memorizzare le informazioni di ridondanza. Se quel disco si guasta, il sistema può ricostruire i suoi contenuti a partire dagli altri N. Se uno degli N dischi con i dati si guasta, i rimanenti N-1 insieme al disco di «parità» contengono abbastanza informazioni per ricostruire i dati richiesti."

msgid "<primary>RAID</primary><secondary>4</secondary>"
msgstr "<primary>RAID</primary><secondary>4</secondary>"

msgid "<primary>RAID</primary><secondary>parity</secondary>"
msgstr "<primary>RAID</primary><secondary>parità</secondary>"

msgid "RAID-4 isn't too expensive since it only involves a one-in-N increase in costs and has no noticeable impact on read performance, but writes are slowed down. Furthermore, since a write to any of the N disks also involves a write to the parity disk, the latter sees many more writes than the former, and its lifespan can shorten dramatically as a consequence. Data on a RAID-4 array is safe only up to one failed disk (of the N+1)."
msgstr "Il RAID-4 non è eccessivamente costoso, dal momento che richiede un aumento dei costi di appena uno-su-N e non ha un impatto notevole sulle prestazioni in lettura, ma le scritture ne risultano rallentate. Inoltre, dal momento che la scrittura su uno qualunque degli N dischi richiede anche una scrittura sul disco di parità, quest'ultimo riceve molte più scritture del primo e di conseguenza la sua vita può ridursi notevolmente. I dati su un array RAID-4 sono sicuri solo fino alla rottura di un solo disco (degli N+1)."

msgid "RAID-5"
msgstr "RAID-5"

msgid "RAID-5 addresses the asymmetry issue of RAID-4: parity blocks are spread over all of the N+1 disks, with no single disk having a particular role."
msgstr "Il RAID-5 risolve il problema di asimmetria del RAID-4: i blocchi di parità sono distribuiti su tutti gli N+1 dischi, senza che un unico disco abbia un ruolo particolare."

msgid "<primary>RAID</primary><secondary>5</secondary>"
msgstr "<primary>RAID</primary><secondary>5</secondary>"

msgid "Read and write performance are identical to RAID-4. Here again, the system stays functional with up to one failed disk (of the N+1), but no more."
msgstr "Le prestazioni in lettura e scrittura sono identiche al RAID-4. Anche qui il sistema rimane in funzione fino al guasto di un unico disco (degli N+1)."

msgid "RAID-6"
msgstr "RAID-6"

msgid "RAID-6 can be considered an extension of RAID-5, where each series of N blocks involves two redundancy blocks, and each such series of N+2 blocks is spread over N+2 disks."
msgstr "Il RAID-6 si può considerare un'estensione del RAID-5, in cui ciascuna serie di N blocchi richiede due blocchi di ridondanza e ciascuna di queste serie di N+2 blocchi viene distribuita su N+2 dischi."

msgid "<primary>RAID</primary><secondary>6</secondary>"
msgstr "<primary>RAID</primary><secondary>6</secondary>"

msgid "This RAID level is slightly more expensive than the previous two, but it brings some extra safety since up to two drives (of the N+2) can fail without compromising data availability. The counterpart is that write operations now involve writing one data block and two redundancy blocks, which makes them even slower."
msgstr "Questo livello di RAID è leggermente più costoso dei due precedenti, ma fornisce un po' di sicurezza in più, dal momento che possono guastarsi fino a due dischi (degli N+2) senza compromettere la disponibilità dei dati. Il difetto è che le operazioni di scrittura ora richiedono la scrittura di un blocco di dati e due blocchi di ridondanza, il che le rende ancora più lente."

msgid "RAID-1+0"
msgstr "RAID-1+0"

msgid "This isn't strictly speaking, a RAID level, but a stacking of two RAID groupings. Starting from 2×N disks, one first sets them up by pairs into N RAID-1 volumes; these N volumes are then aggregated into one, either by “linear RAID” or (increasingly) by LVM. This last case goes farther than pure RAID, but there is no problem with that."
msgstr "Tecnicamente parlando, questo non è un livello di RAID, ma un modo di impilare due gruppi di RAID. Partendo da 2×N dischi, prima si impostano a coppie in N volumi RAID-1; poi, questi N volumi, vengono aggregati in uno solo, tramite \"RAID lineare\" o (sempre più spesso) tramite LVM. In quest'ultimo caso si va oltre il semplice RAID, ma questo non è un problema."

msgid "<primary>RAID</primary><secondary>1+0</secondary>"
msgstr "<primary>RAID</primary><secondary>1+0</secondary>"

msgid "RAID-1+0 can survive multiple disk failures: up to N in the 2×N array described above, provided that at least one disk keeps working in each of the RAID-1 pairs."
msgstr "Il RAID-1+0 può sopravvivere al guasto di più dischi: fino a N nell'array 2×n descritto sopra, a condizione che almeno un disco continui a funzionare in ciascuna coppia RAID-1."

msgid "<emphasis>GOING FURTHER</emphasis> RAID-10"
msgstr "<emphasis>APPROFONDIMENTO</emphasis> RAID-10"

msgid "<primary>RAID</primary><secondary>10</secondary>"
msgstr "<primary>RAID</primary><secondary>10</secondary>"

msgid "RAID-10 is generally considered a synonym of RAID-1+0, but a Linux specificity makes it actually a generalization. This setup allows a system where each block is stored on two different disks, even with an odd number of disks, the copies being spread out along a configurable model."
msgstr "Il RAID-10 viene generalmente considerato un sinonimo di RAID-1+0, ma una particolarità di Linux lo rende in realtà una generalizzazione. Questa configurazione permette di avere un sistema in cui ogni blocco è memorizzato su due dischi diversi, anche con un numero dispari di dischi; le copie vengono poi distribuite secondo un modello configurabile."

msgid "Performances will vary depending on the chosen repartition model and redundancy level, and of the workload of the logical volume."
msgstr "Le prestazioni varieranno a seconda del modello di ripartizione e dal livello di ridondanza scelti e dal carico di lavoro del volume logico."

msgid "Obviously, the RAID level will be chosen according to the constraints and requirements of each application. Note that a single computer can have several distinct RAID arrays with different configurations."
msgstr "Ovviamente, il livello di RAID verrà scelto a seconda dei vincoli e dei requisiti di ciascuna applicazione. Notare che un solo computer può avere diversi array RAID distinti con diverse configurazioni."

msgid "Setting up RAID"
msgstr "Impostazione di un RAID"

msgid "<primary><emphasis role=\"pkg\">mdadm</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">mdadm</emphasis></primary>"

msgid "<primary>RAID</primary><secondary>create</secondary>"
msgstr "<primary>RAID</primary><secondary>creazione</secondary>"

msgid "Setting up RAID volumes requires the <emphasis role=\"pkg\">mdadm</emphasis> package; it provides the <command>mdadm</command> command, which allows creating and manipulating RAID arrays, as well as scripts and tools integrating it to the rest of the system, including the monitoring system."
msgstr "L'impostazione di volumi RAID richiede il pacchetto <emphasis role=\"pkg\">mdadm</emphasis>; esso fornisce il comando <command>mdadm</command>, che permette di creare e manipolare array RAID, oltre che script e strumenti per integrarlo al resto del sistema, compreso il sistema di monitoraggio."

msgid "Our example will be a server with a number of disks, some of which are already used, the rest being available to setup RAID. We initially have the following disks and partitions:"
msgstr "Questo esempio mostrerà un server con un certo numero di dischi, alcuni dei quali sono già usati e i rimanenti sono disponibili per impostare il RAID. All'inizio si hanno i seguenti dischi e partizioni:"

msgid "the <filename>sdb</filename> disk, 4 GB, is entirely available;"
msgstr "il disco <filename>sdb</filename>, 4 GB, è interamente disponibile;"

msgid "the <filename>sdc</filename> disk, 4 GB, is also entirely available;"
msgstr "il disco <filename>sdc</filename>, 4 GB, è anch'esso interamente disponibile;"

msgid "on the <filename>sdd</filename> disk, only partition <filename>sdd2</filename> (about 4 GB) is available;"
msgstr "sul disco <filename>sdd</filename>, solo la partizione <filename>sdd2</filename> (circa 4 GB) è disponibile;"

msgid "finally, a <filename>sde</filename> disk, still 4 GB, entirely available."
msgstr "infine, un disco <filename>sde</filename>, di nuovo di 4 GB, interamente disponibile."

msgid "<emphasis>NOTE</emphasis> Identifying existing RAID volumes"
msgstr "<emphasis>NOTA</emphasis>: identificazione dei volumi RAID esistenti"

msgid "<primary><filename>/proc</filename></primary><secondary><filename>/proc/mdstat</filename></secondary>"
msgstr "<primary><filename>/proc</filename></primary><secondary><filename>/proc/mdstat</filename></secondary>"

msgid "The <filename>/proc/mdstat</filename> file lists existing volumes and their states. When creating a new RAID volume, care should be taken not to name it the same as an existing volume."
msgstr "Il file <filename>/proc/mdstat</filename> elenca i volumi già esistenti e i loro stati. Quando si crea un nuovo volume RAID, bisogna fare attenzione a non dargli lo stesso nome di un volume esistente."

msgid "We're going to use these physical elements to build two volumes, one RAID-0 and one mirror (RAID-1). Let's start with the RAID-0 volume:"
msgstr "Questi elementi fisici verranno usati per costruire due volumi, un RAID-0 e un mirror (RAID-1). Si inizia col volume RAID-0:"

msgid ""
"<computeroutput># </computeroutput><userinput>mdadm --create /dev/md0 --level=0 --raid-devices=2 /dev/sdb /dev/sdc\n"
"</userinput><computeroutput>mdadm: Defaulting to version 1.2 metadata\n"
"mdadm: array /dev/md0 started.\n"
"# </computeroutput><userinput>mdadm --query /dev/md0\n"
"</userinput><computeroutput>/dev/md0: 7.99GiB raid0 2 devices, 0 spares. Use mdadm --detail for more detail.\n"
"# </computeroutput><userinput>mdadm --detail /dev/md0\n"
"</userinput><computeroutput>/dev/md0:\n"
"           Version : 1.2\n"
"     Creation Time : Mon Feb 28 01:54:24 2022\n"
"        Raid Level : raid0\n"
"        Array Size : 8378368 (7.99 GiB 8.58 GB)\n"
"      Raid Devices : 2\n"
"     Total Devices : 2\n"
"       Persistence : Superblock is persistent\n"
"\n"
"       Update Time : Mon Feb 28 01:54:24 2022\n"
"             State : clean \n"
"    Active Devices : 2\n"
"   Working Devices : 2\n"
"    Failed Devices : 0\n"
"     Spare Devices : 0\n"
"\n"
"            Layout : -unknown-\n"
"        Chunk Size : 512K\n"
"\n"
"Consistency Policy : none\n"
"\n"
"              Name : debian:0  (local to host debian)\n"
"              UUID : a75ac628:b384c441:157137ac:c04cd98c\n"
"            Events : 0\n"
"\n"
"    Number   Major   Minor   RaidDevice State\n"
"       0       8        0        0      active sync   /dev/sdb\n"
"       1       8       16        1      active sync   /dev/sdc\n"
"# </computeroutput><userinput>mkfs.ext4 /dev/md0\n"
"</userinput><computeroutput>mke2fs 1.46.2 (28-Feb-2021)\n"
"Discarding device blocks: done                            \n"
"Creating filesystem with 2094592 4k blocks and 524288 inodes\n"
"Filesystem UUID: ef077204-c477-4430-bf01-52288237bea0\n"
"Superblock backups stored on blocks: \n"
"\t32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632\n"
"\n"
"Allocating group tables: done                            \n"
"Writing inode tables: done                            \n"
"Creating journal (16384 blocks): done\n"
"Writing superblocks and filesystem accounting information: done \n"
"\n"
"# </computeroutput><userinput>mkdir /srv/raid-0\n"
"</userinput><computeroutput># </computeroutput><userinput>mount /dev/md0 /srv/raid-0\n"
"</userinput><computeroutput># </computeroutput><userinput>df -h /srv/raid-0\n"
"</userinput><computeroutput>Filesystem      Size  Used Avail Use% Mounted on\n"
"/dev/md0        7.8G   24K  7.4G   1% /srv/raid-0\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>mdadm --create /dev/md0 --level=0 --raid-devices=2 /dev/sdb /dev/sdc\n</userinput><computeroutput>mdadm: Defaulting to version 1.2 metadata\nmdadm: array /dev/md0 started.\n# </computeroutput><userinput>mdadm --query /dev/md0\n</userinput><computeroutput>/dev/md0: 7.99GiB raid0 2 devices, 0 spares. Use mdadm --detail for more detail.\n# </computeroutput><userinput>mdadm --detail /dev/md0\n</userinput><computeroutput>/dev/md0:\n           Version : 1.2\n     Creation Time : Mon Feb 28 01:54:24 2022\n        Raid Level : raid0\n        Array Size : 8378368 (7.99 GiB 8.58 GB)\n      Raid Devices : 2\n     Total Devices : 2\n       Persistence : Superblock is persistent\n\n       Update Time : Mon Feb 28 01:54:24 2022\n             State : clean \n    Active Devices : 2\n   Working Devices : 2\n    Failed Devices : 0\n     Spare Devices : 0\n\n            Layout : -unknown-\n        Chunk Size : 512K\n\nConsistency Policy : none\n\n              Name : debian:0  (local to host debian)\n              UUID : a75ac628:b384c441:157137ac:c04cd98c\n            Events : 0\n\n    Number   Major   Minor   RaidDevice State\n       0       8        0        0      active sync   /dev/sdb\n       1       8       16        1      active sync   /dev/sdc\n# </computeroutput><userinput>mkfs.ext4 /dev/md0\n</userinput><computeroutput>mke2fs 1.46.2 (28-Feb-2021)\nDiscarding device blocks: done                            \nCreating filesystem with 2094592 4k blocks and 524288 inodes\nFilesystem UUID: ef077204-c477-4430-bf01-52288237bea0\nSuperblock backups stored on blocks: \n\t32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632\n\nAllocating group tables: done                            \nWriting inode tables: done                            \nCreating journal (16384 blocks): done\nWriting superblocks and filesystem accounting information: done \n\n# </computeroutput><userinput>mkdir /srv/raid-0\n</userinput><computeroutput># </computeroutput><userinput>mount /dev/md0 /srv/raid-0\n</userinput><computeroutput># </computeroutput><userinput>df -h /srv/raid-0\n</userinput><computeroutput>Filesystem      Size  Used Avail Use% Mounted on\n/dev/md0        7.8G   24K  7.4G   1% /srv/raid-0\n</computeroutput>"

msgid "The <command>mdadm --create</command> command requires several parameters: the name of the volume to create (<filename>/dev/md*</filename>, with MD standing for <foreignphrase>Multiple Device</foreignphrase>), the RAID level, the number of disks (which is compulsory despite being mostly meaningful only with RAID-1 and above), and the physical drives to use. Once the device is created, we can use it like we'd use a normal partition, create a filesystem on it, mount that filesystem, and so on. Note that our creation of a RAID-0 volume on <filename>md0</filename> is nothing but coincidence, and the numbering of the array doesn't need to be correlated to the chosen amount of redundancy. It is also possible to create named RAID arrays, by giving <command>mdadm</command> parameters such as <filename>/dev/md/linear</filename> instead of <filename>/dev/md0</filename>."
msgstr "Il comando <command>mdadm --create</command> richiede diversi parametri: il nome del volume da creare (<filename>/dev/md*</filename>, dove MD sta per <foreignphrase>Multiple Device</foreignphrase>), il livello di RAID, il numero di dischi (obbligatorio nonostante abbia significato perlopiù solo con RAID-1 e superiori), ed i dischi fisici da usare. Una volta che il dispositivo è creato, può essere usato come una normale partizione, ci si crea sopra un file system, lo si monta, e così via. Notare che la creazione di un volume RAID-0 su <filename>md0</filename> è solo una coincidenza, non è necessario che la numerazione dell'array sia legata alla quantità di ridondanza scelta. È anche possibile creare un array RAID, passando a <command>mdadm</command> parametri come <filename>/dev/md/linear</filename> invece di <filename>/dev/md0</filename>."

msgid "Creation of a RAID-1 follows a similar fashion, the differences only being noticeable after the creation:"
msgstr "La creazione di un RAID-1 segue un percorso simile, la differenza si nota solo dopo la creazione:"

msgid ""
"<computeroutput># </computeroutput><userinput>mdadm --create /dev/md1 --level=1 --raid-devices=2 /dev/sdd2 /dev/sde\n"
"</userinput><computeroutput>mdadm: Note: this array has metadata at the start and\n"
"    may not be suitable as a boot device.  If you plan to\n"
"    store '/boot' on this device please ensure that\n"
"    your boot-loader understands md/v1.x metadata, or use\n"
"    --metadata=0.90\n"
"mdadm: largest drive (/dev/sdc2) exceeds size (4189184K) by more than 1%\n"
"Continue creating array? </computeroutput><userinput>y\n"
"</userinput><computeroutput>mdadm: Defaulting to version 1.2 metadata\n"
"mdadm: array /dev/md1 started.\n"
"# </computeroutput><userinput>mdadm --query /dev/md1\n"
"</userinput><computeroutput>/dev/md1: 4.00GiB raid1 2 devices, 0 spares. Use mdadm --detail for more detail.\n"
"# </computeroutput><userinput>mdadm --detail /dev/md1\n"
"</userinput><computeroutput>/dev/md1:\n"
"           Version : 1.2\n"
"     Creation Time : Mon Feb 28 02:07:48 2022\n"
"        Raid Level : raid1\n"
"        Array Size : 4189184 (4.00 GiB 4.29 GB)\n"
"     Used Dev Size : 4189184 (4.00 GiB 4.29 GB)\n"
"      Raid Devices : 2\n"
"     Total Devices : 2\n"
"       Persistence : Superblock is persistent\n"
"\n"
"       Update Time : Mon Feb 28 02:08:09 2022\n"
"             State : clean, resync\n"
"    Active Devices : 2\n"
"   Working Devices : 2\n"
"    Failed Devices : 0\n"
"     Spare Devices : 0\n"
"\n"
"Consistency Policy : resync\n"
"\n"
"    Rebuild Status : 13% complete\n"
"\n"
"              Name : debian:1  (local to host debian)\n"
"              UUID : 2dfb7fd5:e09e0527:0b5a905a:8334adb8\n"
"            Events : 17\n"
"\n"
"    Number   Major   Minor   RaidDevice State\n"
"       0       8       34        0      active sync   /dev/sdd2\n"
"       1       8       48        1      active sync   /dev/sde\n"
"# </computeroutput><userinput>mdadm --detail /dev/md1\n"
"</userinput><computeroutput>/dev/md1:\n"
"[...]\n"
"          State : clean\n"
"[...]\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>mdadm --create /dev/md1 --level=1 --raid-devices=2 /dev/sdd2 /dev/sde\n</userinput><computeroutput>mdadm: Note: this array has metadata at the start and\n    may not be suitable as a boot device.  If you plan to\n    store '/boot' on this device please ensure that\n    your boot-loader understands md/v1.x metadata, or use\n    --metadata=0.90\nmdadm: largest drive (/dev/sdc2) exceeds size (4189184K) by more than 1%\nContinue creating array? </computeroutput><userinput>y\n</userinput><computeroutput>mdadm: Defaulting to version 1.2 metadata\nmdadm: array /dev/md1 started.\n# </computeroutput><userinput>mdadm --query /dev/md1\n</userinput><computeroutput>/dev/md1: 4.00GiB raid1 2 devices, 0 spares. Use mdadm --detail for more detail.\n# </computeroutput><userinput>mdadm --detail /dev/md1\n</userinput><computeroutput>/dev/md1:\n           Version : 1.2\n     Creation Time : Mon Feb 28 02:07:48 2022\n        Raid Level : raid1\n        Array Size : 4189184 (4.00 GiB 4.29 GB)\n     Used Dev Size : 4189184 (4.00 GiB 4.29 GB)\n      Raid Devices : 2\n     Total Devices : 2\n       Persistence : Superblock is persistent\n\n       Update Time : Mon Feb 28 02:08:09 2022\n             State : clean, resync\n    Active Devices : 2\n   Working Devices : 2\n    Failed Devices : 0\n     Spare Devices : 0\n\nConsistency Policy : resync\n\n    Rebuild Status : 13% complete\n\n              Name : debian:1  (local to host debian)\n              UUID : 2dfb7fd5:e09e0527:0b5a905a:8334adb8\n            Events : 17\n\n    Number   Major   Minor   RaidDevice State\n       0       8       34        0      active sync   /dev/sdd2\n       1       8       48        1      active sync   /dev/sde\n# </computeroutput><userinput>mdadm --detail /dev/md1\n</userinput><computeroutput>/dev/md1:\n[...]\n          State : clean\n[...]\n</computeroutput>"

msgid "<emphasis>TIP</emphasis> RAID, disks and partitions"
msgstr "<emphasis>SUGGERIMENTO</emphasis> RAID, dischi e partizioni"

msgid "As illustrated by our example, RAID devices can be constructed out of disk partitions as well, and do not require full disks."
msgstr "Come si è visto nell'esempio, i device RAID possono essere costruiti anche usando delle partizioni e non richiedono interi dischi."

msgid "A few remarks are in order. First, <command>mdadm</command> notices that the physical elements have different sizes; since this implies that some space will be lost on the bigger element, a confirmation is required."
msgstr "Bisogna fare alcune osservazioni. Prima di tutto, <command>mdadm</command> si accorge che gli elementi fisici hanno dimensioni diverse; poiché ciò implica che verrà perso dello spazio sull'elemento più grande, è richiesta una conferma."

msgid "More importantly, note the state of the mirror. The normal state of a RAID mirror is that both disks have exactly the same contents. However, nothing guarantees this is the case when the volume is first created. The RAID subsystem will therefore provide that guarantee itself, and there will be a synchronization phase as soon as the RAID device is created. After some time (the exact amount will depend on the actual size of the disks…), the RAID array switches to the “active” or “clean” state. Note that during this reconstruction phase, the mirror is in a degraded mode, and redundancy isn't assured. A disk failing during that risk window could lead to losing all the data. Large amounts of critical data, however, are rarely stored on a freshly created RAID array before its initial synchronization. Note that even in degraded mode, the <filename>/dev/md1</filename> is usable, and a filesystem can be created on it, as well as some data copied on it."
msgstr "Cosa ancora più importante, notare lo stato del mirror. Lo stato normale di un mirror RAID è che entrambi i dischi abbiano esattamente gli stessi contenuti. Tuttavia, nulla garantisce che ciò sia vero quando il volume viene creato. Il sottosistema RAID perciò fornirà esso stesso questa garanzia, e appena dopo la creazione del device RAID ci sarà una fase di sincronizzazione. Dopo un certo tempo (l'esatta durata dipenderà dall'effettiva dimensione dei dischi…), l'array RAID passa allo stato \"attivo\" o \"pulito\". Notare che durante questa fase di ricostruzione, il mirror è in modalità degradata, e la ridondanza non è assicurata. Il guasto di un disco durante questa fase potrebbe comportare la perdita di tutti i dati. Ad ogni modo, è raro che grandi quantità di dati critici vengano memorizzati su un array RAID appena creato prima della sincronizzazione iniziale. Notare che anche in modalità degradata, <filename>/dev/md1</filename> è usabile, e vi si può creare sopra un file system, oltre a copiarvi sopra dei dati."

msgid "<emphasis>TIP</emphasis> Starting a mirror in degraded mode"
msgstr "<emphasis>SUGGERIMENTO</emphasis> Avviare un mirror in modalità degradata"

msgid "Sometimes two disks are not immediately available when one wants to start a RAID-1 mirror, for instance because one of the disks one plans to include is already used to store the data one wants to move to the array. In such circumstances, it is possible to deliberately create a degraded RAID-1 array by passing <filename>missing</filename> instead of a device file as one of the arguments to <command>mdadm</command>. Once the data have been copied to the “mirror”, the old disk can be added to the array. A synchronization will then take place, giving us the redundancy that was wanted in the first place."
msgstr "A volte non si hanno subito a disposizione due dischi quando si vuole avviare un mirror RAID-1, per esempio perché uno dei dischi che si vogliono includere è già usato per memorizzare i dati che si vogliono spostare nell'array. In questi casi è possibile creare volontariamente un array RAID-1 degradato passando <filename>missing</filename> invece di un file di device come uno degli argomenti a <command>mdadm</command>. Una volta che i dati sono stati copiati sul «mirror», il vecchio disco può essere aggiunto all'array. A quel punto avrà luogo una sincronizzazione, che darà la ridondanza voluta all'inizio."

msgid "<emphasis>TIP</emphasis> Setting up a mirror without synchronization"
msgstr "<emphasis>SUGGERIMENTO</emphasis> Impostare un mirror senza sincronizzazione"

msgid "RAID-1 volumes are often created to be used as a new disk, often considered blank. The actual initial contents of the disk is therefore not very relevant, since one only needs to know that the data written after the creation of the volume, in particular the filesystem, can be accessed later."
msgstr "I volumi RAID-1 sono spesso creati per essere usati come nuovo disco, spesso considerato vuoto. L'effettivo contenuto iniziale del disco quindi non è molto importante, visto che basta sapere che i dati scritti dopo la creazione del volume, in particolare il file system, possono essere letti in seguito."

msgid "One might therefore wonder about the point of synchronizing both disks at creation time. Why care whether the contents are identical on zones of the volume that we know will only be read after we have written to them?"
msgstr "Ci si può quindi chiedere il senso di sincronizzare entrambi i dischi al momento della creazione. Perché preoccuparsi del fatto che i contenuti siano identici in zone del volume di cui si sa che verranno lette solo dopo che sono state scritte?"

msgid "Fortunately, this synchronization phase can be avoided by passing the <literal>--assume-clean</literal> option to <command>mdadm</command>. However, this option can lead to surprises in cases where the initial data will be read (for instance if a filesystem is already present on the physical disks), which is why it isn't enabled by default."
msgstr "Per fortuna, questa fase di sincronizzazione può essere evitata passando l'opzione <literal>--assume-clean</literal> a <command>mdadm</command>. Tuttavia, questa opzione può portare a delle sorprese in casi in cui i dati iniziali saranno letti (per esempio se sui dischi fisici è già presente un file system), che è il motivo per cui non è abilitata in modo predefinito."

msgid "<primary>RAID</primary><secondary>failing</secondary>"
msgstr "<primary>RAID</primary><secondary>guasto</secondary>"

msgid "Now let's see what happens when one of the elements of the RAID-1 array fails. <command>mdadm</command>, in particular its <literal>--fail</literal> option, allows simulating such a disk failure:"
msgstr "Ora si mostrerà cosa succede quando uno degli elementi dell'array RAID 1 si guasta. <command>mdadm</command>, in particolare la sua opzione <literal>--fail</literal>, permette di simulare uno guasto:"

msgid ""
"<computeroutput># </computeroutput><userinput>mdadm /dev/md1 --fail /dev/sde\n"
"</userinput><computeroutput>mdadm: set /dev/sde faulty in /dev/md1\n"
"# </computeroutput><userinput>mdadm --detail /dev/md1\n"
"</userinput><computeroutput>/dev/md1:\n"
"           Version : 1.2\n"
"     Creation Time : Mon Feb 28 02:07:48 2022\n"
"        Raid Level : raid1\n"
"        Array Size : 4189184 (4.00 GiB 4.29 GB)\n"
"     Used Dev Size : 4189184 (4.00 GiB 4.29 GB)\n"
"      Raid Devices : 2\n"
"     Total Devices : 2\n"
"       Persistence : Superblock is persistent\n"
"\n"
"       Update Time : Mon Feb 28 02:15:34 2022\n"
"             State : clean, degraded \n"
"    Active Devices : 1\n"
"   Working Devices : 1\n"
"    Failed Devices : 1\n"
"     Spare Devices : 0\n"
"\n"
"Consistency Policy : resync\n"
"\n"
"              Name : debian:1  (local to host debian)\n"
"              UUID : 2dfb7fd5:e09e0527:0b5a905a:8334adb8\n"
"            Events : 19\n"
"\n"
"    Number   Major   Minor   RaidDevice State\n"
"       0       8       34        0      active sync   /dev/sdd2\n"
"       -       0        0        1      removed\n"
"\n"
"       1       8       48        -      faulty   /dev/sde\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>mdadm /dev/md1 --fail /dev/sde\n</userinput><computeroutput>mdadm: set /dev/sde faulty in /dev/md1\n# </computeroutput><userinput>mdadm --detail /dev/md1\n</userinput><computeroutput>/dev/md1:\n           Version : 1.2\n     Creation Time : Mon Feb 28 02:07:48 2022\n        Raid Level : raid1\n        Array Size : 4189184 (4.00 GiB 4.29 GB)\n     Used Dev Size : 4189184 (4.00 GiB 4.29 GB)\n      Raid Devices : 2\n     Total Devices : 2\n       Persistence : Superblock is persistent\n\n       Update Time : Mon Feb 28 02:15:34 2022\n             State : clean, degraded \n    Active Devices : 1\n   Working Devices : 1\n    Failed Devices : 1\n     Spare Devices : 0\n\nConsistency Policy : resync\n\n              Name : debian:1  (local to host debian)\n              UUID : 2dfb7fd5:e09e0527:0b5a905a:8334adb8\n            Events : 19\n\n    Number   Major   Minor   RaidDevice State\n       0       8       34        0      active sync   /dev/sdd2\n       -       0        0        1      removed\n\n       1       8       48        -      faulty   /dev/sde\n</computeroutput>"

msgid "The contents of the volume are still accessible (and, if it is mounted, the applications don't notice a thing), but the data safety isn't assured anymore: should the <filename>sdd</filename> disk fail in turn, the data would be lost. We want to avoid that risk, so we'll replace the failed disk with a new one, <filename>sdf</filename>:"
msgstr "I contenuti del volume sono ancora accessibili (e, se montato, le applicazioni non si accorgono di nulla), ma la sicurezza dei dati non è più assicurata: se il disco <filename>sdd</filename> dovesse a sua volta guastarsi, i dati andrebbero persi. Poiché è meglio evitare questo rischio, si va a sostituire il disco guasto con uno nuovo, <filename>sdf</filename>:"

msgid ""
"<computeroutput># </computeroutput><userinput>mdadm /dev/md1 --add /dev/sdf</userinput>\n"
"<computeroutput>mdadm: added /dev/sdf\n"
"# </computeroutput><userinput>mdadm --detail /dev/md1\n"
"</userinput><computeroutput>/dev/md1:\n"
"           Version : 1.2\n"
"     Creation Time : Mon Feb 28 02:07:48 2022\n"
"        Raid Level : raid1\n"
"        Array Size : 4189184 (4.00 GiB 4.29 GB)\n"
"     Used Dev Size : 4189184 (4.00 GiB 4.29 GB)\n"
"      Raid Devices : 2\n"
"     Total Devices : 3\n"
"       Persistence : Superblock is persistent\n"
"\n"
"       Update Time : Mon Feb 28 02:25:34 2022\n"
"             State : clean, degraded, recovering \n"
"    Active Devices : 1\n"
"   Working Devices : 2\n"
"    Failed Devices : 1\n"
"     Spare Devices : 1\n"
"\n"
"Consistency Policy : resync\n"
"\n"
"    Rebuild Status : 47% complete\n"
"\n"
"              Name : debian:1  (local to host debian)\n"
"              UUID : 2dfb7fd5:e09e0527:0b5a905a:8334adb8\n"
"            Events : 39\n"
"\n"
"    Number   Major   Minor   RaidDevice State\n"
"       0       8       34        0      active sync   /dev/sdd2\n"
"       2       8       64        1      spare rebuilding   /dev/sdf\n"
"\n"
"       1       8       48        -      faulty   /dev/sde\n"
"# </computeroutput><userinput>[...]</userinput>\n"
"<computeroutput>[...]\n"
"# </computeroutput><userinput>mdadm --detail /dev/md1</userinput>\n"
"<computeroutput>/dev/md1:\n"
"           Version : 1.2\n"
"     Creation Time : Mon Feb 28 02:07:48 2022\n"
"        Raid Level : raid1\n"
"        Array Size : 4189184 (4.00 GiB 4.29 GB)\n"
"     Used Dev Size : 4189184 (4.00 GiB 4.29 GB)\n"
"      Raid Devices : 2\n"
"     Total Devices : 3\n"
"       Persistence : Superblock is persistent\n"
"\n"
"       Update Time : Mon Feb 28 02:25:34 2022\n"
"             State : clean\n"
"    Active Devices : 2\n"
"   Working Devices : 2\n"
"    Failed Devices : 1\n"
"     Spare Devices : 0\n"
"\n"
"Consistency Policy : resync\n"
"\n"
"              Name : debian:1  (local to host debian)\n"
"              UUID : 2dfb7fd5:e09e0527:0b5a905a:8334adb8\n"
"            Events : 41\n"
"\n"
"    Number   Major   Minor   RaidDevice State\n"
"       0       8       34        0      active sync   /dev/sdd2\n"
"       2       8       64        1      active sync   /dev/sdf\n"
"\n"
"       1       8       48        -      faulty   /dev/sde\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>mdadm /dev/md1 --add /dev/sdf</userinput>\n<computeroutput>mdadm: added /dev/sdf\n# </computeroutput><userinput>mdadm --detail /dev/md1\n</userinput><computeroutput>/dev/md1:\n           Version : 1.2\n     Creation Time : Mon Feb 28 02:07:48 2022\n        Raid Level : raid1\n        Array Size : 4189184 (4.00 GiB 4.29 GB)\n     Used Dev Size : 4189184 (4.00 GiB 4.29 GB)\n      Raid Devices : 2\n     Total Devices : 3\n       Persistence : Superblock is persistent\n\n       Update Time : Mon Feb 28 02:25:34 2022\n             State : clean, degraded, recovering \n    Active Devices : 1\n   Working Devices : 2\n    Failed Devices : 1\n     Spare Devices : 1\n\nConsistency Policy : resync\n\n    Rebuild Status : 47% complete\n\n              Name : debian:1  (local to host debian)\n              UUID : 2dfb7fd5:e09e0527:0b5a905a:8334adb8\n            Events : 39\n\n    Number   Major   Minor   RaidDevice State\n       0       8       34        0      active sync   /dev/sdd2\n       2       8       64        1      spare rebuilding   /dev/sdf\n\n       1       8       48        -      faulty   /dev/sde\n# </computeroutput><userinput>[...]</userinput>\n<computeroutput>[...]\n# </computeroutput><userinput>mdadm --detail /dev/md1</userinput>\n<computeroutput>/dev/md1:\n           Version : 1.2\n     Creation Time : Mon Feb 28 02:07:48 2022\n        Raid Level : raid1\n        Array Size : 4189184 (4.00 GiB 4.29 GB)\n     Used Dev Size : 4189184 (4.00 GiB 4.29 GB)\n      Raid Devices : 2\n     Total Devices : 3\n       Persistence : Superblock is persistent\n\n       Update Time : Mon Feb 28 02:25:34 2022\n             State : clean\n    Active Devices : 2\n   Working Devices : 2\n    Failed Devices : 1\n     Spare Devices : 0\n\nConsistency Policy : resync\n\n              Name : debian:1  (local to host debian)\n              UUID : 2dfb7fd5:e09e0527:0b5a905a:8334adb8\n            Events : 41\n\n    Number   Major   Minor   RaidDevice State\n       0       8       34        0      active sync   /dev/sdd2\n       2       8       64        1      active sync   /dev/sdf\n\n       1       8       48        -      faulty   /dev/sde\n</computeroutput>"

msgid "Here again, the kernel automatically triggers a reconstruction phase during which the volume, although still accessible, is in a degraded mode. Once the reconstruction is over, the RAID array is back to a normal state. One can then tell the system that the <filename>sde</filename> disk is about to be removed from the array, so as to end up with a classical RAID mirror on two disks:"
msgstr "Anche qui, il kernel attiva automaticamente una fase di ricostruzione durante la quale il volume, sebbene ancora accessibile, è in modalità degradata. Una volta finita la ricostruzione, l'array RAID torna a uno stato normale. A questo punto si può dire al sistema che il disco <filename>sde</filename> sta per essere rimosso dall'array, così da arrivare a un classico mirror RAID su due dischi:"

msgid ""
"<computeroutput># </computeroutput><userinput>mdadm /dev/md1 --remove /dev/sde\n"
"</userinput><computeroutput>mdadm: hot removed /dev/sde from /dev/md1\n"
"# </computeroutput><userinput>mdadm --detail /dev/md1\n"
"</userinput><computeroutput>/dev/md1:\n"
"[...]\n"
"    Number   Major   Minor   RaidDevice State\n"
"       0       8       34        0      active sync   /dev/sdd2\n"
"       2       8       64        1      active sync   /dev/sdf\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>mdadm /dev/md1 --remove /dev/sde\n</userinput><computeroutput>mdadm: hot removed /dev/sde from /dev/md1\n# </computeroutput><userinput>mdadm --detail /dev/md1\n</userinput><computeroutput>/dev/md1:\n[...]\n    Number   Major   Minor   RaidDevice State\n       0       8       34        0      active sync   /dev/sdd2\n       2       8       64        1      active sync   /dev/sdf\n</computeroutput>"

msgid "From then on, the drive can be physically removed when the server is next switched off, or even hot-removed when the hardware configuration allows hot-swap. Such configurations include some SCSI controllers, most SATA disks, and external drives operating on USB or Firewire."
msgstr "Da questo punto il drive può essere rimosso fisicamente al prossimo spegnimento del server, o anche rimosso a caldo quando la configurazione hardware permette l'hot-swap. Tali configurazioni includono alcuni controller SCSI, la maggior parte dei dischi SATA e i dischi esterni che operano su USB o Firewire."

msgid "Backing up the Configuration"
msgstr "Fare il backup della configurazione"

msgid "Most of the meta-data concerning RAID volumes are saved directly on the disks that make up these arrays, so that the kernel can detect the arrays and their components and assemble them automatically when the system starts up. However, backing up this configuration is encouraged, because this detection isn't fail-proof, and it is only expected that it will fail precisely in sensitive circumstances. In our example, if the <filename>sde</filename> disk failure had been real (instead of simulated) and the system had been restarted without removing this <filename>sde</filename> disk, this disk could start working again due to having been probed during the reboot. The kernel would then have three physical elements, each claiming to contain half of the same RAID volume. In reality this leads to the RAID starting from the individual disks alternately - distributing the data also alternately, depending on which disk started the RAID in degraded mode Another source of confusion can come when RAID volumes from two servers are consolidated onto one server only. If these arrays were running normally before the disks were moved, the kernel would be able to detect and reassemble the pairs properly; but if the moved disks had been aggregated into an <filename>md1</filename> on the old server, and the new server already has an <filename>md1</filename>, one of the mirrors would be renamed."
msgstr "La maggior parte dei meta-dati riguardanti i volumi RAID sono salvati direttamente sui dischi che compongono questi array, cosicché il kernel può rilevare gli array e i loro componenti e assemblarli automaticamente all'avvio del sistema. Tuttavia, è consigliabile fare copie di riserva di questa configurazione, perché questo rilevamento non è a prova d'errore, ed è ovvio che fallisca proprio in circostanze delicate. Nell'esempio in questione, se il guasto al disco <filename>sdh</filename> fosse stato reale (invece di essere solo una simulazione) e il sistema si fosse riavviato senza rimuovere questo disco <filename>sdh</filename>, questo disco si sarebbe attivato di nuovo, essendo stato riconosciuto durante il riavvio. A quel punto il kernel avrebbe tre elementi fisici, ciascuno dei quali direbbe di contenere metà dello stesso volume RAID. In realtà questo porta il RAID a partire alternativamente dai singoli dischi, distribuendo i dati anche in modo alternato, a seconda di quale disco ha avviato il RAID in modalità degradata. Un'altra fonte di confusione può sorgere quando volumi RAID di due server vengono consolidati su un solo server. Se questi array stavano funzionando normalmente prima che i dischi fossero spostati, il kernel sarebbe in grado di rilevare e riassemblare le coppie correttamente; ma se i dischi spostati sono stati aggregati in un <filename>md1</filename> sul vecchio server e il nuovo server ha già un <filename>md1</filename>, uno dei mirror verrebbe rinominato."

msgid "Backing up the configuration is therefore important, if only for reference. The standard way to do it is by editing the <filename>/etc/mdadm/mdadm.conf</filename> file, an example of which is listed here:"
msgstr "È quindi importante fare il backup della configurazione, se non altro per avere un riferimento. Il modo standard di farlo è modificare il file <filename>/etc/mdadm/mdadm.conf</filename>, un esempio del quale è mostrato qui:"

msgid "<primary><filename>/etc</filename></primary><secondary><filename>/etc/mdadm/mdadm.conf</filename></secondary>"
msgstr "<primary><filename>/etc</filename></primary><secondary><filename>/etc/mdadm/mdadm.conf</filename></secondary>"

msgid "<command>mdadm</command> configuration file"
msgstr "File di configurazione di <command>mdadm</command>"

msgid ""
"<![CDATA[# mdadm.conf\n"
"#\n"
"# !NB! Run update-initramfs -u after updating this file.\n"
"# !NB! This will ensure that initramfs has an uptodate copy.\n"
"#\n"
"# Please refer to mdadm.conf(5) for information about this file.\n"
"#\n"
"\n"
"# by default (built-in), scan all partitions (/proc/partitions) and all\n"
"# containers for MD superblocks. alternatively, specify devices to scan, using\n"
"# wildcards if desired.\n"
"DEVICE /dev/sd*\n"
"\n"
"# automatically tag new arrays as belonging to the local system\n"
"HOMEHOST <system>\n"
"\n"
"# instruct the monitoring daemon where to send mail alerts\n"
"MAILADDR root\n"
"\n"
"# definitions of existing MD arrays\n"
"ARRAY /dev/md/0  metadata=1.2 UUID=a75ac628:b384c441:157137ac:c04cd98c name=debian:0\n"
"ARRAY /dev/md/1  metadata=1.2 UUID=2dfb7fd5:e09e0527:0b5a905a:8334adb8 name=debian:1\n"
"# This configuration was auto-generated on Mon, 28 Feb 2022 01:53:48 +0100 by mkconf\n"
"]]>"
msgstr "<![CDATA[# mdadm.conf\n#\n# !NB! Run update-initramfs -u after updating this file.\n# !NB! This will ensure that initramfs has an uptodate copy.\n#\n# Please refer to mdadm.conf(5) for information about this file.\n#\n\n# by default (built-in), scan all partitions (/proc/partitions) and all\n# containers for MD superblocks. alternatively, specify devices to scan, using\n# wildcards if desired.\nDEVICE /dev/sd*\n\n# automatically tag new arrays as belonging to the local system\nHOMEHOST <system>\n\n# instruct the monitoring daemon where to send mail alerts\nMAILADDR root\n\n# definitions of existing MD arrays\nARRAY /dev/md/0  metadata=1.2 UUID=a75ac628:b384c441:157137ac:c04cd98c name=debian:0\nARRAY /dev/md/1  metadata=1.2 UUID=2dfb7fd5:e09e0527:0b5a905a:8334adb8 name=debian:1\n# This configuration was auto-generated on Mon, 28 Feb 2022 01:53:48 +0100 by mkconf\n]]>"

msgid "One of the most useful details is the <literal>DEVICE</literal> option, which lists the devices where the system will automatically look for components of RAID volumes at start-up time. In our example, we replaced the default value, <literal>partitions containers</literal>, with an explicit list of device files, since we chose to use entire disks and not only partitions, for some volumes."
msgstr "Uno dei dettagli più utili è l'opzione <literal>DEVICE</literal>, che elenca i dispositi in cui il sistema cercherà automaticamente le componenti dei volumi RAID all'avvio. Nell'esempio in questione, abbiamo sostituito il valore predefinito, <literal>partitions containers</literal>, con una lista esplicita dei file di dispositi, poiché si è scelto di usare dei dischi interi e non solo delle partizioni, per alcuni volumi."

msgid "The last two lines in our example are those allowing the kernel to safely pick which volume number to assign to which array. The metadata stored on the disks themselves are enough to re-assemble the volumes, but not to determine the volume number (and the matching <filename>/dev/md*</filename> device name)."
msgstr "Le ultime due righe nell'esempio sono quelle che permettono al kernel di scegliere in sicurezza quale numero di volume assegnare a ciascun array. I metadati memorizzati sui dischi stessi sono sufficienti a riassemblare i volumi ma non a determinare i numeri di volume (e il corrispondente nome di device <filename>/dev/md*</filename>)."

msgid "Fortunately, these lines can be generated automatically:"
msgstr "Per fortuna, queste righe si possono generare automaticamente:"

msgid ""
"<computeroutput># </computeroutput><userinput>mdadm --misc --detail --brief /dev/md?\n"
"</userinput><computeroutput>ARRAY /dev/md/0  metadata=1.2 UUID=a75ac628:b384c441:157137ac:c04cd98c name=debian:0\n"
"ARRAY /dev/md/1  metadata=1.2 UUID=2dfb7fd5:e09e0527:0b5a905a:8334adb8 name=debian:1\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>mdadm --misc --detail --brief /dev/md?\n</userinput><computeroutput>ARRAY /dev/md/0  metadata=1.2 UUID=a75ac628:b384c441:157137ac:c04cd98c name=debian:0\nARRAY /dev/md/1  metadata=1.2 UUID=2dfb7fd5:e09e0527:0b5a905a:8334adb8 name=debian:1\n</computeroutput>"

msgid "The contents of these last two lines doesn't depend on the list of disks included in the volume. It is therefore not necessary to regenerate these lines when replacing a failed disk with a new one. On the other hand, care must be taken to update the file when creating or deleting a RAID array."
msgstr "I contenuti di queste ultime due righe non dipendono dall'elenco dei dischi inclusi nel volume. Pertanto non è necessario rigenerare queste righe quando si sostituisce un disco guasto con uno nuovo. D'altro canto, bisogna avere cura di aggiornare il file quando si crea o si elimina un array RAID."

msgid "LVM, the <emphasis>Logical Volume Manager</emphasis>, is another approach to abstracting logical volumes from their physical supports, which focuses on increasing flexibility rather than increasing reliability. LVM allows changing a logical volume transparently as far as the applications are concerned; for instance, it is possible to add new disks, migrate the data to them, and remove the old disks, without unmounting the volume."
msgstr "LVM, il <emphasis>Logical Volume Manager (Gestore Volume Logico)</emphasis> , è un altro approccio per astrarre volumi logici dai loro supporti fisici, che si concentra più sull'aumento della flessibilità che sull'aumento dell'affidabilità. LVM permette la modifica di un volume logico in modo trasparente dal punto di vista delle applicazioni; per esempio, è possibile aggiungere nuovi dischi, migrare i dati ad esso, e rimuovere i vecchi dischi, senza smontare il volume."

msgid "LVM Concepts"
msgstr "Concetti relativi a LVM"

msgid "<primary>LVM</primary><secondary>concept</secondary>"
msgstr "<primary>LVM</primary><secondary>concetti</secondary>"

msgid "<primary>PV</primary>"
msgstr "<primary>PV</primary>"

msgid "<primary>Physical Volume</primary><see>PV</see>"
msgstr "<primary>Physical Volume (Volume Fisico)</primary><see>PV</see>"

msgid "This flexibility is attained by a level of abstraction involving three concepts."
msgstr "Questa flessibilità si raggiunge tramite un livello di astrazione che riguarda tre concetti."

msgid "First, the PV (<emphasis>Physical Volume</emphasis>) is the entity closest to the hardware: it can be partitions on a disk, or a full disk, or even any other block device (including, for instance, a RAID array). Note that when a physical element is set up to be a PV for LVM, it should only be accessed via LVM, otherwise the system will get confused."
msgstr "Primo, il PV (<emphasis>Physical Volume</emphasis>, volume fisico) è l'entità più vicina all'hardware: i volumi fisici possono essere partizioni di un disco, o un disco completo, o anche qualunque altro dispositivo a blocchi (incluso, ad esempio, un array RAID). Notare che quando un elemento fisico viene configurato come PV per LVM, vi si deve accedere solo via LVM, altrimenti il sistema si confonderà."

msgid "<primary>VG</primary>"
msgstr "<primary>VG</primary>"

msgid "<primary>Volume Group</primary><see>VG</see>"
msgstr "<primary>Volume Group (gruppo del volume)</primary><see>VG</see>"

msgid "A number of PVs can be clustered in a VG (<emphasis>Volume Group</emphasis>), which can be compared to disks both virtual and extensible. VGs are abstract, and don't appear in a device file in the <filename>/dev</filename> hierarchy, so there is no risk of using them directly."
msgstr "Un certo numero di PV può essere raggruppato in un VG (<emphasis>Volume Group</emphasis>), che è paragonabile a dischi che sono virtuali ed estendibili. I VG sono astratti e non compaiono come device nella gerarchia <filename>/dev</filename>, quindi non c'è rischio di usarli direttamente."

msgid "<primary>LV</primary>"
msgstr "<primary>LV</primary>"

msgid "<primary>Logical Volume</primary><see>LV</see>"
msgstr "<primary>Logical Volume (Volume Logico)</primary><see>LV</see>"

msgid "The third kind of object is the LV (<emphasis>Logical Volume</emphasis>), which is a chunk of a VG; if we keep the VG-as-disk analogy, the LV compares to a partition. The LV appears as a block device with an entry in <filename>/dev</filename>, and it can be used as any other physical partition can be (most commonly, to host a filesystem or swap space)."
msgstr "Il terzo tipo di oggetto è il LV (<emphasis>Logical Volume</emphasis>, volume logico), che è una parte di un VG; proseguendo con l'analogia fra VG e dischi, il LV è simile a una partizione. Il LV appare come un dispositivo a blocchi con una voce in <filename>/dev</filename>, e può essere usato come ogni altra partizione fisica (più di frequente, per ospitare un filesystem o spazio di swap)."

msgid "The important thing is that the splitting of a VG into LVs is entirely independent of its physical components (the PVs). A VG with only a single physical component (a disk for instance) can be split into a dozen logical volumes; similarly, a VG can use several physical disks and appear as a single large logical volume. The only constraint, obviously, is that the total size allocated to LVs can't be bigger than the total capacity of the PVs in the volume group."
msgstr "La cosa importante è che la divisione di un VG in LV è completamente indipendente dai suoi componenti fisici (i PV). Un VG con un solo componente fisico (per esempio un disco) può essere diviso in una dozzina di volumi logici; allo stesso modo, un VG può usare diversi dischi fisici e apparire come un unico grande volume logico. L'unico vincolo, ovviamente, è che la dimensione totale allocata ai LV non può superare la capacità totale dei PV nel gruppo di volume."

msgid "It often makes sense, however, to have some kind of homogeneity among the physical components of a VG, and to split the VG into logical volumes that will have similar usage patterns. For instance, if the available hardware includes fast disks and slower disks, the fast ones could be clustered into one VG and the slower ones into another; chunks of the first one can then be assigned to applications requiring fast data access, while the second one will be kept for less demanding tasks."
msgstr "Spesso comunque ha un senso avere una certa omogeneità fra le componenti fisiche di un VG, e suddividere i VG in volumi logici che avranno modelli d'uso simili. Per esempio, se l'hardware disponibile include dischi rapidi e dischi più lenti, quelli rapidi possono essere raggruppati in un VG e quelli più lenti in un altro; blocchi del primo possono quindi essere assegnati ad applicazioni che richiedono un accesso rapido ai dati, mentre il secondo sarà tenuto per compiti meno impegnativi."

msgid "In any case, keep in mind that an LV isn't particularly attached to any one PV. It is possible to influence where the data from an LV are physically stored, but this possibility isn't required for day-to-day use. On the contrary: when the set of physical components of a VG evolves, the physical storage locations corresponding to a particular LV can be migrated across disks (while staying within the PVs assigned to the VG, of course)."
msgstr "In ogni caso, è bene tenere a mente che un LV non è particolarmente legato a un singolo PV. È possibile indicare dove sono fisicamente memorizzati i dati di un LV, ma questa possibilità non è richiesta per un uso quotidiano. Al contrario: quando l'insieme dei componenti fisici di un VG evolve, il luogo fisico di stoccaggio che corrisponde a un particolare LV può essere migrato da un disco a un altro (ovviamente rimanendo all'interno dei PV assegnati ai VG)."

msgid "Setting up LVM"
msgstr "Impostazione di un LVM"

msgid "<primary>LVM</primary><secondary>setup</secondary>"
msgstr "<primary>LVM</primary><secondary>configurazione</secondary>"

msgid "Let us now follow, step by step, the process of setting up LVM for a typical use case: we want to simplify a complex storage situation. Such a situation usually happens after some long and convoluted history of accumulated temporary measures. For the purposes of illustration, we'll consider a server where the storage needs have changed over time, ending up in a maze of available partitions split over several partially used disks. In more concrete terms, the following partitions are available:"
msgstr "Si seguirà ora, passo per passo, il processo di impostazione di un LVM per un tipico caso d'uso: semplificare una situazione complessa di memorizzazione dati. Una tale situazione di solito si ha dopo una lunga e intricata storia fatta di misure temporanee accumulatesi nel tempo. A scopo illustrativo, si considererà un server in cui le necessità di memorizzazione sono cambiate nel tempo, arrivando ad avere alla fine un labirinto di partizioni disponibili sparse fra diversi dischi usati parzialmente. In termini più concreti, sono disponibili le seguenti partizioni:"

msgid "on the <filename>sdb</filename> disk, a <filename>sdb2</filename> partition, 4 GB;"
msgstr "sul disco <filename>sdb</filename>, una partizione <filename>sdb2</filename>, 4 GB;"

msgid "on the <filename>sdc</filename> disk, a <filename>sdc3</filename> partition, 3 GB;"
msgstr "sul disco <filename>sdc</filename>, una partizione <filename>sdc3</filename>, 3 GB;"

msgid "the <filename>sdd</filename> disk, 4 GB, is fully available;"
msgstr "il disco <filename>sdd</filename>, 4 GB, è completamente disponibile;"

msgid "on the <filename>sdf</filename> disk, a <filename>sdf1</filename> partition, 4 GB; and a <filename>sdf2</filename> partition, 5 GB."
msgstr "sul disco <filename>sdf</filename>, una partizione <filename>sdf1</filename>, 4 GB e una partizione <filename>sdf2</filename>, 5 GB."

msgid "In addition, let's assume that disks <filename>sdb</filename> and <filename>sdf</filename> are faster than the other two."
msgstr "Inoltre, si suppone che i dischi <filename>sdb</filename> e <filename>sdf</filename> siano più veloci degli altri due."

msgid "Our goal is to set up three logical volumes for three different applications: a file server requiring 5 GB of storage space, a database (1 GB) and some space for back-ups (12 GB). The first two need good performance, but back-ups are less critical in terms of access speed. All these constraints prevent the use of partitions on their own; using LVM can abstract the physical size of the devices, so the only limit is the total available space."
msgstr "Lo scopo è di impostare tre volumi logici per tre diverse applicazioni: un file server che richiede 5 GB di spazio disco, un database (1 GB) e un po' di spazio per i backup (12 GB). I primi due hanno bisogno di buone prestazioni, ma i backup sono meno critici in termini di velocità di accesso. Tutti questi vincoli impediscono di usare le partizioni così come sono; l'uso di LVM permette di astrarre dalla dimensione fisica dei dispositivi, cosicché l'unico limite è lo spazio totale disponibile."

msgid "<primary><emphasis role=\"pkg\">lvm2</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">lvm2</emphasis></primary>"

msgid "<primary>LVM</primary><secondary>create PV</secondary>"
msgstr "<primary>LVM</primary><secondary>creazione PV</secondary>"

msgid "The required tools are in the <emphasis role=\"pkg\">lvm2</emphasis> package and its dependencies. When they're installed, setting up LVM takes three steps, matching the three levels of concepts."
msgstr "Gli strumenti richiesti sono nel pacchetto <emphasis role=\"pkg\">lvm2</emphasis> e nelle sue dipendenze. Una volta installati, impostare un LVM richiede tre passi, che corrispondono ai tre livelli di concetti."

msgid "First, we prepare the physical volumes using <command>pvcreate</command>:"
msgstr "Prima di tutto si preparano i volumi fisici usando <command>pvcreate</command>:"

msgid "<primary><command>pvcreate</command></primary>"
msgstr "<primary><command>pvcreate</command></primary>"

msgid "<primary><command>pvdisplay</command></primary>"
msgstr "<primary><command>pvdisplay</command></primary>"

msgid ""
"<computeroutput># </computeroutput><userinput>pvcreate /dev/sdb2\n"
"</userinput><computeroutput>  Physical volume \"/dev/sdb2\" successfully created.\n"
"# </computeroutput><userinput>pvdisplay\n"
"</userinput><computeroutput>  \"/dev/sdb2\" is a new physical volume of \"4.00 GiB\"\n"
"  --- NEW Physical volume ---\n"
"  PV Name               /dev/sdb2\n"
"  VG Name               \n"
"  PV Size               4.00 GiB\n"
"  Allocatable           NO\n"
"  PE Size               0   \n"
"  Total PE              0\n"
"  Free PE               0\n"
"  Allocated PE          0\n"
"  PV UUID               yK0K6K-clbc-wt6e-qk9o-aUh9-oQqC-k1T71B\n"
"\n"
"# </computeroutput><userinput>for i in sdc3 sdd sdf1 sdf2 ; do pvcreate /dev/$i ; done\n"
"</userinput><computeroutput>  Physical volume \"/dev/sdc3\" successfully created.\n"
"  Physical volume \"/dev/sdd\" successfully created.\n"
"  Physical volume \"/dev/sdf1\" successfully created.\n"
"  Physical volume \"/dev/sdf2\" successfully created.\n"
"# </computeroutput><userinput>pvdisplay -C\n"
"</userinput><computeroutput>  PV         VG Fmt  Attr PSize PFree\n"
"  /dev/sdb2     lvm2 ---  4.00g 4.00g\n"
"  /dev/sdc3     lvm2 ---  3.00g 3.00g\n"
"  /dev/sdd      lvm2 ---  4.00g 4.00g\n"
"  /dev/sdf1     lvm2 ---  4.00g 4.00g\n"
"  /dev/sdf2     lvm2 ---  5.00g 5.00g\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>pvcreate /dev/sdb2\n</userinput><computeroutput>  Physical volume \"/dev/sdb2\" successfully created.\n# </computeroutput><userinput>pvdisplay\n</userinput><computeroutput>  \"/dev/sdb2\" is a new physical volume of \"4.00 GiB\"\n  --- NEW Physical volume ---\n  PV Name               /dev/sdb2\n  VG Name               \n  PV Size               4.00 GiB\n  Allocatable           NO\n  PE Size               0   \n  Total PE              0\n  Free PE               0\n  Allocated PE          0\n  PV UUID               yK0K6K-clbc-wt6e-qk9o-aUh9-oQqC-k1T71B\n\n# </computeroutput><userinput>for i in sdc3 sdd sdf1 sdf2 ; do pvcreate /dev/$i ; done\n</userinput><computeroutput>  Physical volume \"/dev/sdc3\" successfully created.\n  Physical volume \"/dev/sdd\" successfully created.\n  Physical volume \"/dev/sdf1\" successfully created.\n  Physical volume \"/dev/sdf2\" successfully created.\n# </computeroutput><userinput>pvdisplay -C\n</userinput><computeroutput>  PV         VG Fmt  Attr PSize PFree\n  /dev/sdb2     lvm2 ---  4.00g 4.00g\n  /dev/sdc3     lvm2 ---  3.00g 3.00g\n  /dev/sdd      lvm2 ---  4.00g 4.00g\n  /dev/sdf1     lvm2 ---  4.00g 4.00g\n  /dev/sdf2     lvm2 ---  5.00g 5.00g\n</computeroutput>"

msgid "So far, so good; note that a PV can be set up on a full disk as well as on individual partitions of it. As shown above, the <command>pvdisplay</command> command lists the existing PVs, with two possible output formats."
msgstr "Finora tutto bene: notare che un PV può essere impostato su tutto un disco così come su singole partizioni. Come mostrato sopra, il comando <command>pvdisplay</command> elenca le PV esistenti, con due possibili formati di output."

msgid "<primary><command>vgcreate</command></primary>"
msgstr "<primary><command>vgcreate</command></primary>"

msgid "<primary><command>vgdisplay</command></primary>"
msgstr "<primary><command>vgdisplay</command></primary>"

msgid "Now let's assemble these physical elements into VGs using <command>vgcreate</command>. We'll gather only PVs from the fast disks into a <filename>vg_critical</filename> VG; the other VG, <filename>vg_normal</filename>, will also include slower elements."
msgstr "Ora si assemblano questi elementi fisici in VG usando <command>vgcreate</command>. Solo le PV dei dischi più veloci saranno riunite in un VG <filename>vg_critical</filename>; l'altro VG, <filename>vg_normal</filename>, includerà anche gli elementi più lenti."

msgid "<primary>LVM</primary><secondary>create VG</secondary>"
msgstr "<primary>LVM</primary><secondary>creazione VG</secondary>"

msgid ""
"<computeroutput># </computeroutput><userinput>vgcreate vg_critical /dev/sdb2 /dev/sdf1\n"
"</userinput><computeroutput>  Volume group \"vg_critical\" successfully created\n"
"# </computeroutput><userinput>vgdisplay\n"
"</userinput><computeroutput>  --- Volume group ---\n"
"  VG Name               vg_critical\n"
"  System ID             \n"
"  Format                lvm2\n"
"  Metadata Areas        2\n"
"  Metadata Sequence No  1\n"
"  VG Access             read/write\n"
"  VG Status             resizable\n"
"  MAX LV                0\n"
"  Cur LV                0\n"
"  Open LV               0\n"
"  Max PV                0\n"
"  Cur PV                2\n"
"  Act PV                2\n"
"  VG Size               7.99 GiB\n"
"  PE Size               4.00 MiB\n"
"  Total PE              2046\n"
"  Alloc PE / Size       0 / 0   \n"
"  Free  PE / Size       2046 / 7.99 GiB\n"
"  VG UUID               JgFWU3-emKg-9QA1-stPj-FkGX-mGFb-4kzy1G\n"
"\n"
"# </computeroutput><userinput>vgcreate vg_normal /dev/sdc3 /dev/sdd /dev/sdf2\n"
"</userinput><computeroutput>  Volume group \"vg_normal\" successfully created\n"
"# </computeroutput><userinput>vgdisplay -C\n"
"</userinput><computeroutput><![CDATA[  VG          #PV #LV #SN Attr   VSize   VFree  \n"
"  vg_critical   2   0   0 wz--n-   7.99g   7.99g\n"
"  vg_normal     3   0   0 wz--n- <11.99g <11.99g\n"
"]]></computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>vgcreate vg_critical /dev/sdb2 /dev/sdf1\n</userinput><computeroutput>  Volume group \"vg_critical\" successfully created\n# </computeroutput><userinput>vgdisplay\n</userinput><computeroutput>  --- Volume group ---\n  VG Name               vg_critical\n  System ID             \n  Format                lvm2\n  Metadata Areas        2\n  Metadata Sequence No  1\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                0\n  Open LV               0\n  Max PV                0\n  Cur PV                2\n  Act PV                2\n  VG Size               7.99 GiB\n  PE Size               4.00 MiB\n  Total PE              2046\n  Alloc PE / Size       0 / 0   \n  Free  PE / Size       2046 / 7.99 GiB\n  VG UUID               JgFWU3-emKg-9QA1-stPj-FkGX-mGFb-4kzy1G\n\n# </computeroutput><userinput>vgcreate vg_normal /dev/sdc3 /dev/sdd /dev/sdf2\n</userinput><computeroutput>  Volume group \"vg_normal\" successfully created\n# </computeroutput><userinput>vgdisplay -C\n</userinput><computeroutput><![CDATA[  VG          #PV #LV #SN Attr   VSize   VFree  \n  vg_critical   2   0   0 wz--n-   7.99g   7.99g\n  vg_normal     3   0   0 wz--n- <11.99g <11.99g\n]]></computeroutput>"

msgid "Here again, commands are rather straightforward (and <command>vgdisplay</command> proposes two output formats). Note that it is quite possible to use two partitions of the same physical disk into two different VGs. Note also that we used a <filename>vg_</filename> prefix to name our VGs, but it is nothing more than a convention."
msgstr "Anche qui, i comandi sono piuttosto semplici (e <command>vgdisplay</command> propone due formati di output). Notare che è possibile usare due partizioni dello stesso disco fisico in due diversi VG. Notare inoltre che si è usato un prefisso <filename>vg_</filename> per nominare i VG, ma non è altro che una convenzione."

msgid "We now have two “virtual disks”, sized about 8 GB and 12 GB respectively. Let's now carve them up into “virtual partitions” (LVs). This involves the <command>lvcreate</command> command, and a slightly more complex syntax:"
msgstr "Adesso ci sono due «dischi virtuali», della dimensione di circa 8 GB e 12 GB rispettivamente. Ora suddividiamoli in \"partizioni virtuali\" (LV). Ciò richiede l'uso del comando <command>lvcreate</command> ed una sintassi leggermente più complessa:"

msgid "<primary>LVM</primary><secondary>create LV</secondary>"
msgstr "<primary>LVM</primary><secondary>creazione LV</secondary>"

msgid "<primary><command>lvcreate</command></primary>"
msgstr "<primary><command>lvcreate</command></primary>"

msgid "<primary><command>lvdisplay</command></primary>"
msgstr "<primary><command>lvdisplay</command></primary>"

msgid ""
"<computeroutput># </computeroutput><userinput>lvdisplay\n"
"</userinput><computeroutput># </computeroutput><userinput>lvcreate -n lv_files -L 5G vg_critical\n"
"</userinput><computeroutput>  Logical volume \"lv_files\" created.\n"
"# </computeroutput><userinput>lvdisplay\n"
"</userinput><computeroutput>  --- Logical volume ---\n"
"  LV Path                /dev/vg_critical/lv_files\n"
"  LV Name                lv_files\n"
"  VG Name                vg_critical\n"
"  LV UUID                Nr62xe-Zu7d-0u3z-Yyyp-7Cj1-Ej2t-gw04Xd\n"
"  LV Write Access        read/write\n"
"  LV Creation host, time debian, 2022-03-01 00:17:46 +0100\n"
"  LV Status              available\n"
"  # open                 0\n"
"  LV Size                5.00 GiB\n"
"  Current LE             1280\n"
"  Segments               2\n"
"  Allocation             inherit\n"
"  Read ahead sectors     auto\n"
"  - currently set to     256\n"
"  Block device           253:0\n"
"\n"
"# </computeroutput><userinput>lvcreate -n lv_base -L 1G vg_critical\n"
"</userinput><computeroutput>  Logical volume \"lv_base\" created.\n"
"# </computeroutput><userinput>lvcreate -n lv_backups -L 11.98G vg_normal\n"
"</userinput><computeroutput>  Rounding up size to full physical extent 11.98 GiB\n"
"  Rounding up size to full physical extent 11.98 GiB\n"
"  Logical volume \"lv_backups\" created.\n"
"# </computeroutput><userinput>lvdisplay -C\n"
"</userinput><computeroutput>  LV         VG          Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert\n"
"  lv_base    vg_critical -wi-a-----  1.00g                                                    \n"
"  lv_files   vg_critical -wi-a-----  5.00g                                                    \n"
"  lv_backups vg_normal   -wi-a----- 11.98g             \n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>lvdisplay\n</userinput><computeroutput># </computeroutput><userinput>lvcreate -n lv_files -L 5G vg_critical\n</userinput><computeroutput>  Logical volume \"lv_files\" created.\n# </computeroutput><userinput>lvdisplay\n</userinput><computeroutput>  --- Logical volume ---\n  LV Path                /dev/vg_critical/lv_files\n  LV Name                lv_files\n  VG Name                vg_critical\n  LV UUID                Nr62xe-Zu7d-0u3z-Yyyp-7Cj1-Ej2t-gw04Xd\n  LV Write Access        read/write\n  LV Creation host, time debian, 2022-03-01 00:17:46 +0100\n  LV Status              available\n  # open                 0\n  LV Size                5.00 GiB\n  Current LE             1280\n  Segments               2\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           253:0\n\n# </computeroutput><userinput>lvcreate -n lv_base -L 1G vg_critical\n</userinput><computeroutput>  Logical volume \"lv_base\" created.\n# </computeroutput><userinput>lvcreate -n lv_backups -L 11.98G vg_normal\n</userinput><computeroutput>  Rounding up size to full physical extent 11.98 GiB\n  Rounding up size to full physical extent 11.98 GiB\n  Logical volume \"lv_backups\" created.\n# </computeroutput><userinput>lvdisplay -C\n</userinput><computeroutput>  LV         VG          Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert\n  lv_base    vg_critical -wi-a-----  1.00g                                                    \n  lv_files   vg_critical -wi-a-----  5.00g                                                    \n  lv_backups vg_normal   -wi-a----- 11.98g             \n</computeroutput>"

msgid "Two parameters are required when creating logical volumes; they must be passed to the <command>lvcreate</command> as options. The name of the LV to be created is specified with the <literal>-n</literal> option, and its size is generally given using the <literal>-L</literal> option. We also need to tell the command what VG to operate on, of course, hence the last parameter on the command line."
msgstr "La creazione di volumi logici richiede due parametri che devono essere passati come opzioni al comando <command>lvcreate</command>. Il nome dei LV da creare viene specificato con l'opzione <literal>-n</literal> e la sua dimensione viene generalmente data usando l'opzione <literal>-L</literal>. Ovviamente bisogna anche dire al comando su quale VG operare, da cui l'ultimo parametro sulla riga di comando."

msgid "<emphasis>GOING FURTHER</emphasis> <command>lvcreate</command> options"
msgstr "<emphasis>APPROFONDIMENTO</emphasis> Opzioni di <command>lvcreate</command>"

msgid "The <command>lvcreate</command> command has several options to allow tweaking how the LV is created."
msgstr "Il comando <command>lvcreate</command> ha diverse opzioni per poter specificare i dettagli della creazione del LV."

msgid "Let's first describe the <literal>-l</literal> option, with which the LV's size can be given as a number of blocks (as opposed to the “human” units we used above). These blocks (called PEs, <emphasis>physical extents</emphasis>, in LVM terms) are contiguous units of storage space in PVs, and they can't be split across LVs. When one wants to define storage space for an LV with some precision, for instance to use the full available space, the <literal>-l</literal> option will probably be preferred over <literal>-L</literal>."
msgstr "Prima si descrive l'opzione <literal>-l</literal>, con cui si può specificare la dimensione del LV come numero di blocchi (invece delle unità «umane» usate sopra). Questi blocchi (chiamati PE, <emphasis>physical extents</emphasis>, estensioni fisiche, in termini LVM) sono unità contigue di spazio di memorizzazione e non possono essere divisi fra più LV. Quando si vuol definire lo spazio di memorizzazione con una certa precisione¸per esempio per usare tutto lo spazio disponibile, probabilmente è meglio usare l'opzione <literal>-l</literal> piuttosto che <literal>-L</literal>."

msgid "It is also possible to hint at the physical location of an LV, so that its extents are stored on a particular PV (while staying within the ones assigned to the VG, of course). Since we know that <filename>sdb</filename> is faster than <filename>sdf</filename>, we may want to store the <filename>lv_base</filename> there if we want to give an advantage to the database server compared to the file server. The command line becomes: <command>lvcreate -n lv_base -L 1G vg_critical /dev/sdb2</command>. Note that this command can fail if the PV doesn't have enough free extents. In our example, we would probably have to create <filename>lv_base</filename> before <filename>lv_files</filename> to avoid this situation – or free up some space on <filename>sdb2</filename> with the <command>pvmove</command> command."
msgstr "È inoltre possibile suggerire la posizione fisica di un LV, cosicché le sue estensioni siano memorizzate su un particolare PV (ovviamente rimanendo all'interno di quelli assegnati al VG). Poiché è risaputo che <filename>sdb</filename> è più veloce di <filename>sdf</filename>, è meglio memorizzare lì <filename>lv_base</filename> se si vuol dare un vantaggio al server di database rispetto al file server. La riga di comando diventa: <command>lvcreate -n lv_base -L 1G vg_critical /dev/sdb2</command>. Notare che questo comando può fallire se il PV non ha abbastanza estensioni libere. Nell'esempio, per evitare questa situazione, probabilmente si deve creare <filename>lv_base</filename> prima di <filename>lv_files</filename> o liberare spazio su <filename>sdb2</filename> con il comando <command>pvmove</command>."

msgid "<primary><command>pvmove</command></primary>"
msgstr "<primary><command>pvmove</command></primary>"

msgid "Logical volumes, once created, end up as block device files in <filename>/dev/mapper/</filename>:"
msgstr "Una volta creati, i volumi logici si trovano come file di device a blocchi in <filename>/dev/mapper/</filename>:"

msgid "<primary><filename>/dev</filename></primary><secondary><filename>/dev/mapper/</filename></secondary>"
msgstr "<primary><filename>/dev</filename></primary><secondary><filename>/dev/mapper/</filename></secondary>"

msgid "<primary>device</primary><secondary>block</secondary>"
msgstr "<primary>dispositivo</primary><secondary>blocco</secondary>"

msgid ""
"<computeroutput># </computeroutput><userinput>ls -l /dev/mapper\n"
"</userinput><computeroutput><![CDATA[total 0\n"
"crw------- 1 root root 10, 236 Mar  1 00:17 control\n"
"lrwxrwxrwx 1 root root       7 Mar  1 00:19 vg_critical-lv_base -> ../dm-1\n"
"lrwxrwxrwx 1 root root       7 Mar  1 00:17 vg_critical-lv_files -> ../dm-0\n"
"lrwxrwxrwx 1 root root       7 Mar  1 00:19 vg_normal-lv_backups -> ../dm-2 ]]>\n"
"# </computeroutput><userinput>ls -l /dev/dm-*\n"
"</userinput><computeroutput>brw-rw---- 1 root disk 253, 0 Mar  1 00:17 /dev/dm-0\n"
"brw-rw---- 1 root disk 253, 1 Mar  1 00:19 /dev/dm-1\n"
"brw-rw---- 1 root disk 253, 2 Mar  1 00:19 /dev/dm-2\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>ls -l /dev/mapper\n</userinput><computeroutput><![CDATA[total 0\ncrw------- 1 root root 10, 236 Mar  1 00:17 control\nlrwxrwxrwx 1 root root       7 Mar  1 00:19 vg_critical-lv_base -> ../dm-1\nlrwxrwxrwx 1 root root       7 Mar  1 00:17 vg_critical-lv_files -> ../dm-0\nlrwxrwxrwx 1 root root       7 Mar  1 00:19 vg_normal-lv_backups -> ../dm-2 ]]>\n# </computeroutput><userinput>ls -l /dev/dm-*\n</userinput><computeroutput>brw-rw---- 1 root disk 253, 0 Mar  1 00:17 /dev/dm-0\nbrw-rw---- 1 root disk 253, 1 Mar  1 00:19 /dev/dm-1\nbrw-rw---- 1 root disk 253, 2 Mar  1 00:19 /dev/dm-2\n</computeroutput>"

msgid "<emphasis>NOTE</emphasis> Auto-detecting LVM volumes"
msgstr "<emphasis>NOTA</emphasis> Rilevamento automatico di volumi LVM"

msgid "<primary>service</primary><secondary><filename>lvm2-activation.service</filename></secondary>"
msgstr "<primary>servizio</primary><secondary><filename>lvm2-activation.service</filename></secondary>"

msgid "<primary><command>vgchange</command></primary>"
msgstr "<primary><command>vgchange</command></primary>"

msgid "When the computer boots, the <filename>lvm2-activation</filename> systemd service unit executes <command>vgchange -aay</command> to “activate” the volume groups: it scans the available devices; those that have been initialized as physical volumes for LVM are registered into the LVM subsystem, those that belong to volume groups are assembled, and the relevant logical volumes are started and made available. There is therefore no need to edit configuration files when creating or modifying LVM volumes."
msgstr "All'avvio del computer, l'unità di servizio di systemd <filename>lvm2-activation</filename> esegue <command>vgchange -aay</command> per \"attivare\" i gruppi di volumi: passa in rassegna i device disponibili; quelli che sono stati inizializzati come volumi fisici per LVM sono registrati nel sottosistema LVM, quelli che appartengono a gruppi di volume vengono assemblati e i relativi volumi logici vengono avviati e resi disponibili. Non c'è quindi bisogno di modificare file di configurazione quando si creano o si modificano volumi LVM."

msgid "Note, however, that the layout of the LVM elements (physical and logical volumes, and volume groups) is backed up in <filename>/etc/lvm/backup</filename>, which can be useful in case of a problem (or just to sneak a peek under the hood)."
msgstr "Notare, tuttavia, che la disposizione degli elementi LVM (volumi fisici e logici e gruppi di volume) viene replicata in <filename>/etc/lvm/backup</filename>, che può essere utile in caso di problemi (o solo per dare un'occhiata a cosa succede)."

msgid "<primary><filename>/etc</filename></primary><secondary><filename>/etc/lvm/backup</filename></secondary>"
msgstr "<primary><filename>/etc</filename></primary><secondary><filename>/etc/lvm/backup</filename></secondary>"

msgid "To make things easier, convenience symbolic links are also created in directories matching the VGs:"
msgstr "Per facilitare le cose, vengono inoltre creati dei comodi collegamenti simbolici in directory corrispondenti ai VG:"

msgid ""
"<computeroutput># </computeroutput><userinput>ls -l /dev/vg_critical\n"
"</userinput><computeroutput><![CDATA[total 0\n"
"lrwxrwxrwx 1 root root 7 Mar  1 00:19 lv_base -> ../dm-1\n"
"lrwxrwxrwx 1 root root 7 Mar  1 00:17 lv_files -> ../dm-0 ]]>\n"
"# </computeroutput><userinput>ls -l /dev/vg_normal\n"
"</userinput><computeroutput><![CDATA[total 0\n"
"lrwxrwxrwx 1 root root 7 Mar  1 00:19 lv_backups -> ../dm-2 ]]>\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>ls -l /dev/vg_critical\n</userinput><computeroutput><![CDATA[total 0\nlrwxrwxrwx 1 root root 7 Mar  1 00:19 lv_base -> ../dm-1\nlrwxrwxrwx 1 root root 7 Mar  1 00:17 lv_files -> ../dm-0 ]]>\n# </computeroutput><userinput>ls -l /dev/vg_normal\n</userinput><computeroutput><![CDATA[total 0\nlrwxrwxrwx 1 root root 7 Mar  1 00:19 lv_backups -> ../dm-2 ]]>\n</computeroutput>"

msgid "The LVs can then be used exactly like standard partitions:"
msgstr "I LV possono quindi essere usati esattamente come normali partizioni:"

msgid ""
"<computeroutput># </computeroutput><userinput>mkfs.ext4 /dev/vg_normal/lv_backups\n"
"</userinput><computeroutput>mke2fs 1.46.2 (28-Feb-2021)\n"
"Discarding device blocks: done                            \n"
"Creating filesystem with 3140608 4k blocks and 786432 inodes\n"
"Filesystem UUID: 7eaf0340-b740-421e-96b2-942cdbf29cb3\n"
"Superblock backups stored on blocks: \n"
"\t32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208\n"
"\n"
"Allocating group tables: done                            \n"
"Writing inode tables: done                            \n"
"Creating journal (16384 blocks): done\n"
"Writing superblocks and filesystem accounting information: done \n"
"\n"
"# </computeroutput><userinput>mkdir /srv/backups\n"
"</userinput><computeroutput># </computeroutput><userinput>mount /dev/vg_normal/lv_backups /srv/backups\n"
"</userinput><computeroutput># </computeroutput><userinput>df -h /srv/backups\n"
"</userinput><computeroutput>Filesystem                        Size  Used Avail Use% Mounted on\n"
"/dev/mapper/vg_normal-lv_backups   12G   24K   12G   1% /srv/backups\n"
"# </computeroutput><userinput>[...]\n"
"</userinput><computeroutput>[...]\n"
"# </computeroutput><userinput>cat /etc/fstab\n"
"</userinput><computeroutput>[...]\n"
"/dev/vg_critical/lv_base    /srv/base       ext4 defaults 0 2\n"
"/dev/vg_critical/lv_files   /srv/files      ext4 defaults 0 2\n"
"/dev/vg_normal/lv_backups   /srv/backups    ext4 defaults 0 2\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>mkfs.ext4 /dev/vg_normal/lv_backups\n</userinput><computeroutput>mke2fs 1.46.2 (28-Feb-2021)\nDiscarding device blocks: done                            \nCreating filesystem with 3140608 4k blocks and 786432 inodes\nFilesystem UUID: 7eaf0340-b740-421e-96b2-942cdbf29cb3\nSuperblock backups stored on blocks: \n\t32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208\n\nAllocating group tables: done                            \nWriting inode tables: done                            \nCreating journal (16384 blocks): done\nWriting superblocks and filesystem accounting information: done \n\n# </computeroutput><userinput>mkdir /srv/backups\n</userinput><computeroutput># </computeroutput><userinput>mount /dev/vg_normal/lv_backups /srv/backups\n</userinput><computeroutput># </computeroutput><userinput>df -h /srv/backups\n</userinput><computeroutput>Filesystem                        Size  Used Avail Use% Mounted on\n/dev/mapper/vg_normal-lv_backups   12G   24K   12G   1% /srv/backups\n# </computeroutput><userinput>[...]\n</userinput><computeroutput>[...]\n# </computeroutput><userinput>cat /etc/fstab\n</userinput><computeroutput>[...]\n/dev/vg_critical/lv_base    /srv/base       ext4 defaults 0 2\n/dev/vg_critical/lv_files   /srv/files      ext4 defaults 0 2\n/dev/vg_normal/lv_backups   /srv/backups    ext4 defaults 0 2\n</computeroutput>"

msgid "From the applications' point of view, the myriad small partitions have now been abstracted into one large 12 GB volume, with a friendlier name."
msgstr "Dal punto di vista delle applicazioni, la miriade di piccole partizioni è stata ora astratta in un grande volume di 12 GB con un nome più familiare."

msgid "LVM Over Time"
msgstr "LVM nel tempo"

msgid "<primary><command>lvresize</command></primary>"
msgstr "<primary><command>lvresize</command></primary>"

msgid "<primary><command>resize2fs</command></primary>"
msgstr "<primary><command>resize2fs</command></primary>"

msgid "<primary>volume</primary><secondary>resize</secondary>"
msgstr "<primary>volume</primary><secondary>ridimensionamento</secondary>"

msgid "<primary>LVM</primary><secondary>resize LV</secondary>"
msgstr "<primary>LVM</primary><secondary>ridimensionamento LV</secondary>"

msgid "Even though the ability to aggregate partitions or physical disks is convenient, this is not the main advantage brought by LVM. The flexibility it brings is especially noticed as time passes, when needs evolve. In our example, let's assume that new large files must be stored, and that the LV dedicated to the file server is too small to contain them. Since we haven't used the whole space available in <filename>vg_critical</filename>, we can grow <filename>lv_files</filename>. For that purpose, we'll use the <command>lvresize</command> command, then <command>resize2fs</command> to adapt the filesystem accordingly:"
msgstr "Anche se la capacità di aggregare partizioni o dischi fisici è comoda, questo non è il vantaggio principale di LVM. La sua flessibilità si nota soprattutto col passare del tempo, quando le necessità evolvono. Nell'esempio, si supponga di dover memorizzare dei nuovi grandi file e che il LV dedicato al file server sia troppo piccolo per contenerli. Poiché non si è usato tutto lo spazio disponibile in <filename>vg_critical</filename>, si può espandere <filename>lv_files</filename>. A questo scopo, si usa il comando <command>lvresize</command>, quindi <command>resize2fs</command> per adattare il file system di conseguenza:"

msgid ""
"<computeroutput># </computeroutput><userinput>df -h /srv/files/\n"
"</userinput><computeroutput>Filesystem                        Size  Used Avail Use% Mounted on\n"
"/dev/mapper/vg_critical-lv_files  4.9G  4.2G  485M  90% /srv/files\n"
"# </computeroutput><userinput>lvdisplay -C vg_critical/lv_files\n"
"</userinput><computeroutput>  LV       VG          Attr       LSize Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert\n"
"  lv_files vg_critical -wi-ao---- 5.00g                                                    \n"
"# </computeroutput><userinput>vgdisplay -C vg_critical\n"
"</userinput><computeroutput>  VG          #PV #LV #SN Attr   VSize VFree\n"
"  vg_critical   2   2   0 wz--n- 7.99g 1.99g\n"
"# </computeroutput><userinput>lvresize -L 6G vg_critical/lv_files\n"
"</userinput><computeroutput>  Size of logical volume vg_critical/lv_files changed from 5.00 GiB (1280 extents) to 6.00 GiB (1536 extents).\n"
"  Logical volume vg_critical/lv_files successfully resized.\n"
"# </computeroutput><userinput>lvdisplay -C vg_critical/lv_files\n"
"</userinput><computeroutput>  LV       VG          Attr       LSize Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert\n"
"  lv_files vg_critical -wi-ao---- 6.00g                                                    \n"
"# </computeroutput><userinput>resize2fs /dev/vg_critical/lv_files\n"
"</userinput><computeroutput>resize2fs 1.46.2 (28-Feb-2021)\n"
"Filesystem at /dev/vg_critical/lv_files is mounted on /srv/files; on-line resizing required\n"
"old_desc_blocks = 1, new_desc_blocks = 1\n"
"The filesystem on /dev/vg_critical/lv_files is now 1572864 (4k) blocks long.\n"
"\n"
"# </computeroutput><userinput>df -h /srv/files/\n"
"</userinput><computeroutput>Filesystem                        Size  Used Avail Use% Mounted on\n"
"/dev/mapper/vg_critical-lv_files  5.9G  4.2G  1.5G  75% /srv/files\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>df -h /srv/files/\n</userinput><computeroutput>Filesystem                        Size  Used Avail Use% Mounted on\n/dev/mapper/vg_critical-lv_files  4.9G  4.2G  485M  90% /srv/files\n# </computeroutput><userinput>lvdisplay -C vg_critical/lv_files\n</userinput><computeroutput>  LV       VG          Attr       LSize Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert\n  lv_files vg_critical -wi-ao---- 5.00g                                                    \n# </computeroutput><userinput>vgdisplay -C vg_critical\n</userinput><computeroutput>  VG          #PV #LV #SN Attr   VSize VFree\n  vg_critical   2   2   0 wz--n- 7.99g 1.99g\n# </computeroutput><userinput>lvresize -L 6G vg_critical/lv_files\n</userinput><computeroutput>  Size of logical volume vg_critical/lv_files changed from 5.00 GiB (1280 extents) to 6.00 GiB (1536 extents).\n  Logical volume vg_critical/lv_files successfully resized.\n# </computeroutput><userinput>lvdisplay -C vg_critical/lv_files\n</userinput><computeroutput>  LV       VG          Attr       LSize Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert\n  lv_files vg_critical -wi-ao---- 6.00g                                                    \n# </computeroutput><userinput>resize2fs /dev/vg_critical/lv_files\n</userinput><computeroutput>resize2fs 1.46.2 (28-Feb-2021)\nFilesystem at /dev/vg_critical/lv_files is mounted on /srv/files; on-line resizing required\nold_desc_blocks = 1, new_desc_blocks = 1\nThe filesystem on /dev/vg_critical/lv_files is now 1572864 (4k) blocks long.\n\n# </computeroutput><userinput>df -h /srv/files/\n</userinput><computeroutput>Filesystem                        Size  Used Avail Use% Mounted on\n/dev/mapper/vg_critical-lv_files  5.9G  4.2G  1.5G  75% /srv/files\n</computeroutput>"

msgid "<emphasis>CAUTION</emphasis> Resizing filesystems"
msgstr "<emphasis>ATTENZIONE</emphasis> Ridimensionare i file system"

msgid "<primary>filesystem</primary><secondary>resize</secondary>"
msgstr "<primary>filesystem</primary><secondary>ridimensionamento</secondary>"

msgid "Not all filesystems can be resized online; resizing a volume can therefore require unmounting the filesystem first and remounting it afterwards. Of course, if one wants to shrink the space allocated to an LV, the filesystem must be shrunk first; the order is reversed when the resizing goes in the other direction: the logical volume must be grown before the filesystem on it. It is rather straightforward, since at no time must the filesystem size be larger than the block device where it resides (whether that device is a physical partition or a logical volume)."
msgstr "Non tutti i filesystem si possono ridimensionare a caldo; per ridimensionare un volume può quindi essere necessario smontare il filesystem e rimontarlo in seguito. Ovviamente, se si vuole restringere lo spazio allocato a un LV, bisogna prima restringere il filesystem; l'ordine è invertito quando il ridimensionamento è al contrario: il volume logico deve essere allargato prima del filesystem che c'è sopra. È piuttosto semplice, dal momento che la dimensione del filesystem non deve mai essere superiore a quella del dispositivo a blocchi dove risiede (che quel dispositivo sia una partizione fisica o un volume logico)."

msgid "The ext3, ext4 and xfs filesystems can be grown online, without unmounting; shrinking requires an unmount. The reiserfs filesystem allows online resizing in both directions. The venerable ext2 allows neither, and always requires unmounting."
msgstr "I file system ext3, ext4 e xfs possono essere allargati a caldo, senza smontarli; per restringerli vanno invece smontati. Il file system reiserfs permette il ridimensionamento a caldo in entrambe le direzioni. Il buon vecchio ext2 non permette alcuna delle due cose e richiede sempre di essere smontato."

msgid "We could proceed in a similar fashion to extend the volume hosting the database, only we've reached the VG's available space limit:"
msgstr "Si potrebbe procedere in modo simile per estendere il volume che ospita il database, ma è stato raggiunto il limite di spazio disponibile del VG:"

msgid ""
"<computeroutput># </computeroutput><userinput>df -h /srv/base/\n"
"</userinput><computeroutput>Filesystem                       Size  Used Avail Use% Mounted on\n"
"/dev/mapper/vg_critical-lv_base  974M  883M   25M  98% /srv/base\n"
"# </computeroutput><userinput>vgdisplay -C vg_critical\n"
"</userinput><computeroutput>  VG          #PV #LV #SN Attr   VSize VFree   \n"
"  vg_critical   2   2   0 wz--n- 7.99g 1016.00m\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>df -h /srv/base/\n</userinput><computeroutput>Filesystem                       Size  Used Avail Use% Mounted on\n/dev/mapper/vg_critical-lv_base  974M  883M   25M  98% /srv/base\n# </computeroutput><userinput>vgdisplay -C vg_critical\n</userinput><computeroutput>  VG          #PV #LV #SN Attr   VSize VFree   \n  vg_critical   2   2   0 wz--n- 7.99g 1016.00m\n</computeroutput>"

msgid "No matter, since LVM allows adding physical volumes to existing volume groups. For instance, maybe we've noticed that the <filename>sdb3</filename> partition, which was so far used outside of LVM, only contained archives that could be moved to <filename>lv_backups</filename>. We can now recycle it and integrate it to the volume group, and thereby reclaim some available space. This is the purpose of the <command>vgextend</command> command. Of course, the partition must be prepared as a physical volume beforehand. Once the VG has been extended, we can use similar commands as previously to grow the logical volume then the filesystem:"
msgstr "Questo non è un problema, dal momento che LVM permette di aggiungere volumi fisici a gruppi di volume esistenti. Per esempio, si può notare che la partizione <filename>sdb3</filename>, che finora era stata usata al di fuori di LVM, conteneva solo archivi che potrebbero essere spostati su <filename>lv_backups</filename>. La si può quindi riciclare e integrare nel gruppo di volume, liberando così dello spazio utilizzabile. Questo è lo scopo del comando <command>vgextend</command>. Ovviamente la partizione deve essere preparata in precedenza come volume fisico. Una volta che il VG è stato esteso, possiamo usare comandi simili ai precedenti per espandere il volume logico e poi il filesystem:"

msgid ""
"<computeroutput># </computeroutput><userinput>pvcreate /dev/sdb3\n"
"</userinput><computeroutput>  Physical volume \"/dev/sdb3\" successfully created.\n"
"# </computeroutput><userinput>vgextend vg_critical /dev/sdb3\n"
"</userinput><computeroutput>  Volume group \"vg_critical\" successfully extended\n"
"# </computeroutput><userinput>vgdisplay -C vg_critical\n"
"</userinput><computeroutput><![CDATA[  VG          #PV #LV #SN Attr   VSize   VFree \n"
"  vg_critical   3   2   0 wz--n- <12.99g <5.99g ]]>\n"
"# </computeroutput><userinput>lvresize -L 2G vg_critical/lv_base\n"
"</userinput><computeroutput>[...]\n"
"# </computeroutput><userinput>resize2fs /dev/vg_critical/lv_base\n"
"</userinput><computeroutput>[...]\n"
"# </computeroutput><userinput>df -h /srv/base/\n"
"</userinput><computeroutput>Filesystem                       Size  Used Avail Use% Mounted on\n"
"/dev/mapper/vg_critical-lv_base  2.0G  886M  991M  48% /srv/base\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>pvcreate /dev/sdb3\n</userinput><computeroutput>  Physical volume \"/dev/sdb3\" successfully created.\n# </computeroutput><userinput>vgextend vg_critical /dev/sdb3\n</userinput><computeroutput>  Volume group \"vg_critical\" successfully extended\n# </computeroutput><userinput>vgdisplay -C vg_critical\n</userinput><computeroutput><![CDATA[  VG          #PV #LV #SN Attr   VSize   VFree \n  vg_critical   3   2   0 wz--n- <12.99g <5.99g ]]>\n# </computeroutput><userinput>lvresize -L 2G vg_critical/lv_base\n</userinput><computeroutput>[...]\n# </computeroutput><userinput>resize2fs /dev/vg_critical/lv_base\n</userinput><computeroutput>[...]\n# </computeroutput><userinput>df -h /srv/base/\n</userinput><computeroutput>Filesystem                       Size  Used Avail Use% Mounted on\n/dev/mapper/vg_critical-lv_base  2.0G  886M  991M  48% /srv/base\n</computeroutput>"

msgid "<emphasis>GOING FURTHER</emphasis> Advanced LVM"
msgstr "<emphasis>APPROFONDIMENTO</emphasis> LVM avanzato"

msgid "LVM also caters for more advanced uses, where many details can be specified by hand. For instance, an administrator can tweak the size of the blocks that make up physical and logical volumes, as well as their physical layout. It is also possible to move blocks across PVs, for instance, to fine-tune performance or, in a more mundane way, to free a PV when one needs to extract the corresponding physical disk from the VG (whether to affect it to another VG or to remove it from LVM altogether). The manual pages describing the commands are generally clear and detailed. A good entry point is the <citerefentry><refentrytitle>lvm</refentrytitle> <manvolnum>8</manvolnum></citerefentry> manual page."
msgstr "LVM soddisfa anche necessità più avanzate, dove molti dettagli si possono specificare a mano. Per esempio, un amministratore può regolare la dimensione dei blocchi che compongono i volumi fisici e logici, oltre alla loro disposizione fisica. È anche possibile spostare i blocchi fra i vari PV, per esempio per affinare le prestazioni o, in modo più banale, per liberare un PV quando si deve estrarre il corrispondente disco fisico dal VG (per spostarlo su un altro VG o per rimuoverlo del tutto dal LVM). Le pagine di manuale che descrivono i comandi sono di solito chiare e dettagliate. Un buon punto di partenza è la pagina di manuale <citerefentry><refentrytitle>lvm</refentrytitle> <manvolnum>8</manvolnum></citerefentry>."

msgid "RAID or LVM?"
msgstr "RAID o LVM?"

msgid "RAID and LVM both bring indisputable advantages as soon as one leaves the simple case of a desktop computer with a single hard disk where the usage pattern doesn't change over time. However, RAID and LVM go in two different directions, with diverging goals, and it is legitimate to wonder which one should be adopted. The most appropriate answer will of course depend on current and foreseeable requirements."
msgstr "RAID e LVM portano entrambi indiscutibili vantaggi quando si abbandona il caso semplice di un computer desktop con un solo disco fisso in cui il modello d'uso non cambia nel tempo. Tuttavia, RAID e LVM vanno in due direzioni differenti, con scopi distinti ed è giusto chiedersi quale dei due adottare. La risposta più appropriata ovviamente dipenderà dai requisiti attuali e da quelli prevedibili in futuro."

msgid "There are a few simple cases where the question doesn't really arise. If the requirement is to safeguard data against hardware failures, then obviously RAID will be set up on a redundant array of disks, since LVM doesn't really address this problem. If, on the other hand, the need is for a flexible storage scheme where the volumes are made independent of the physical layout of the disks, RAID doesn't help much and LVM will be the natural choice."
msgstr "Ci sono alcuni casi semplici in cui il problema non si pone. Se il requisito è di salvaguardare i dati da guasti hardware, allora ovviamente si configurerà RAID su un array ridondante di dischi, in quanto LVM non risolve questo problema. Se, d'altro canto, c'è bisogno di uno schema flessibile per memorizzare dati dove i volumi siano indipendenti dalla disposizione fisica dei dischi, il RAID non è molto d'aiuto e LVM è la scelta naturale."

msgid "<emphasis>NOTE</emphasis> If performance matters…"
msgstr "<emphasis>NOTA</emphasis> Se importanto le performance…"

msgid "<primary>SSD</primary>"
msgstr "<primary>SSD</primary>"

msgid "<primary>Solid State Drives</primary><see>SSD</see>"
msgstr "<primary>Solid State Drives (dispositivi a stato solido)</primary><see>SSD</see>"

msgid "If input/output speed is of the essence, especially in terms of access times, using LVM and/or RAID in one of the many combinations may have some impact on performances, and this may influence decisions as to which to pick. However, these differences in performance are really minor, and will only be measurable in a few use cases. If performance matters, the best gain to be obtained would be to use non-rotating storage media (<emphasis>solid-state drives</emphasis> or SSDs); their cost per megabyte is higher than that of standard hard disk drives, and their capacity is usually smaller, but they provide excellent performance for random accesses. If the usage pattern includes many input/output operations scattered all around the filesystem, for instance for databases where complex queries are routinely being run, then the advantage of running them on an SSD far outweigh whatever could be gained by picking LVM over RAID or the reverse. In these situations, the choice should be determined by other considerations than pure speed, since the performance aspect is most easily handled by using SSDs."
msgstr "Se la velocità di input/output è essenziale, soprattutto in termini di tempi di accesso, l'utilizzo di LVM e/o RAID in uno delle tante combinazioni può avere un certo impatto sulle prestazioni, e questo può influenzare le decisioni su quale per scegliere. Tuttavia, queste differenze di prestazioni sono molto minori, e saranno misurabili solo in pochi casi di utilizzo. Se si cercano maggiori performance, il miglior modo per ottenerle sarebbe quello di utilizzare supporti di memorizzazione non-rotanti (<emphasis>solid-state drives</emphasis> o SSDs); il costo per megabyte è superiore a quello degli hard disk standard, e la loro capacità è di solito più piccola, ma forniscono prestazioni eccellenti per accessi casuali. Se il modello di utilizzo include molte operazioni di input/output sparse in tutto il filesystem, ad esempio per i database in cui sono regolarmente in esecuzione query complesse, allora il vantaggio di una loro esecuzione su un SSD supera di gran lunga qualunque cosa si potrebbe avere scegliendo LVM su RAID o il contrario. In queste situazioni, la scelta dovrebbe essere determinata da altre considerazioni più che dalla velocità pura, dal momento che l'aspetto delle prestazioni è più facilmente gestitibile utilizzando gli SSD."

msgid "The third notable use case is when one just wants to aggregate two disks into one volume, either for performance reasons or to have a single filesystem that is larger than any of the available disks. This case can be addressed both by a RAID-0 (or even linear-RAID) and by an LVM volume. When in this situation, and barring extra constraints (for instance, keeping in line with the rest of the computers if they only use RAID), the configuration of choice will often be LVM. The initial set up is barely more complex, and that slight increase in complexity more than makes up for the extra flexibility that LVM brings if the requirements change or if new disks need to be added."
msgstr "Il terzo importante caso d'uso è quando si vuole semplicemente aggregare due dischi in un unico volume, per motivi di prestazioni o per avere un unico file system più grande di qualunque disco disponibile. Questo caso può essere affrontato sia utilizzando un RAID-0 (o addirittura un linear-RAID) sia tramite un volume LVM. In questa situazione, senza considerare ulteriori vincoli (per esempio, mantenere la coerenza con altre macchine se queste usano solo RAID), la configurazione preferita di solito sarà LVM. L'impostazione iniziale è appena più complessa, ma questo leggero aumento di complessità è più che compensato dall'aumentata flessibilità di LVM nel caso i requisiti cambiassero o si dovessero aggiungere nuovi dischi."

msgid "Then of course, there is the really interesting use case, where the storage system needs to be made both resistant to hardware failure and flexible when it comes to volume allocation. Neither RAID nor LVM can address both requirements on their own; no matter, this is where we use both at the same time — or rather, one on top of the other. The scheme that has all but become a standard since RAID and LVM have reached maturity is to ensure data redundancy first by grouping disks in a small number of large RAID arrays, and to use these RAID arrays as LVM physical volumes; logical partitions will then be carved from these LVs for filesystems. The selling point of this setup is that when a disk fails, only a small number of RAID arrays will need to be reconstructed, thereby limiting the time spent by the administrator for recovery."
msgstr "Poi, ovviamente, c'è il caso d'uso veramente interessante, in cui il sistema di memorizzazione deve essere reso sia resistente ai guasti hardware sia flessibile in termini di allocazione di volumi. Né RAID né LVM possono di per sé soddisfare entrambi i requisiti; ciò non è un problema, perché qui si possono usare entrambi contemporaneamente, o piuttosto, uno sopra l'altro. Lo schema che è diventato lo standard da quando RAID e LVM hanno raggiunto la maturità è di assicurare prima di tutto la ridondanza dei dati raggruppando i dischi in un piccolo numero di array RAID e usare questi array RAID come volumi fisici LVM; a questo punto si creano i file system tramite partizioni logiche all'interno di questi LV. Il punto di forza di questa impostazione è che quando un disco si guasta si deve ricostruire solo un piccolo numero di array RAID, limitando così il tempo speso dall'amministratore per il ripristino."

msgid "Let's take a concrete example: the public relations department at Falcot Corp needs a workstation for video editing, but the department's budget doesn't allow investing in high-end hardware from the bottom up. A decision is made to favor the hardware that is specific to the graphic nature of the work (monitor and video card), and to stay with generic hardware for storage. However, as is widely known, digital video does have some particular requirements for its storage: the amount of data to store is large, and the throughput rate for reading and writing this data is important for the overall system performance (more than typical access time, for instance). These constraints need to be fulfilled with generic hardware, in this case two 300 GB SATA hard disk drives; the system data must also be made resistant to hardware failure, as well as some of the user data. Edited video clips must indeed be safe, but video rushes pending editing are less critical, since they're still on the videotapes."
msgstr "Si faccia un esempio concreto: il dipartimento di pubbliche relazioni alla Falcot Corp ha bisogno di una postazione di lavoro per l'editing video, ma il bilancio del dipartimento non permette di investire in hardware di fascia alta per tutti i componenti. Si prende la decisione di favorire l'hardware specifico per la natura grafica del lavoro (monitor e scheda video) e di rimanere con hardware generico per quanto riguarda la memorizzazione dei dati. Tuttavia, come è ben noto, il video digitale ha dei requisiti particolari per la memorizzazione dei suoi dati: la quantità di dati da memorizzare è grande e il tasso di throughput per leggere e scrivere questi dati è importante per le prestazioni globali del sistema (più del tipico tempo di accesso, per esempio). Questi vincoli devono essere soddisfatti con hardware generico, in questo caso due dischi SATA da 300 GB; i dati del sistema devono inoltre essere resi resistenti ai guasti hardware, così come parte dei dati degli utenti. I video elaborati devono infatti essere al sicuro, ma i provini durante le modifiche sono meno critici, in quanto sono ancora sui nastri."

msgid "RAID-1 and LVM are combined to satisfy these constraints. The disks are attached to two different SATA controllers to optimize parallel access and reduce the risk of a simultaneous failure, and they therefore appear as <filename>sda</filename> and <filename>sdc</filename>. They are partitioned identically along the following scheme:"
msgstr "RAID-1 e LVM vengono combinati per soddisfare questi vincoli. I dischi sono collegati a due controller SATA diversi per ottimizzare l'accesso in parallelo e ridurre i rischi di guasto simultaneo e quindi appaiono come <filename>sda</filename> e <filename>sdc</filename>. Vengono partizionati in modo identico secondo il seguente schema:"

msgid ""
"<computeroutput># </computeroutput><userinput>sfdisk -l /dev/sda\n"
"</userinput><computeroutput>Disk /dev/sda: 894.25 GiB, 960197124096 bytes, 1875385008 sectors\n"
"Disk model: SAMSUNG MZ7LM960\n"
"Units: sectors of 1 * 512 = 512 bytes\n"
"Sector size (logical/physical): 512 bytes / 512 bytes\n"
"I/O size (minimum/optimal): 512 bytes / 512 bytes\n"
"Disklabel type: gpt\n"
"Disk identifier: BB14C130-9E9A-9A44-9462-6226349CA012\n"
"\n"
"Device         Start        End   Sectors   Size Type\n"
"/dev/sda1        2048       4095      2048     1M BIOS boot\n"
"/dev/sda2        4096  100667391 100663296    48G Linux RAID\n"
"/dev/sda3   100667392  134221823  33554432    16G Linux RAID\n"
"/dev/sda4   134221824  763367423 629145600   300G Linux RAID\n"
"/dev/sda5   763367424 1392513023 629145600   300G Linux RAID\n"
"/dev/sda6  1392513024 1875384974 482871951 230.3G Linux LVM\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>sfdisk -l /dev/sda\n</userinput><computeroutput>Disk /dev/sda: 894.25 GiB, 960197124096 bytes, 1875385008 sectors\nDisk model: SAMSUNG MZ7LM960\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: gpt\nDisk identifier: BB14C130-9E9A-9A44-9462-6226349CA012\n\nDevice         Start        End   Sectors   Size Type\n/dev/sda1        2048       4095      2048     1M BIOS boot\n/dev/sda2        4096  100667391 100663296    48G Linux RAID\n/dev/sda3   100667392  134221823  33554432    16G Linux RAID\n/dev/sda4   134221824  763367423 629145600   300G Linux RAID\n/dev/sda5   763367424 1392513023 629145600   300G Linux RAID\n/dev/sda6  1392513024 1875384974 482871951 230.3G Linux LVM\n</computeroutput>"

msgid "The first partitions of both disks are BIOS boot partitions."
msgstr "Le prime partizioni di entrambi i dischi sono partizioni di avvio del BIOS."

msgid "The next two partitions <filename>sda2</filename> and <filename>sdc2</filename> (about 48 GB) are assembled into a RAID-1 volume, <filename>md0</filename>. This mirror is directly used to store the root filesystem."
msgstr "Le successive due partizioni <filename>sda2</filename> e <filename>sdc2</filename> (circa 48 GB) sono assemblate in un volume RAID-1, <filename>md0</filename>. Questo mirror è usato direttamente per contenere il filesystem di root."

msgid "The <filename>sda3</filename> and <filename>sdc3</filename> partitions are assembled into a RAID-0 volume, <filename>md1</filename>, and used as swap partition, providing a total 32 GB of swap space. Modern systems can provide plenty of RAM and our system won't need hibernation. So with this amount added, our system will unlikely run out of memory."
msgstr "Le partizioni <filename>sda3</filename> e <filename>sdc3</filename> sono assemblate in un volume RAID-0, <filename>md1</filename>, e usate come partizione di swap, fornendo un totale di 32 GB di spazio di swap. I sistemi moderni sono in grado di fornire molta RAM e questo sistema non necessita dell'ibernazione. Così, con questa aggiunta, è improbabile che ci siano problemi di esaurimento della memoria."

msgid "The <filename>sda4</filename> and <filename>sdc4</filename> partitions, as well as <filename>sda5</filename> and <filename>sdc5</filename>, are assembled into two new RAID-1 volumes of about 300 GB each, <filename>md2</filename> and <filename>md3</filename>. Both these mirrors are initialized as physical volumes for LVM, and assigned to the <filename>vg_raid</filename> volume group. This VG thus contains about 600 GB of safe space."
msgstr "Le partizioni <filename>sda4</filename> e <filename>sdc4</filename>, così come <filename>sda5</filename> e <filename>sdc5</filename>, sono assemblate in due nuovi volumi RAID-1 di circa 300 GB l'uno, <filename>md2</filename> e <filename>md3</filename>. Entrambi questi mirror sono inizializzati come volumi fisici per LVM e assegnati al gruppo di volume <filename>vg_raid</filename>. Questo VG contiene circa 600 GB di spazio sicuro."

msgid "The remaining partitions, <filename>sda6</filename> and <filename>sdc6</filename>, are directly used as physical volumes, and assigned to another VG called <filename>vg_bulk</filename>, which therefore ends up with roughly 460 GB of space."
msgstr "Le rimanenti partizioni, <filename>sda6</filename> e <filename>sdc6</filename>, sono usate direttamente come volumi fisici e assegnate a un altro VG chiamato <filename>vg_bulk</filename>, che quindi ha all'incirca 460 GB di spazio."

msgid "Once the VGs are created, they can be partitioned in a very flexible way. One must keep in mind that LVs created in <filename>vg_raid</filename> will be preserved even if one of the disks fails, which will not be the case for LVs created in <filename>vg_bulk</filename>; on the other hand, the latter will be allocated in parallel on both disks, which allows higher read or write speeds for large files."
msgstr "Una volta creati i VG, possono essere partizionati in modo molto flessibile. Bisogna ricordarsi che i LV creati in <filename>vg_raid</filename> saranno preservati anche in caso di guasto di uno dei dischi, cosa che non succede per i LV creati in <filename>vg_bulk</filename>; d'altro canto, quest'ultimo sarà allocato in parallelo su entrambi i dischi, il che consente velocità di lettura o scrittura maggiori per file grandi."

msgid "We will therefore create the <filename>lv_var</filename> and <filename>lv_home</filename> LVs on <filename>vg_raid</filename>, to host the matching filesystems; another large LV, <filename>lv_movies</filename>, will be used to host the definitive versions of movies after editing. The other VG will be split into a large <filename>lv_rushes</filename>, for data straight out of the digital video cameras, and a <filename>lv_tmp</filename> for temporary files. The location of the work area is a less straightforward choice to make: while good performance is needed for that volume, is it worth risking losing work if a disk fails during an editing session? Depending on the answer to that question, the relevant LV will be created on one VG or the other."
msgstr "Si creeranno quindi i LV <filename>lv_var</filename> e <filename>lv_home</filename> su <filename>vg_raid</filename>, per ospitare i filesystem corrispondenti; un altro grande LV, <filename>lv_movies</filename>, verrà usato per ospitare le versioni definitive dei filmati dopo l'elaborazione. L'altro VG verrà suddiviso in un grande <filename>lv_rushes</filename>, per ospitare i dati che provengono direttamente dalle videocamere digitali e un <filename>lv_tmp</filename> per i file temporanei. La posizione dell'area di lavoro è meno ovvia: pur essendo necessarie delle buone prestazioni per quel volume, vale la pena rischiare di perdere il lavoro se un disco si guasta durante una sessione di elaborazione? A seconda della risposta a questa domanda, il relativo LV sarà creato su uno dei due VG."

msgid "We now have both some redundancy for important data and much flexibility in how the available space is split across the applications."
msgstr "Adesso è presente un certo livello di ridondanza per i dati importanti e molta flessibilità su come viene diviso lo spazio disponibile fra le applicazioni."

msgid "<emphasis>NOTE</emphasis> Why three RAID-1 volumes?"
msgstr "<emphasis>NOTA</emphasis> Perché tre volumi RAID-1?"

msgid "We could have set up one RAID-1 volume only, to serve as a physical volume for <filename>vg_raid</filename>. Why create three of them, then?"
msgstr "Si sarebbe potuto impostare un unico volume RAID-1 come volume fisico per <filename>vg_raid</filename>. Perché dunque crearne tre?"

msgid "The rationale for the first split (<filename>md0</filename> vs. the others) is about data safety: data written to both elements of a RAID-1 mirror are exactly the same, and it is therefore possible to bypass the RAID layer and mount one of the disks directly. In case of a kernel bug, for instance, or if the LVM metadata become corrupted, it is still possible to boot a minimal system to access critical data such as the layout of disks in the RAID and LVM volumes; the metadata can then be reconstructed and the files can be accessed again, so that the system can be brought back to its nominal state."
msgstr "Il motivo della prima suddivisione (<filename>md0</filename> separato dagli altri) è la sicurezza dei dati: i dati scritti su entrambi gli elementi di un mirror RAID-1 sono esattamente gli stessi ed è quindi possibile aggirare il livello RAID e montare uno dei dischi direttamente. In caso di un bug nel kernel, per esempio, o se i metadati LVM si rovinano, è comunque possibile avviare un sistema minimale per avere accesso ai dati critici come la struttura dei dischi nei volumi RAID e LVM; i metadati possono poi essere ricostruiti e i file resi di nuovo accessibili, cosicché il sistema può essere riportato al suo stato normale."

msgid "The rationale for the second split (<filename>md2</filename> vs. <filename>md3</filename>) is less clear-cut, and more related to acknowledging that the future is uncertain. When the workstation is first assembled, the exact storage requirements are not necessarily known with perfect precision; they can also evolve over time. In our case, we can't know in advance the actual storage space requirements for video rushes and complete video clips. If one particular clip needs a very large amount of rushes, and the VG dedicated to redundant data is less than halfway full, we can re-use some of its unneeded space. We can remove one of the physical volumes, say <filename>md3</filename>, from <filename>vg_raid</filename> and either assign it to <filename>vg_bulk</filename> directly (if the expected duration of the operation is short enough that we can live with the temporary drop in performance), or undo the RAID setup on <filename>md3</filename> and integrate its components <filename>sda5</filename> and <filename>sdc5</filename> into the bulk VG (which grows by 600 GB instead of 300 GB); the <filename>lv_rushes</filename> logical volume can then be grown according to requirements."
msgstr "Il motivo della seconda suddivisione (<filename>md2</filename> vs. <filename>md3</filename>) è meno evidente e più collegato all'accettazione del fatto che il futuro è incerto. Quando la postazione di lavoro viene inizialmente installata, i requisiti esatti di archiviazione non sono necessariamente noti con precisione perfetta; inoltre questi possono evolvere nel tempo. In questo caso, non si può conoscere in anticipo gli effettivi requisiti di spazio per gli spezzoni di video ed i video completi. Se un particolare video necessita di una grande quantità di spezzoni e il VG dedicato ai dati ridondanti è pieno per meno della metà, si può riutilizzare parte del suo spazio non usato. Si può rimuovere uno dei volumi fisici, ad esempio <filename>md3</filename>, da <filename>vg_raid</filename> e assegnarlo direttamente a <filename>vg_bulk</filename> (se la durata attesa dell'operazione è abbastanza breve da poter convivere con il temporaneo calo di prestazioni) o annullare l'impostazione RAID su <filename>md3</filename> e integrare le sue componenti <filename>sda5</filename> e <filename>sdc5</filename> nel VG di grosse dimensioni (che cresce di 600 GB invece di 300 GB); il volume logico <filename>lv_rushes</filename> può quindi essere allargato secondo necessità."

msgid "<primary>virtualization</primary>"
msgstr "<primary>virtualizzazione</primary>"

msgid "Virtualization is one of the most major advances in the recent years of computing. The term covers various abstractions and techniques simulating virtual computers with a variable degree of independence on the actual hardware. One physical server can then host several systems working at the same time and in isolation. Applications are many, and often derive from this isolation: test environments with varying configurations for instance, or separation of hosted services across different virtual machines for security."
msgstr "La virtualizzazione è uno dei più grandi progressi dell'informatica negli ultimi anni. Il termine copre diverse astrazioni e tecniche per simulare macchine virtuali con grado variabile di indipendenza dall'effettivo hardware. Un server fisico può quindi ospitare diversi sistemi contemporaneamente in funzione e isolati fra loro. Le applicazioni sono molte e spesso derivano da questo isolamento; per esempio ambienti di prova con configurazioni variabili, oppure separazioni di servizi ospitati per ragioni di sicurezza su differenti macchine virtuali."

msgid "There are multiple virtualization solutions, each with its own pros and cons. This book will focus on Xen, LXC, and KVM, but other noteworthy implementations include the following:"
msgstr "Ci sono numerose soluzioni di virtualizzazione, ciascuna coi suoi pro e contro. Questo libro si concentrerà su Xen, LXC e KVM, ma fra le altre implementazioni degne di nota vi sono le seguenti:"

msgid "<primary>Xen</primary>"
msgstr "<primary>Xen</primary>"

msgid "<primary>VMWare</primary>"
msgstr "<primary>VMWare</primary>"

msgid "<primary>Bochs</primary>"
msgstr "<primary>Bochs</primary>"

msgid "<primary>QEMU</primary>"
msgstr "<primary>QEMU</primary>"

msgid "<primary>VirtualBox</primary>"
msgstr "<primary>VirtualBox</primary>"

msgid "<primary>KVM</primary>"
msgstr "<primary>KVM</primary>"

msgid "<primary>LXC</primary>"
msgstr "<primary>LXC</primary>"

msgid "QEMU is a software emulator for a full computer; performances are far from the speed one could achieve running natively, but this allows running unmodified or experimental operating systems on the emulated hardware. It also allows emulating a different hardware architecture: for instance, an <emphasis>amd64</emphasis> system can emulate an <emphasis>arm</emphasis> computer. QEMU is free software. <ulink type=\"block\" url=\"https://qemu.org/\" />"
msgstr "QEMU è un software di emulazione che permette di emulare una macchina completa; le prestazioni sono lontane dalla velocità ottenibile in modo nativo, ma questo permette di far girare sistemi operativi non modificati o sperimentali sull'hardware emulato. Permette inoltre di emulare un'architettura hardware diversa: per esempio, un sistema <emphasis>amd64</emphasis> può emulare un computer <emphasis>arm</emphasis>. QEMU è software libero. <ulink type=\"block\" url=\"https://qemu.org/\" />"

msgid "Bochs is another free virtual machine, but it only emulates the x86 architectures (i386 and amd64)."
msgstr "Bochs è un'altra macchina virtuale libera, ma emula soltanto le architetture x86 (i386 e amd64)."

msgid "VMWare is a proprietary virtual machine; being one of the oldest out there, it is also one of the most widely-known. It works on principles similar to QEMU. VMWare proposes advanced features such as “snapshotting“ a running virtual machine. <ulink type=\"block\" url=\"https://vmware.com/\" />"
msgstr "VMWare è una macchina virtuale proprietaria; essendo una delle più vecchie in circolazione, è anche una delle più conosciute. Funziona in modo simile a QEMU. VMWare propone funzionalità avanzate, come immagini istantanee di una macchina virtuale in esecuzione. <ulink type=\"block\" url=\"https://vmware.com/\" />"

msgid "VirtualBox is a virtual machine that is mostly free software (some extra components are available under a proprietary license). Unfortunately it is in Debian's “contrib” section because it includes some precompiled files that cannot be rebuilt without a proprietary compiler and it currently only resides in Debian Unstable as Oracle's policies make it impossible to keep it secure in a Debian stable release (see <ulink url=\"https://bugs.debian.org/794466\">#794466</ulink>). While younger than VMWare and restricted to the i386 and amd64 architectures, it still includes some “snapshotting“ and other interesting features. <ulink type=\"block\" url=\"https://www.virtualbox.org/\" />"
msgstr "VirtualBox è una macchina virtuale che è perlopiù software libero (sebbene alcune componenti aggiuntive siano sotto una licenza proprietaria). Purtroppo è nella sezione \"contrib\" di Debian poiché include alcuni file precompilati che non possono essere ricostruiti senza un compilatore proprietario e attualmente è presente solo in Debian Unstable dato che le politiche di Oracle rendono impossibile mantenerlo sicuro in un rilascio stabile di Debian (vedere <ulink url=\"https://bugs.debian.org/794466\">#794466</ulink>). Sebbene sia più giovane di VMWare e limitata alle architetture i386 e amd64, include già la possibilità di effettuare immagini istantanee ed altre caratteristiche interessanti. <ulink type=\"block\" url=\"https://www.virtualbox.org/\" />"

msgid "<emphasis>HARDWARE</emphasis> Virtualization support"
msgstr "<emphasis>HARDWARE</emphasis> Supporto alla virtualizzazione"

msgid "Some computers might not have hardware virtualization support; when they do, it should be enabled in the BIOS."
msgstr "Alcuni computer potrebbero non avere il supporto per la virtualizzazione hardware; quando disponibile, dev'essere abilitato nel BIOS."

msgid "To know if you have virtualization support enabled, you can check if the relevant flag is enabled with <command>grep</command>. If the following command for your processor returns some text, you already have virtualization support enabled:"
msgstr "Per sapere se è abilitato il supporto per la virtualizzazione, si può verificare se il relativo flag è abilitato con <command>grep</command>. Se il seguente comando restituisce del testo, significa che il supporto alla virtualizzazione è abilitato:"

msgid "For Intel processors you can execute <command>grep vmx /proc/cpuinfo</command> to check for Intel's Virtual Machine Extensions."
msgstr "Per processori Intel è possibile eseguire <command>grep vmx /proc/cpuinfo</command> per controllare se sono presenti le Virtual Machine Extensions (estensioni della macchina virtuale) di Intel."

msgid "For AMD processors you can execute <command>grep svm /proc/cpuinfo</command> to check for AMD's Secure Virtual Machine."
msgstr "Per processori AMD è possibile eseguire <command>grep svm /proc/cpuinfo</command> per verificare la presenza della Secure Virtual Machine (macchina virtuale sicura) di AMD."

msgid "If that is not the case, you can access the BIOS of your system and check for entries like “Intel Virtualization Technology”/“Intel VT-x” or “SVM mode” (AMD) - usually to be found in the CPU configuration in the Advanced section."
msgstr "Se questo non è il caso, è possibile accedere al BIOS del sistema e verificare la presenza di voci del tipo “Intel Virtualization Technology”/“Intel VT-x” o “SVM mode” (AMD) che di solito si trovano nella configurazione della CPU nella sezione Advanced."

msgid "<primary>paravirtualization</primary>"
msgstr "<primary>paravirtualizzazione</primary>"

msgid "<primary>hypervisor</primary>"
msgstr "<primary>hypervisor</primary>"

msgid "Xen <indexterm><primary>Xen</primary></indexterm> is a “paravirtualization” solution. It introduces a thin abstraction layer, called a “hypervisor”, between the hardware and the upper systems; this acts as a referee that controls access to hardware from the virtual machines. However, it only handles a few of the instructions, the rest is directly executed by the hardware on behalf of the systems. The main advantage is that performances are not degraded, and systems run close to native speed; the drawback is that the kernels of the operating systems one wishes to use on a Xen hypervisor need to be adapted to run on Xen."
msgstr "Xen <indexterm><primary>Xen</primary></indexterm> è una situazione di «paravirtualizzazione». Introduce un sottile strato di astrazione, chiamato «ipervisore», fra l'hardware e i sistemi superiori; ciò agisce come un arbitro che controlla l'accesso all'hardware dalle macchine virtuali. Tuttavia, questo gestisce solo alcune delle istruzioni, mentre il resto è eseguito direttamente dall'hardware per conto dei sistemi. Il vantaggio principale è che non c'è degrado di prestazioni e i sistemi girano a una velocità prossima a quella nativa; il difetto è che i kernel dei sistemi operativi che si vogliono usare su un ipervisore Xen devono essere adattati per girare su Xen."

msgid "<primary>dom0</primary>"
msgstr "<primary>dom0</primary>"

msgid "<primary>domU</primary>"
msgstr "<primary>domU</primary>"

msgid "<primary>virtualization</primary><secondary>host</secondary>"
msgstr "<primary>virtualizzazione</primary><secondary>host</secondary>"

msgid "<primary>virtualization</primary><secondary>guest</secondary>"
msgstr "<primary>virtualizzazione</primary><secondary>guest</secondary>"

msgid "Let's spend some time on terms. The hypervisor is the lowest layer, which runs directly on the hardware, even below the kernel. This hypervisor can split the rest of the software across several <emphasis>domains</emphasis>, which can be seen as so many virtual machines. One of these domains (the first one that gets started) is known as <emphasis>dom0</emphasis>, and has a special role, since only this domain can control the hypervisor and the execution of other domains. These other domains are known as <emphasis>domU</emphasis>. In other words, and from a user point of view, the <emphasis>dom0</emphasis> matches the “host” of other virtualization systems, while a <emphasis>domU</emphasis> can be seen as a “guest”."
msgstr "Dedichiamo un po' di tempo alla terminologia. L'ipervisore è lo strato inferiore, che gira direttamente sull'hardware, addirittura sotto il kernel. Questo ipervisore può suddividere il resto del software su più <emphasis>domini</emphasis>, che possono essere visti come altrettante macchine virtuali. Uno di questi domini (il primo che viene avviato) è conosciuto come <emphasis>dom0</emphasis> e ha un ruolo speciale, in quanto solo questo dominio può controllare l'ipervisore e l'esecuzione di altri domini. Questi altri domini si chiamano <emphasis>domU</emphasis>. In altre parole, e dal punto di vista dell'utente, il <emphasis>dom0</emphasis> coincide con l'«host» di altri sistemi di virtualizzazione, mentre un <emphasis>domU</emphasis> può essere visto come «guest»."

msgid "<emphasis>CULTURE</emphasis> Xen and the various versions of Linux"
msgstr "<emphasis>CULTURA</emphasis> Xen e le varie versioni di Linux"

msgid "Xen was initially developed as a set of patches that lived out of the official tree, and not integrated to the Linux kernel. At the same time, several upcoming virtualization systems (including KVM) required some generic virtualization-related functions to facilitate their integration, and the Linux kernel gained this set of functions (known as the <emphasis>paravirt_ops</emphasis> or <emphasis>pv_ops</emphasis> interface). Since the Xen patches were duplicating some of the functionality of this interface, they couldn't be accepted officially."
msgstr "Xen inizialmente fu sviluppato come un insieme di patch al di fuori dell'albero ufficiale e non integrate nel kernel Linux. Allo stesso tempo, diversi nuovi sistemi di virtualizzazione (incluso KVM) richiedevano alcune funzioni generiche relative alla virtualizzazione per facilitare la loro integrazione e il kernel Linux incluse queste funzioni (note come interfaccia <emphasis>paravirt_ops</emphasis> o <emphasis>pv_ops</emphasis>). Dal momento che le patch Xen duplicavano alcune delle funzionalità di questa interfaccia, non potevano essere accettate ufficialmente."

msgid "Xensource, the company behind Xen, therefore had to port Xen to this new framework, so that the Xen patches could be merged into the official Linux kernel. That meant a lot of code rewrite, and although Xensource soon had a working version based on the paravirt_ops interface, the patches were only progressively merged into the official kernel. The merge was completed in Linux 3.0. <ulink type=\"block\" url=\"https://wiki.xenproject.org/wiki/XenParavirtOps\" />"
msgstr "Xensource, la compagnia dietro Xen, ha quindi dovuto portare Xen su questa nuova infrastruttura, cosicché le patch per Xen potessero essere incluse nel kernel Linux ufficiale. Ciò ha significato la riscrittura di gran parte del codice e sebbene Xensource in breve tempo avesse ottenuto una versione funzionante basata sull'interfaccia paravirt_ops, le patch sono state integrate nel kernel ufficiale solo gradualmente. L'integrazione è stata completata in Linux 3.0. <ulink type=\"block\" url=\"https://wiki.xenproject.org/wiki/XenParavirtOps\" />"

#, fuzzy
#| msgid "Since <emphasis role=\"distribution\">Jessie</emphasis> is based on version 3.16 of the Linux kernel, the standard <emphasis role=\"pkg\">linux-image-686-pae</emphasis> and <emphasis role=\"pkg\">linux-image-amd64</emphasis> packages include the necessary code, and the distribution-specific patching that was required for <emphasis role=\"distribution\">Squeeze</emphasis> and earlier versions of Debian is no more. <ulink type=\"block\" url=\"http://wiki.xenproject.org/wiki/Xen_Kernel_Feature_Matrix\" />"
msgid "Since <emphasis role=\"distribution\">Jessie</emphasis> is based on version 3.16 of the Linux kernel, the standard <emphasis role=\"pkg\">linux-image-686-pae</emphasis> and <emphasis role=\"pkg\">linux-image-amd64</emphasis> packages include the necessary code, and the distribution-specific patching that was required for <emphasis role=\"distribution\">Squeeze</emphasis> and earlier versions of Debian is no more. <ulink type=\"block\" url=\"https://wiki.xenproject.org/wiki/Xen_Kernel_Feature_Matrix\" />"
msgstr "Poiché <emphasis role=\"distribution\">Jessie</emphasis> è basato sulla versione 3.16 del kernel Linux, i pacchetti standard <emphasis role=\"pkg\">linux-image-686-pae</emphasis> e <emphasis role=\"pkg\">linux-image-amd64</emphasis> includono tutto il codice necessario; le patch specifiche per la distribuzione, necessarie per <emphasis role=\"distribution\">Squeeze</emphasis> e le versioni precedenti di Debian, non servono più. <ulink type=\"block\" url=\"https://wiki.xenproject.org/wiki/Xen_Kernel_Feature_Matrix\" />"

msgid "<emphasis>CULTURE</emphasis> Xen and non-Linux kernels"
msgstr "<emphasis>CULTURA</emphasis> Xen e kernel non Linux"

msgid "Xen requires modifications to all the operating systems one wants to run on it; not all kernels have the same level of maturity in this regard. Many are fully-functional, both as dom0 and domU: Linux 3.0 and later, NetBSD 4.0 and later, and OpenSolaris. Others only work as a domU. You can check the status of each operating system in the Xen wiki: <ulink type=\"block\" url=\"https://wiki.xenproject.org/wiki/Dom0_Kernels_for_Xen\" /> <ulink type=\"block\" url=\"https://wiki.xenproject.org/wiki/DomU_Support_for_Xen\" />"
msgstr "Xen richiede modifiche a tutti i sistemi operativi che vi si vogliano far girare su di esso; non tutti i kernel hanno lo stesso livello di maturità da questo punto di vista. Molti sono completamente funzionanti, sia come dom0 che come domU: Linux 3.0 e successivi, NetBSD 4.0 e successivi e OpenSolaris. Altri funzionano solo come domU. È possibile controllare lo stato di ogni sistema operativo nel wiki di Xen: <ulink type=\"block\" url=\"https://wiki.xenproject.org/wiki/Dom0_Kernels_for_Xen\" /> <ulink type=\"block\" url=\"https://wiki.xenproject.org/wiki/DomU_Support_for_Xen\" />"

msgid "However, if Xen can rely on the hardware functions dedicated to virtualization (which are only present in more recent processors), even non-modified operating systems can run as domU (including Windows)."
msgstr "Tuttavia, se Xen può basarsi sulle funzioni hardware dedicate alla virtualizzazione (che sono presenti solo nei processori più recenti), anche sistemi operativi non modificati possono girare come domU (compreso Windows)."

msgid "<emphasis>NOTE</emphasis> Architectures compatible with Xen"
msgstr "<emphasis>NOTA</emphasis> Architetture compatibili con Xen"

msgid "Xen is currently only available for the i386, amd64, arm64 and armhf architectures."
msgstr "Xen è attualmente disponibile solo per architetture i386, amd64, arm64 ed armhf."

msgid "Using Xen under Debian requires three components:"
msgstr "L'uso di Xen sotto Debian richiede tre componenti:"

msgid "<primary><emphasis role=\"pkg\">xen-hypervisor</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">xen-hypervisor</emphasis></primary>"

msgid "The hypervisor itself. According to the available hardware, the appropriate package providing <emphasis role=\"pkg\">xen-hypervisor</emphasis> will be either <emphasis role=\"pkg\">xen-hypervisor-4.14-amd64</emphasis>, <emphasis role=\"pkg\">xen-hypervisor-4.14-armhf</emphasis>, or <emphasis role=\"pkg\">xen-hypervisor-4.14-arm64</emphasis>."
msgstr "L'ipervisore stesso. A seconda dell'hardware disponibile, il pacchetto appropriato che fornisce <emphasis role=\"pkg\">xen-hypervisor</emphasis> sarà <emphasis role=\"pkg\">xen-hypervisor-4.14-amd64</emphasis>, <emphasis role=\"pkg\">xen-hypervisor-4.14-armhf</emphasis> o <emphasis role=\"pkg\">xen-hypervisor-4.14-arm64</emphasis>."

msgid "A kernel that runs on that hypervisor. Any kernel more recent than 3.0 will do, including the 5.10 version present in <emphasis role=\"distribution\">Bullseye</emphasis>."
msgstr "Un kernel che gira su tale hypervisor. Qualsiasi kernel più recente del 3.0 lo farà, inclusa la versione 5.10 presente in <emphasis role=\"distribution\">Bullseye</emphasis>."

msgid "The i386 architecture also requires a standard library with the appropriate patches taking advantage of Xen; this is in the <emphasis role=\"pkg\">libc6-xen</emphasis> package."
msgstr "L'architettura i386 richiede inoltre una libreria standard con le patch appropriate che si appoggino a Xen; questa si trova nel pacchetto <emphasis role=\"pkg\">libc6-xen</emphasis>."

msgid "<primary><emphasis role=\"pkg\">xen-utils</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">xen-utils</emphasis></primary>"

msgid "The hypervisor also brings <emphasis role=\"pkg\">xen-utils-4.14</emphasis>, which contains tools to control the hypervisor from the dom0. This in turn brings the appropriate standard library. During the installation of all that, configuration scripts also create a new entry in the GRUB bootloader menu, so as to start the chosen kernel in a Xen dom0. Note, however, that this entry is not usually set to be the first one in the list, but it will be selected by default."
msgstr "L'hypervisor installa anche <emphasis role=\"pkg\">xen-utils-4.14</emphasis>, che contiene gli strumenti per controllare l'hypervisor dal dom0. Questo, a sua volta, installa l'appropriata libreria standard. Durante l'installazione di tutto ciò, gli script di configurazione creano anche una nuova voce nel menu del bootloader GRUB, in modo da poter avviare il kernel scelto in un dom0 Xen. Da notare, tuttavia, che questa voce non è solitamente impostata come la prima della lista, ma sarà selezionata per impostazione predefinita."

msgid "Once these prerequisites are installed, the next step is to test the behavior of the dom0 by itself; this involves a reboot to the hypervisor and the Xen kernel. The system should boot in its standard fashion, with a few extra messages on the console during the early initialization steps."
msgstr "Una volta installati questi prerequisiti, il passo successivo è collaudare il comportamento del dom0 da solo; questo richiede un riavvio per entrare nell'ipervisore e nel kernel Xen. Il sistema dovrebbe avviarsi nel modo consueto, mostrando alcuni messaggi in più nella console durante i primi passi dell'inizializzazione."

msgid "<primary><emphasis role=\"pkg\">xen-tools</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">xen-tools</emphasis></primary>"

msgid "<primary><command>xen-create-image</command></primary>"
msgstr "<primary><command>xen-create-image</command></primary>"

msgid "<primary><filename>/etc</filename></primary><secondary><filename>/etc/xen-tools/xen-tools.conf</filename></secondary>"
msgstr "<primary><filename>/etc</filename></primary><secondary><filename>/etc/xen-tools/xen-tools.conf</filename></secondary>"

msgid "Now is the time to actually install useful systems on the domU systems, using the tools from <emphasis role=\"pkg\">xen-tools</emphasis>. This package provides the <command>xen-create-image</command> command, which largely automates the task. The only mandatory parameter is <literal>--hostname</literal>, giving a name to the domU; other options are important, but they can be stored in the <filename>/etc/xen-tools/xen-tools.conf</filename> configuration file, and their absence from the command line doesn't trigger an error. It is therefore important to either check the contents of this file before creating images, or to use extra parameters in the <command>xen-create-image</command> invocation. Important parameters of note include the following:"
msgstr "Ora è il momento di installare veramente dei sistemi utili sui sistemi domU, usando gli strumenti di <emphasis role=\"pkg\">xen-tools</emphasis>. Questo pacchetto fornisce il comando <command>xen-create-image</command>, che automatizza gran parte del compito. L'unico parametro obbligatorio è <literal>--hostname</literal>, che dà un nome al domU; altre opzioni sono importanti, ma possono essere memorizzate nel file di configurazione <filename>/etc/xen-tools/xen-tools.conf</filename> e la loro mancanza dalla riga di comando non genera un errore. Perciò è importante controllare i contenuti di questo file prima di creare delle immagini oppure, in alternativa, usare parametri aggiuntivi nell'esecuzione di <command>xen-create-image</command>. I parametri importanti includono:"

msgid "<literal>--memory</literal>, to specify the amount of RAM dedicated to the newly created system;"
msgstr "<literal>--memory</literal>, per specificare la quantità di RAM dedicata al sistema appena creato;"

msgid "<literal>--size</literal> and <literal>--swap</literal>, to define the size of the “virtual disks” available to the domU;"
msgstr "<literal>--size</literal> e <literal>--swap</literal>, per definire la dimensione dei «dischi virtuali» disponibili al domU;"

msgid "<primary><command>debootstrap</command></primary>"
msgstr "<primary><command>debootstrap</command></primary>"

msgid "<literal>--debootstrap-cmd</literal>, to specify the which debootstrap command is used. The default is <command>debootstrap</command> if debootstrap and cdebootstrap are installed. In that case, the <literal>--dist</literal> option will also most often be used (with a distribution name such as <emphasis role=\"distribution\">bullseye</emphasis>)."
msgstr "<literal>--debootstrap-cmd</literal>, per specificare il comando debootstrap usato. Il predefinito è <command>debootstrap</command> se sono installati debootstrap e cdebootstrap; in questo caso, verrà usata spesso anche l'opzione <literal>--dist</literal> (con il nome di una distribuzione come <emphasis role=\"distribution\">bullseye</emphasis>)."

msgid "<emphasis>GOING FURTHER</emphasis> Installing a non-Debian system in a domU"
msgstr "<emphasis>APPROFONDIMENTO</emphasis> Installare un sistema non Debian in un domU"

msgid "In case of a non-Linux system, care should be taken to define the kernel the domU must use, using the <literal>--kernel</literal> option."
msgstr "In caso di un sistema non Linux, bisogna fare attenzione a definire il kernel che il domU deve usare, usando l'opzione <literal>--kernel</literal>."

msgid "<literal>--dhcp</literal> states that the domU's network configuration should be obtained by DHCP while <literal>--ip</literal> allows defining a static IP address."
msgstr "<literal>--dhcp</literal> dichiara che la configurazione di rete del domU deve essere ottenuta tramite DHCP mentre <literal>--ip</literal> permette di definire un indirizzo IP statico."

msgid "<primary>LVM</primary><secondary>Xen</secondary>"
msgstr "<primary>LVM</primary><secondary>Xen</secondary>"

msgid "Lastly, a storage method must be chosen for the images to be created (those that will be seen as hard disk drives from the domU). The simplest method, corresponding to the <literal>--dir</literal> option, is to create one file on the dom0 for each device the domU should be provided. For systems using LVM, the alternative is to use the <literal>--lvm</literal> option, followed by the name of a volume group; <command>xen-create-image</command> will then create a new logical volume inside that group, and this logical volume will be made available to the domU as a hard disk drive."
msgstr "Da ultimo, bisogna scegliere un metodo di memorizzazione per le immagini da creare (quelle che saranno viste come dischi fissi dal domU). Il metodo più semplice, che corrisponde all'opzione <literal>--dir</literal>, è di creare un file sul dom0 per ogni dispositivo da rendere disponibile al domU. Per i sistemi che usano LVM, l'alternativa è usare l'opzione <literal>--lvm</literal>, seguita dal nome di un gruppo di volume; quindi <command>xen-create-image</command> creerà un nuovo volume logico dentro quel gruppo e questo volume logico sarà reso disponibile al domU come disco fisso."

msgid "<emphasis>NOTE</emphasis> Storage in the domU"
msgstr "<emphasis>NOTA</emphasis> Memorizzazione nel domU"

msgid "Entire hard disks can also be exported to the domU, as well as partitions, RAID arrays or pre-existing LVM logical volumes. These operations are not automated by <command>xen-create-image</command>, however, so editing the Xen image's configuration file is in order after its initial creation with <command>xen-create-image</command>."
msgstr "Oltre a partizioni, array RAID o volumi logici LVM preesistenti, anche interi dischi fissi possono essere esportati verso il domU. Queste operazioni non sono tuttavia automatizzate da <command>xen-create-image</command>, quindi è necessario modificare il file di configurazione dell'immagine Xen dopo la sua creazione iniziale con <command>xen-create-image</command>."

msgid "Once these choices are made, we can create the image for our future Xen domU:"
msgstr "Una volta effettuate queste scelte, si può creare l'immagine per il futuro domU Xen:"

msgid ""
"<computeroutput># </computeroutput><userinput>xen-create-image --hostname testxen --dhcp --dir /srv/testxen --size=2G --dist=bullseye --role=udev\n"
"</userinput><computeroutput>\n"
"General Information\n"
"--------------------\n"
"Hostname       :  testxen\n"
"Distribution   :  bullseye\n"
"Mirror         :  http://deb.debian.org/debian\n"
"Partitions     :  swap            512M  (swap)\n"
"                  /               2G    (ext4)\n"
"Image type     :  sparse\n"
"Memory size    :  256M\n"
"Bootloader     :  pygrub\n"
"\n"
"[...]\n"
"Logfile produced at:\n"
"\t /var/log/xen-tools/testxen.log\n"
"\n"
"Installation Summary\n"
"---------------------\n"
"Hostname        :  testxen\n"
"Distribution    :  bullseye\n"
"MAC Address     :  00:16:3E:C2:07:EE\n"
"IP Address(es)  :  dynamic\n"
"SSH Fingerprint :  SHA256:K+0QjpGzZOacLZ3jX4gBwp0mCESt5ceN5HCJZSKWS1A (DSA)\n"
"SSH Fingerprint :  SHA256:9PnovvGRuTw6dUcEVzzPKTITO0+3Ki1Gs7wu4ke+4co (ECDSA)\n"
"SSH Fingerprint :  SHA256:X5z84raKBajUkWBQA6MVuanV1OcV2YIeD0NoCLLo90k (ED25519)\n"
"SSH Fingerprint :  SHA256:VXu6l4tsrCoRsXOqAwvgt57sMRj2qArEbOzHeydvV34 (RSA)\n"
"Root Password   :  FS7CUxsY3xkusv7EkbT9yae\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>xen-create-image --hostname testxen --dhcp --dir /srv/testxen --size=2G --dist=bullseye --role=udev\n</userinput><computeroutput>\nGeneral Information\n--------------------\nHostname       :  testxen\nDistribution   :  bullseye\nMirror         :  http://deb.debian.org/debian\nPartitions     :  swap            512M  (swap)\n                  /               2G    (ext4)\nImage type     :  sparse\nMemory size    :  256M\nBootloader     :  pygrub\n\n[...]\nLogfile produced at:\n\t /var/log/xen-tools/testxen.log\n\nInstallation Summary\n---------------------\nHostname        :  testxen\nDistribution    :  bullseye\nMAC Address     :  00:16:3E:C2:07:EE\nIP Address(es)  :  dynamic\nSSH Fingerprint :  SHA256:K+0QjpGzZOacLZ3jX4gBwp0mCESt5ceN5HCJZSKWS1A (DSA)\nSSH Fingerprint :  SHA256:9PnovvGRuTw6dUcEVzzPKTITO0+3Ki1Gs7wu4ke+4co (ECDSA)\nSSH Fingerprint :  SHA256:X5z84raKBajUkWBQA6MVuanV1OcV2YIeD0NoCLLo90k (ED25519)\nSSH Fingerprint :  SHA256:VXu6l4tsrCoRsXOqAwvgt57sMRj2qArEbOzHeydvV34 (RSA)\nRoot Password   :  FS7CUxsY3xkusv7EkbT9yae\n</computeroutput>"

msgid "We now have a virtual machine, but it is currently not running (and therefore only using space on the dom0's hard disk). Of course, we can create more images, possibly with different parameters."
msgstr "Adesso è stata creata una macchina virtuale, ma attualmente non è in esecuzione (e quindi occupa solo spazio sul disco fisso del dom0). Ovviamente si possono creare altre immagini, magari con parametri diversi."

msgid "<primary>Xen</primary><secondary>network models</secondary>"
msgstr "<primary>Xen</primary><secondary>modelli di rete</secondary>"

msgid "Before turning these virtual machines on, we need to define how they'll be accessed. They can of course be considered as isolated machines, only accessed through their system console, but this rarely matches the usage pattern. Most of the time, a domU will be considered as a remote server, and accessed only through a network. However, it would be quite inconvenient to add a network card for each domU; which is why Xen allows creating virtual interfaces that each domain can see and use in a standard way. Note that these cards, even though they're virtual, will only be useful once connected to a network, even a virtual one. Xen has several network models for that:"
msgstr "Prima di accendere queste macchine virtuali, bisogna definirne le modalità di accesso. Ovviamente possono essere considerate come macchine isolate, a cui si accederà soltanto tramite la loro console di sistema, ma raramente vengono usate in questo modo. Nella maggior parte dei casi, un domU sarà considerato come un server remoto e vi si accederà solo via rete. Tuttavia sarebbe molto scomodo aggiungere una scheda di rete per ogni domU; per questo Xen permette di creare interfacce virtuali, che ogni dominio può vedere e usare in modo standard. Notare che queste schede, seppur siano virtuali, saranno utili solo una volta connesse a una rete, anche solo virtuale. Per questo scopo, Xen ha diversi modelli di rete:"

msgid "The simplest model is the <emphasis>bridge</emphasis> model; all the eth0 network cards (both in the dom0 and the domU systems) behave as if they were directly plugged into an Ethernet switch."
msgstr "Il modello più semplice è il modello <emphasis>bridge</emphasis>; tutte le schede di rete eth0 (sia nel dom0 che nei sistemi domU) si comportano come se fossero direttamente inserite in uno switch Ethernet."

msgid "Then comes the <emphasis>routing</emphasis> model, where the dom0 behaves as a router that stands between the domU systems and the (physical) external network."
msgstr "C'è poi il modello <emphasis>routing</emphasis>, dove il dom0 si comporta come un router che sta fra i sistemi domU e la rete esterna (fisica)."

msgid "Finally, in the <emphasis>NAT</emphasis> model, the dom0 is again between the domU systems and the rest of the network, but the domU systems are not directly accessible from outside, and traffic goes through some network address translation on the dom0."
msgstr "Infine, nel modello <emphasis>NAT</emphasis>, il dom0 è di nuovo fra i sistemi domU e il resto della rete, ma i sistemi domU non sono direttamente accessibili dall'esterno e il traffico passa attraverso alcune traduzioni degli indirizzi di rete sul dom0."

msgid "These three networking nodes involve a number of interfaces with unusual names, such as <filename>vif*</filename>, <filename>veth*</filename>, <filename>peth*</filename> and <filename>xenbr0</filename>. The Xen hypervisor arranges them in whichever layout has been defined, under the control of the user-space tools. Since the NAT and routing models are only adapted to particular cases, we will only address the bridging model."
msgstr "Queste tre modalità di rete comprendono alcune interfacce dai nomi insoliti, come <filename>vif*</filename>, <filename>veth*</filename>, <filename>peth*</filename> e <filename>xenbr0</filename>. L'ipervisore Xen le dispone in qualunque configurazione sia stata definita, sotto il controllo degli strumenti nello spazio utente. Poiché le modalità NAT e routing si adattano solo a casi particolari, qui si descriverà solo il modello di bridge."

msgid "The standard configuration of the Xen packages does not change the system-wide network configuration. However, the <command>xend</command> daemon is configured to integrate virtual network interfaces into any pre-existing network bridge (with <filename>xenbr0</filename> taking precedence if several such bridges exist). We must therefore set up a bridge in <filename>/etc/network/interfaces</filename> (which requires installing the <emphasis role=\"pkg\">bridge-utils</emphasis> package, which is why the <emphasis role=\"pkg\">xen-utils</emphasis> package recommends it) to replace the existing <replaceable>eth0</replaceable> entry (be careful to use the correct network device name):"
msgstr "La configurazione standard dei pacchetti Xen non cambia la configurazione di rete di sistema. Tuttavia, il demone <command>xend</command> è configurato per integrare le interfacce di rete virtuali in qualunque bridge di rete preesistente (con precedenza a <filename>xenbr0</filename> se esiste più di un bridge). Bisogna quindi impostare un bridge in <filename>/etc/network/interfaces</filename> (il che richiede l'installazione del pacchetto <emphasis role=\"pkg\">bridge-utils</emphasis>, che è il motivo per cui <emphasis role=\"pkg\">xen-utils</emphasis> lo raccomanda) per sostituire la voce esistente relativa a <replaceable>eth0</replaceable> (fare attenzione ad utilizzare il nome di dispositivo di rete corretto):"

msgid "<primary><filename>/etc</filename></primary><secondary><filename>/etc/network/interfaces</filename></secondary>"
msgstr "<primary><filename>/etc</filename></primary><secondary><filename>/etc/network/interfaces</filename></secondary>"

msgid "<primary><emphasis role=\"pkg\">bridge-utils</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">bridge-utils</emphasis></primary>"

msgid "<primary>Xen</primary><secondary><literal>xenbr0</literal></secondary>"
msgstr "<primary>Xen</primary><secondary><literal>xenbr0</literal></secondary>"

msgid ""
"auto xenbr0\n"
"iface xenbr0 inet dhcp\n"
"    bridge_ports <replaceable>eth0</replaceable>\n"
"    bridge_maxwait 0"
msgstr "auto xenbr0\niface xenbr0 inet dhcp\n    bridge_ports <replaceable>eth0</replaceable>\n    bridge_maxwait 0"

msgid "<primary><command>xl</command></primary>"
msgstr "<primary><command>xl</command></primary>"

msgid "After rebooting to make sure the bridge is automatically created, we can now start the domU with the Xen control tools, in particular the <command>xl</command> command. This command allows different manipulations on the domains, including listing them and, starting/stopping them. You might need to increase the default memory by editing the variable memory from configuration file (in this case, <filename>/etc/xen/testxen.cfg</filename>). Here we have set it to 1024 (megabytes)."
msgstr "Dopo aver riavviato per assicurarsi che il bridge sia stato creato automaticamente, si può ora avviare il domU con gli strumenti di controllo di Xen, in particolare il comando <command>xl</command>. Questo comando permette diverse manipolazioni sui domini, fra cui elencarli, avviarli e fermarli. Si potrebbe dover incrementare la memoria predefinita mediante modifica della variabile memory nel file di configurazione (<filename>/etc/xen/testxen.cfg</filename>, in questo caso). Qui è stata impostata a 1024 (megabyte)."

msgid "<primary><filename>/etc</filename></primary><secondary><filename>/etc/xen/testxen.cfg</filename></secondary>"
msgstr "<primary><filename>/etc</filename></primary><secondary><filename>/etc/xen/testxen.cfg</filename></secondary>"

msgid ""
"<computeroutput># </computeroutput><userinput>xl list\n"
"</userinput><computeroutput>Name                                        ID   Mem VCPUs\tState\tTime(s)\n"
"Domain-0                                     0  3918     2     r-----      35.1\n"
"# </computeroutput><userinput>xl create /etc/xen/testxen.cfg\n"
"</userinput><computeroutput>Parsing config from /etc/xen/testxen.cfg\n"
"# </computeroutput><userinput>xl list\n"
"</userinput><computeroutput>Name                                        ID   Mem VCPUs\tState\tTime(s)\n"
"Domain-0                                     0  2757     2     r-----      45.2\n"
"testxen                                      3  1024     1     r-----       1.3\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>xl list\n</userinput><computeroutput>Name                                        ID   Mem VCPUs\tState\tTime(s)\nDomain-0                                     0  3918     2     r-----      35.1\n# </computeroutput><userinput>xl create /etc/xen/testxen.cfg\n</userinput><computeroutput>Parsing config from /etc/xen/testxen.cfg\n# </computeroutput><userinput>xl list\n</userinput><computeroutput>Name                                        ID   Mem VCPUs\tState\tTime(s)\nDomain-0                                     0  2757     2     r-----      45.2\ntestxen                                      3  1024     1     r-----       1.3\n</computeroutput>"

msgid "<emphasis>TOOL</emphasis> Choice of toolstacks to manage Xen VM"
msgstr "<emphasis>STRUMENTO</emphasis> Scelta dei toolstack per gestire Xen VM"

msgid "<primary><command>xm</command></primary>"
msgstr "<primary><command>xm</command></primary>"

msgid "<primary><command>xe</command></primary>"
msgstr "<primary><command>xe</command></primary>"

msgid "<primary><command>virsh</command></primary>"
msgstr "<primary><command>virsh</command></primary>"

msgid "<primary><emphasis role=\"pkg\">libvirt</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">libvirt</emphasis></primary>"

msgid "In Debian 7 and older releases, <command>xm</command> was the reference command line tool to use to manage Xen virtual machines. It has now been replaced by <command>xl</command> which is mostly backwards compatible. But those are not the only available tools: <command>virsh</command> of <emphasis role=\"pkg\">libvirt</emphasis> and <command>xe</command> of XenServer's XAPI (commercial offering of Xen) are alternative tools."
msgstr "In Debian 7 e nelle versioni precedenti, <command>xm</command> è stato lo strumento da riga di comando di riferimento da utilizzare per gestire le macchine virtuali Xen. Ora è stato sostituito da <command>xl</command> che è per lo più compatibile con xm. Ma questi non sono gli unici strumenti a disposizione: <command>virsh</command> di <emphasis role=\"pkg\">libvirt</emphasis> e <command>xe</command> per XAPI di XenServer (offerta commerciale di Xen) sono strumenti alternativi."

msgid "<emphasis>CAUTION</emphasis> Only one domU per image!"
msgstr "<emphasis>ATTENZIONE</emphasis> Solo un domU per immagine!"

msgid "While it is of course possible to have several domU systems running in parallel, they will all need to use their own image, since each domU is made to believe it runs on its own hardware (apart from the small slice of the kernel that talks to the hypervisor). In particular, it isn't possible for two domU systems running simultaneously to share storage space. If the domU systems are not run at the same time, it is, however, quite possible to reuse a single swap partition, or the partition hosting the <filename>/home</filename> filesystem."
msgstr "Anche se è ovviamente possibile far girare più sistemi domU in parallelo, ognuno di essi deve usare la propria immagine, dal momento che ad ogni domU viene fatto crede di girare sul proprio hardware (a parte la piccola parte del kernel che parla all'ipervisore). In particolare, non è possibile che due sistemi domU in esecuzione contemporanea condividano uno spazio di archiviazione. Se tuttavia i sistemi domU non sono contemporaneamente in esecuzione, è tuttavia possibile riutilizzare una singola partizione di swap o la partizione che ospita il filesystem <filename>/home</filename>."

msgid "Note that the <filename>testxen</filename> domU uses real memory taken from the RAM that would otherwise be available to the dom0, not simulated memory. Care should therefore be taken, when building a server meant to host Xen instances, to provision the physical RAM accordingly."
msgstr "Notare che il domU <filename>testxen</filename> usa memoria fisica presa dalla RAM che altrimenti sarebbe disponibile per il dom0, non memoria simulata. Pertanto bisogna fare attenzione, quando si assembla un server che deve ospitare istanze di Xen, a fornire RAM fisica secondo le necessità."

msgid "Voilà! Our virtual machine is starting up. We can access it in one of two modes. The usual way is to connect to it “remotely” through the network, as we would connect to a real machine; this will usually require setting up either a DHCP server or some DNS configuration. The other way, which may be the only way if the network configuration was incorrect, is to use the <filename>hvc0</filename> console, with the <command>xl console</command> command:"
msgstr "Voilà! La macchina virtuale è partita. Vi si può accedere in uno dei due modi. Il modo consueto è di connettersi ad essa \"in remoto\" tramite la rete, come ci si connetterebbe a una macchina reale; questo di solito richiederà di impostare un server DHCP o qualche configurazione di DNS. L'altro modo, che potrebbe essere l'unico se la configurazione di rete era errata, è di usare la console <filename>hvc0</filename>, con il comando <command>xl console</command>:"

msgid "<primary>Xen</primary><secondary><literal>hvc0</literal></secondary>"
msgstr "<primary>Xen</primary><secondary><literal>hvc0</literal></secondary>"

msgid ""
"<computeroutput># </computeroutput><userinput>xl console testxen</userinput>\n"
"<computeroutput>[...]\n"
"\n"
"Debian GNU/Linux 11 testxen hvc0\n"
"\n"
"testxen login: </computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>xl console testxen</userinput>\n<computeroutput>[...]\n\nDebian GNU/Linux 11 testxen hvc0\n\ntestxen login: </computeroutput>"

msgid "One can then open a session, just like one would do if sitting at the virtual machine's keyboard. Detaching from this console is achieved through the <keycombo action=\"simul\"><keycap>Control</keycap> <keycap>]</keycap></keycombo> key combination."
msgstr "A questo punto si può aprire una sessione, proprio come si farebbe davanti alla tastiera della macchina virtuale. Lo scollegamento da questa console si ottiene con la combinazione di tasti <keycombo action=\"simul\"><keycap>Control</keycap> <keycap>]</keycap></keycombo>."

msgid "<emphasis>TIP</emphasis> Getting the console straight away"
msgstr "<emphasis>SUGGERIMENTO</emphasis> Arrivare subito alla console"

msgid "<primary>Xen</primary><secondary>console</secondary>"
msgstr "<primary>Xen</primary><secondary>console</secondary>"

msgid "Sometimes one wishes to start a domU system and get to its console straight away; this is why the <command>xl create</command> command takes a <literal>-c</literal> switch. Starting a domU with this switch will display all the messages as the system boots."
msgstr "Qualche volta si vuole avviare un sistema domU e arrivare subito alla sua console; per questo motivo il comando <command>xl create</command> accetta l'opzione <literal>-c</literal>. Avviando un domU con questa opzione verranno visualizzati tutti i messaggi durante l'avvio del sistema."

msgid "<emphasis>TOOL</emphasis> Graphical Xen managers"
msgstr "<emphasis>STRUMENTO</emphasis> Gestori grafici di Xen"

msgid "<primary>Xen</primary><secondary>manager</secondary>"
msgstr "<primary>Xen</primary><secondary>gestore</secondary>"

msgid "OpenXenManager (in the <emphasis role=\"pkg\">openxenmanager</emphasis> package), a graphical interface allowing remote management of Xen domains via Xen's API, is no longer provided by Debian due to the lack of upstream development. If you are looking for a replacement, <emphasis role=\"pkg\">virt-manager</emphasis> provides support to handle Xen VMs as well."
msgstr "OpenXenManager (nel pacchetto <emphasis role=\"pkg\">openxenmanager</emphasis>) è un'interfaccia grafica che permette il controllo remoto di domini Xen attraverso un'API di Xen, non è più fornito da Debian a causa della mancanza di sviluppo upstream. Se si sta cercando un rimpiazzo, <emphasis role=\"pkg\">virt-manager</emphasis> fornisce anch'esso supporto per gestire macchine virtuali di Xen."

msgid "<primary><emphasis role=\"pkg\">openxenmanager</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">openxenmanager</emphasis></primary>"

msgid "<primary><emphasis role=\"pkg\">virt-manager</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">virt-manager</emphasis></primary>"

msgid "Once the domU is up, it can be used just like any other server (since it is a GNU/Linux system after all). However, its virtual machine status allows some extra features. For instance, a domU can be temporarily paused then resumed, with the <command>xl pause</command> and <command>xl unpause</command> commands. Note that even though a paused domU does not use any processor power, its allocated memory is still in use. It may be interesting to consider the <command>xl save</command> and <command>xl restore</command> commands: saving a domU frees the resources that were previously used by this domU, including RAM. When restored (or unpaused, for that matter), a domU doesn't even notice anything beyond the passage of time. If a domU was running when the dom0 is shut down, the packaged scripts automatically save the domU, and restore it on the next boot. This will of course involve the standard inconvenience incurred when hibernating a laptop computer, for instance; in particular, if the domU is suspended for too long, network connections may expire. Note also that Xen is so far incompatible with a large part of ACPI power management, which precludes suspending the host (dom0) system."
msgstr "Una volta che il domU è attivo, può essere usato come qualunque altro server (visto che dopo tutto è un sistema GNU/Linux). Tuttavia, il suo stato di macchina virtuale permette di sfruttare alcune funzionalità aggiuntive. Ad esempio, un domU può essere temporaneamente messo in pausa e poi fatto uscire dalla pausa con i comandi <command>xl pause</command> e <command>xl unpause</command>. Notare che, sebbene un domU in pausa non usi affatto il processore, la memoria ad esso allocata è ancora in uso. Può essere interessante considerare i comandi <command>xl save</command> e <command>xl restore</command>: salvare un domU libera le risorse precedentemente usate da questo domU, compresa la RAM. Al ripristino (o all'uscita dalla pausa, se è per quello) un domU non si accorge di alcunché al di là del passare del tempo. Se un domU era in esecuzione quando il dom0 viene spento, gli script nel pacchetto salvano automaticamente il domU e lo ripristinano all'avvio successivo. Questo ovviamente comporterà i consueti inconvenienti che si riscontrano quando si iberna un computer portatile, per esempio; in particolare, se il domU viene sospeso per troppo tempo, le connessioni di rete possono scadere. Notare inoltre che a tutt'oggi Xen è incompatibile con gran parte della gestione energetica ACPI, il che impedisce di sospendere il sistema host (dom0)."

msgid "<primary>Xen</primary><secondary>ACPI</secondary>"
msgstr "<primary>Xen</primary><secondary>ACPI</secondary>"

msgid "<primary>ACPI</primary>"
msgstr "<primary>ACPI</primary>"

msgid "Halting or rebooting a domU can be done either from within the domU (with the <command>shutdown</command> command) or from the dom0, with <command>xl shutdown</command> or <command>xl reboot</command>."
msgstr "Si può arrestare o riavviare un domU da dentro il domU (con il comando <command>shutdown</command>) o dal dom0, con <command>xm shutdown</command> o <command>xl reboot</command>."

msgid "Most of the <command>xl</command> subcommands expect one or more arguments, often a domU name. These arguments are well described in the <citerefentry><refentrytitle>xl</refentrytitle> <manvolnum>1</manvolnum></citerefentry> manual page."
msgstr "La maggior parte dei sottocomandi di <command>xl</command> richiedono uno o più argomenti, spesso il nome di un domU. Questi argomenti sono ben descritti nella magina di manuale <citerefentry><refentrytitle>xl</refentrytitle> <manvolnum>1</manvolnum></citerefentry>."

msgid "<emphasis>GOING FURTHER</emphasis> Advanced Xen"
msgstr "<emphasis>APPROFONDIMENTO</emphasis> Xen avanzato"

msgid "<primary>Xen</primary><secondary>documentation</secondary>"
msgstr "<primary>Xen</primary><secondary>documentazione</secondary>"

msgid "Xen has many more features than we can describe in these few paragraphs. In particular, the system is very dynamic, and many parameters for one domain (such as the amount of allocated memory, the visible hard drives, the behavior of the task scheduler, and so on) can be adjusted even when that domain is running. A domU can even be migrated across servers without being shut down, and without losing its network connections! For all these advanced aspects, the primary source of information is the official Xen documentation. <ulink type=\"block\" url=\"https://xenproject.org/help/documentation/\" />"
msgstr "Xen ha molte più funzionalità di quanto si possa descrivere in questi pochi paragrafi. In particolare, il sistema è molto dinamico e molti parametri di un dominio (come la quantità di memoria allocata, i dischi fissi visibili, il comportamento dello schedulatore di attività e così via) possono essere regolati anche quando quel dominio è in esecuzione. Un domU può anche essere migrato su un altro server senza venire spento e senza perdere le sue connessioni di rete! Per tutti questi aspetti avanzati, la fonte primaria di informazioni è la documentazione ufficiale di Xen. <ulink type=\"block\" url=\"https://xenproject.org/help/documentation/\" />"

msgid "<primary>Linux Containers</primary><see>LXC</see>"
msgstr "<primary>Contenitori per Linux</primary><see>LXC</see>"

msgid "<primary>kernel</primary><secondary>control groups</secondary>"
msgstr "<primary>kernel</primary><secondary>gruppi di controllo</secondary>"

msgid "Even though it is used to build “virtual machines”, LXC is not, strictly speaking, a virtualization system, but a system to isolate groups of processes from each other even though they all run on the same host. It takes advantage of a set of recent evolutions in the Linux kernel, collectively known as <emphasis>control groups</emphasis>, by which different sets of processes called “groups” have different views of certain aspects of the overall system. Most notable among these aspects are the process identifiers, the network configuration, and the mount points. Such a group of isolated processes will not have any access to the other processes in the system, and its accesses to the filesystem can be restricted to a specific subset. It can also have its own network interface and routing table, and it may be configured to only see a subset of the available devices present on the system."
msgstr "Anche se è usato per costruire \"macchine virtuali\", LXC non è, propriamente, un sistema di virtualizzazione, ma un sistema per isolare gruppi di processi l'uno dall'altro pur girando tutti sullo stesso host. Sfrutta alcune evoluzioni recenti nel kernel Linux, comunemente note come <emphasis>gruppi di controllo</emphasis>, con cui diversi insiemi di processi chiamati \"gruppi\" hanno visioni diverse di certi aspetti del sistema globale. Fra questi aspetti, i più importanti sono gli identificatori dei processi, la configurazione di rete e i punti di mount. Tale gruppo di processi isolati non avrà accesso agli altri processi nel sistema, ed i suoi accessi al file system possono essere ristretti a uno specifico sottoinsieme. Può anche avere la propria interfaccia di rete e la propria tabella di routing e può essere configurato per vedere solo un sottoinsieme dei dispositivi disponibili presenti sul sistema."

msgid "<primary>container</primary>"
msgstr "<primary>contenitore</primary>"

msgid "These features can be combined to isolate a whole process family starting from the <command>init</command> process, and the resulting set looks very much like a virtual machine. The official name for such a setup is a “container” (hence the LXC moniker: <emphasis>LinuX Containers</emphasis>), but a rather important difference with “real” virtual machines such as provided by Xen or KVM is that there is no second kernel; the container uses the very same kernel as the host system. This has both pros and cons: advantages include excellent performance due to the total lack of overhead, and the fact that the kernel has a global vision of all the processes running on the system, so the scheduling can be more efficient than it would be if two independent kernels were to schedule different task sets. Chief among the inconveniences is the impossibility to run a different kernel in a container (whether a different Linux version or a different operating system altogether)."
msgstr "Queste funzionalità possono essere combinate per isolare un'intera famiglia di processi a partire dal processo <command>init</command>, e l'insieme che ne risulta è molto simile ad una macchina virtuale. Il nome ufficiale per una impostazione come questa è \"contenitore\" (da cui il nomignolo LXC: <emphasis>LinuX Containers</emphasis>), ma una differenza piuttosto importante rispetto alle \"vere\" macchine virtuali come quelle fornite da Xen o KVM è che non c'è un secondo kernel; il contenitore usa lo stesso kernel del sistema host. Questo ha sia dei pro che dei contro: fra i vantaggi ci sono prestazioni eccellenti data la totale assenza di carico aggiuntivo e il fatto che il kernel ha una visione globale di tutti i processi che girano sul sistema, quindi la schedulazione può essere più efficiente rispetto al caso in cui due kernel indipendenti dovessero schedulare diversi insiemi di attività. Il principale svantaggio è l'impossibilità di far girare un diverso kernel in un contenitore (sia una diversa versione di Linux sia un sistema operativo del tutto diverso)."

msgid "<emphasis>NOTE</emphasis> LXC isolation limits"
msgstr "<emphasis>NOTA</emphasis> Limiti di isolamento di LXC"

msgid "LXC containers do not provide the level of isolation achieved by heavier emulators or virtualizers. In particular:"
msgstr "I contenitori LXC non forniscono il livello di isolamento raggiunto da emulatori o virtualizzatori più pesanti. In particolare:"

msgid "since the kernel is shared among the host system and the containers, processes constrained to containers can still access the kernel messages, which can lead to information leaks if messages are emitted by a container;"
msgstr "poiché il kernel è condiviso fra il sistema host e i contenitori, i processi limitati ai contenitori possono ancora accedere ai messaggi del kernel, il che può portare a fughe di informazioni se i messaggi sono emessi da un contenitore;"

msgid "for similar reasons, if a container is compromised and a kernel vulnerability is exploited, the other containers may be affected too;"
msgstr "per ragioni simili, se un contenitore è compromesso e viene sfruttata una vulnerabilità del kernel, gli altri contenitori possono anch'essi esserne affetti;"

msgid "on the filesystem, the kernel checks permissions according to the numerical identifiers for users and groups; these identifiers may designate different users and groups depending on the container, which should be kept in mind if writable parts of the filesystem are shared among containers."
msgstr "sul file system, il kernel controlla i permessi in base agli identificativi numerici per utenti e gruppi; questi identificativi possono designare utenti e gruppi diversi a seconda del contenitore, cosa di cui tener conto se si condividono parti scrivibili del file system fra i contenitori."

msgid "Since we are dealing with isolation and not plain virtualization, setting up LXC containers is more complex than just running debian-installer on a virtual machine. We will describe a few prerequisites, then go on to the network configuration; we will then be able to actually create the system to be run in the container."
msgstr "Poiché si parla di isolamento e non di virtualizzazione vera e propria, impostare i contenitori LXC è più complesso che far girare debian-installer su una macchina virtuale. Verranno descritti alcuni prerequisiti, e poi si passerà alla configurazione di rete; a questo punto si potrà effettivamente creare il sistema da far girare nel contenitore."

msgid "Preliminary Steps"
msgstr "Passi preliminari"

msgid "<primary><emphasis role=\"pkg\">lxc</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">lxc</emphasis></primary>"

msgid "The <emphasis role=\"pkg\">lxc</emphasis> package contains the tools required to run LXC, and must therefore be installed."
msgstr "Il pacchetto <emphasis role=\"pkg\">lxc</emphasis> contiene gli strumenti necessari per far girare LXC e quindi deve essere installato."

msgid "<primary><filename>/sys</filename></primary><secondary><filename>/sys/fs/cgroup</filename></secondary>"
msgstr "<primary><filename>/sys</filename></primary><secondary><filename>/sys/fs/cgroup</filename></secondary>"

msgid "LXC also requires the <emphasis>control groups</emphasis> configuration system, which is a virtual filesystem to be mounted on <filename>/sys/fs/cgroup</filename>. Since Debian 8 switched to systemd, which also relies on control groups, this is now done automatically at boot time without further configuration."
msgstr "LXC richiede anche il sistema di configurazione dei <emphasis>gruppi di controllo</emphasis>, che è un filesystem virtuale da montare su <filename>/sys/fs/cgroup</filename>. Dal momento che Debian 8 è passata a systemd, che si basa anche su gruppi di controllo, questo ora è fatto automaticamente al boot senza ulteriori configurazioni."

msgid "Network Configuration"
msgstr "Configurazione di rete"

msgid "<primary>LXC</primary><secondary>network configuration</secondary>"
msgstr "<primary>LXC</primary><secondary>configurazione della rete</secondary>"

msgid "The goal of installing LXC is to set up virtual machines; while we could, of course, keep them isolated from the network, and only communicate with them via the filesystem, most use cases involve giving at least minimal network access to the containers. In the typical case, each container will get a virtual network interface, connected to the real network through a bridge. This virtual interface can be plugged either directly onto the host's physical network interface (in which case the container is directly on the network), or onto another virtual interface defined on the host (and the host can then filter or route traffic). In both cases, the <emphasis role=\"pkg\">bridge-utils</emphasis> package will be required."
msgstr "Lo scopo dell'installazione di LXC è di impostare delle macchine virtuali; pur potendo, ovviamente, tenerle isolate dalla rete e comunicare con loro solo tramite il filesystem, la maggior parte dei casi d'uso richiede di dare almeno un minimo accesso di rete ai contenitori. Nel caso tipico, ciascun contenitore avrà un'interfaccia di rete virtuale, connessa con la rete reale tramite un bridge. Questa interfaccia virtuale può essere inserita direttamente sull'interfaccia fisica di rete dell'host (nel qual caso il contenitore è direttamente in rete) o su un'altra interfaccia virtuale definita sull'host (e l'host può allora filtrare o ridirigere il traffico). In entrambi i casi, sarà necessario il pacchetto <emphasis role=\"pkg\">bridge-utils</emphasis>."

msgid "The simple case is just a matter of editing <filename>/etc/network/interfaces</filename>, moving the configuration for the physical interface (for instance, <literal>eth0</literal> or <literal>enp1s0</literal>) to a bridge interface (usually <literal>br0</literal>), and configuring the link between them. For instance, if the network interface configuration file initially contains entries such as the following:"
msgstr "Nel caso più semplice richiede solo di modificare <filename>/etc/network/interfaces</filename>, spostando la configurazione dell'interfaccia fisica (per esempio <literal>eth0</literal> o <literal>enp1s0</literal>) su un'interfaccia bridge (di solito <literal>br0</literal>) e configurare il collegamento fra di loro. Per esempio, se il file di configurazione dell'interfaccia di rete contiene inizialmente voci come le seguenti:"

msgid "<primary>network</primary><secondary><literal>br</literal> interface</secondary>"
msgstr "<primary>rete</primary><secondary><literal>br</literal> interfaccia</secondary>"

msgid "<primary><literal>br</literal>, network interface</primary>"
msgstr "<primary><literal>br</literal>, interfaccia di rete</primary>"

msgid ""
"auto eth0\n"
"iface eth0 inet dhcp"
msgstr ""
"auto eth0\n"
"iface eth0 inet dhcp"

msgid "They should be disabled and replaced with the following:"
msgstr "Devono essere disabilitate e sostituite con le seguenti:"

msgid ""
"auto br0\n"
"iface br0 inet dhcp\n"
"    bridge-ports <replaceable>eth0</replaceable>"
msgstr "auto br0\niface br0 inet dhcp\n    bridge-ports <replaceable>eth0</replaceable>"

msgid "The effect of this configuration will be similar to what would be obtained if the containers were machines plugged into the same physical network as the host. The “bridge” configuration manages the transit of Ethernet frames between all the bridged interfaces, which includes the physical <literal>eth0</literal> as well as the interfaces defined for the containers."
msgstr "L'effetto di questa configurazione sarà simile a ciò che si otterrebbe se i contenitori fossero macchine collegate alla stessa rete fisica dell'host. La configurazione «bridge» gestisce il transito dei frame Ethernet fra tutte le interfacce in bridge, il che include la <literal>eth0</literal> fisica oltre alle interfacce definite per i contenitori."

msgid "<primary>network</primary><secondary><literal>tap</literal> interface</secondary>"
msgstr "<primary>rete</primary><secondary><literal>tap</literal> interfaccia</secondary>"

msgid "In cases where this configuration cannot be used (for instance, if no public IP addresses can be assigned to the containers), a virtual <emphasis>tap</emphasis> interface will be created and connected to the bridge. The equivalent network topology then becomes that of a host with a second network card plugged into a separate switch, with the containers also plugged into that switch. The host must then act as a gateway for the containers if they are meant to communicate with the outside world."
msgstr "Nei casi in cui questa configurazione non si può usare (per esempio, se non si possono assegnare IP pubblici ai contenitori), un'interfaccia virtuale <emphasis>tap</emphasis> verrà creata e connessa al bridge. A quel punto la topologia di rete equivalente diventa quella di un host con una seconda scheda di rete inserita in uno switch separato, con i contenitori anch'essi inseriti in quello switch. L'host allora deve agire da gateway per i contenitori se questi devono comunicare con il mondo esterno."

msgid "In addition to <emphasis role=\"pkg\">bridge-utils</emphasis>, this “rich” configuration requires the <emphasis role=\"pkg\">vde2</emphasis> package; the <filename>/etc/network/interfaces</filename> file then becomes:"
msgstr "Oltre a <emphasis role=\"pkg\">bridge-utils</emphasis>, questa configurazione «ricca» richiede il pacchetto <emphasis role=\"pkg\">vde2</emphasis>; il file <filename>/etc/network/interfaces</filename> allora diventa:"

msgid "<primary><emphasis role=\"pkg\">vde2</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">vde2</emphasis></primary>"

msgid ""
"# Interface eth0 is unchanged\n"
"auto eth0\n"
"iface eth0 inet dhcp\n"
"\n"
"# Virtual interface \n"
"auto tap0\n"
"iface tap0 inet manual\n"
"    vde2-switch -t tap0\n"
"\n"
"# Bridge for containers\n"
"auto br0\n"
"iface br0 inet static\n"
"    bridge-ports tap0\n"
"    address 10.0.0.1\n"
"    netmask 255.255.255.0"
msgstr "# l'interfaccia eth0 è invariata\nauto eth0\niface eth0 inet dhcp\n\n# interfaccia virtuale\nauto tap0\niface tap0 inet manual\n    vde2-switch -t tap0\n\n# Bridge per i contenitori\nauto br0\niface br0 inet static\n    bridge-ports tap0\n    address 10.0.0.1\n    netmask 255.255.255.0"

msgid "The network can then be set up either statically in the containers, or dynamically with DHCP server running on the host. Such a DHCP server will need to be configured to answer queries on the <literal>br0</literal> interface."
msgstr "La rete allora può essere impostata staticamente nei contenitori o dinamicamente con un server DHCP che gira sull'host. Tale server DHCP dovrà essere configurato per rispondere alle richieste sull'interfaccia <literal>br0</literal>."

msgid "Setting Up the System"
msgstr "Impostazione del sistema"

msgid "Let us now set up the filesystem to be used by the container. Since this “virtual machine” will not run directly on the hardware, some tweaks are required when compared to a standard filesystem, especially as far as the kernel, devices and consoles are concerned. Fortunately, the <emphasis role=\"pkg\">lxc</emphasis> package includes scripts that mostly automate this configuration. For instance, the following commands (which require the <emphasis role=\"pkg\">debootstrap</emphasis> and <emphasis role=\"pkg\">rsync</emphasis> packages) will install a Debian container:"
msgstr "Ora si imposta il filesystem che il contenitore dovrà usare. Poiché questa \"macchina virtuale\" non girerà direttamente sull'hardware, servono alcuni accorgimenti rispetto a un filesystem standard, in particolare riguardo al kernel, i dispositivi e le console. Per fortuna, il pacchetto <emphasis role=\"pkg\">lxc</emphasis> include degli script che automatizzano gran parte di questa configurazione. Per esempio, i seguenti comandi (che richiedono i pacchetti <emphasis role=\"pkg\">debootstrap</emphasis> e <emphasis role=\"pkg\">rsync</emphasis>) installeranno un contenitore Debian:"

msgid ""
"<computeroutput># </computeroutput><userinput>lxc-create -n testlxc -t debian\n"
"</userinput><computeroutput>debootstrap is /usr/sbin/debootstrap\n"
"Checking cache download in /var/cache/lxc/debian/rootfs-stable-amd64 ... \n"
"Downloading debian minimal ...\n"
"I: Retrieving Release \n"
"I: Retrieving Release.gpg \n"
"[...]\n"
"Download complete.\n"
"Copying rootfs to /var/lib/lxc/testlxc/rootfs...\n"
"[...]\n"
"# </computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>lxc-create -n testlxc -t debian\n</userinput><computeroutput>debootstrap is /usr/sbin/debootstrap\nChecking cache download in /var/cache/lxc/debian/rootfs-stable-amd64 ... \nDownloading debian minimal ...\nI: Retrieving Release \nI: Retrieving Release.gpg \n[...]\nDownload complete.\nCopying rootfs to /var/lib/lxc/testlxc/rootfs...\n[...]\n# </computeroutput>"

msgid "Note that the filesystem is initially created in <filename>/var/cache/lxc</filename>, then moved to its destination directory. This allows creating identical containers much more quickly, since only copying is then required."
msgstr "Notare che il file system è creato all'inizio in <filename>/var/cache/lxc</filename> e poi spostato nella sua directory di destinazione. Ciò permette di creare contenitori identici molto più rapidamente, visto che a questo punto basta copiarli."

msgid "Note that the Debian template creation script accepts an <option>--arch</option> option to specify the architecture of the system to be installed and a <option>--release</option> option if you want to install something else than the current stable release of Debian. You can also set the <literal>MIRROR</literal> environment variable to point to a local Debian mirror."
msgstr "Da notare che lo script per la creazione dei modelli Debian accetta l'opzione <option>--arch</option> per specificare l'architettura del sistema da installare ed un'opzione <option>--release</option> se si vuole installare qualcos'altro rispetto all'attuale versione stabile di Debian. È anche possibile impostare la variabile d'ambiente <literal>MIRROR</literal> per puntare ad un mirror locale di Debian."

msgid "The <emphasis role=\"pkg\">lxc</emphasis> package further creates a bridge interface <literal>lxcbr0</literal>, which by default is used by all newly created containers via <filename>/etc/lxc/default.conf</filename> and the <filename>lxc-net</filename> service:"
msgstr "Il pacchetto <emphasis role=\"pkg\">lxc</emphasis> crea inoltre un'interfaccia bridge <literal>lxcbr0</literal>, che viene usata, in modo predefinito, da tutti i nuovi contenitori creati tramite <filename>/etc/lxc/default.conf</filename> e il servizio <filename>lxc-net</filename>:"

msgid "<primary><filename>/etc</filename></primary><secondary><filename>/etc/lxc/default.conf</filename></secondary>"
msgstr "<primary><filename>/etc</filename></primary><secondary><filename>/etc/lxc/default.conf</filename></secondary>"

msgid "<primary>service</primary><secondary><filename>lxc-net.service</filename></secondary>"
msgstr "<primary>servizio</primary><secondary><filename>lxc-net.service</filename></secondary>"

msgid "<primary>network</primary><secondary><literal>veth</literal> interface</secondary>"
msgstr "<primary>rete</primary><secondary><literal>veth</literal> interfaccia</secondary>"

msgid "<primary><literal>veth</literal>, network interface</primary>"
msgstr "<primary><literal>veth</literal>, interfaccia di rete</primary>"

msgid ""
"lxc.net.0.type = veth\n"
"lxc.net.0.link = lxcbr0\n"
"lxc.net.0.flags = up"
msgstr "lxc.net.0.type = veth\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up"

msgid "These entries mean, respectively, that a virtual interface will be created in every new container; that it will automatically be brought up when said container is started; and that it will be automatically connected to the <literal>lxcbr0</literal> bridge on the host. You will find these settings in the created container's configuration (<filename>/var/lib/lxc/testlxc/config</filename>), where also the device' MAC address will be specified in <literal>lxc.net.0.hwaddr</literal>. Should this last entry be missing or disabled, a random MAC address will be generated."
msgstr "Queste voci vogliono dire, rispettivamente, che verrà creata un'interfaccia virtuale in ogni nuovo contenitore; che verrà automaticamente attivata quando il suddetto contenitore verrà avviato; e che verrà automaticamente connessa al bridge <literal>lxcbr0</literal> sull'host. Queste impostazioni sono presenti nella configurazione del contenitore creato (<filename>/var/lib/lxc/testlxc/config</filename>), anche l'indirizzo MAC del dispositivo sarà contenuto in <literal>lxc.net.0.hwaddr</literal>. Se quest'ultima voce fosse assente o disabilitata, verrà generato un indirizzo MAC casuale."

msgid "<primary>LXC</primary><secondary>container configuration</secondary>"
msgstr "<primary>LXC</primary><secondary>configurazione del contenitore</secondary>"

msgid "Another useful entry in that file is the setting of the hostname:"
msgstr "Un'altra voce di utile in quel file è l'impostazione del nome host:"

msgid "lxc.uts.name = testlxc"
msgstr "lxc.uts.name = testlxc"

msgid "The newly-created filesystem now contains a minimal Debian system and a network interface."
msgstr "Il nuovo filesystem creato ora contiene un sistema Debian minimale e un'interfaccia di rete."

msgid "Starting the Container"
msgstr "Avvio del contenitore"

msgid "<primary>LXC</primary><secondary><command>lxc-start</command></secondary>"
msgstr "<primary>LXC</primary><secondary><command>lxc-start</command></secondary>"

msgid "<primary>LXC</primary><secondary><command>lxc-attach</command></secondary>"
msgstr "<primary>LXC</primary><secondary><command>lxc-attach</command></secondary>"

msgid "Now that our virtual machine image is ready, let's start the container with <command>lxc-start --name=testlxc</command>."
msgstr "Ora che l'immagine della macchina virtuale è pronta, si avvia il contenitore con <command>lxc-start --name=testlxc</command>."

msgid "In LXC releases following 2.0.8, root passwords are not set by default. We can set one running <command>lxc-attach -n testlxc <replaceable>passwd</replaceable></command> if we want. We can login with:"
msgstr "Nelle versioni di LXC successive alla 2.0.8 non vi è un'impostazione predefinita della password di root. Se si vuole è possibile impostarla eseguendo <command>lxc-attach -n testlxc <replaceable>passwd</replaceable></command>. È possibile accedere con:"

msgid ""
"<computeroutput># </computeroutput><userinput>lxc-console -n testlxc\n"
"</userinput><computeroutput><![CDATA[Connected to tty 1\n"
"Type <Ctrl+a q> to exit the console, <Ctrl+a Ctrl+a> to enter Ctrl+a itself\n"
"\n"
"Debian GNU/Linux 11 testlxc tty1\n"
"\n"
"testlxc login: ]]></computeroutput><userinput>root</userinput><computeroutput>\n"
"Password: \n"
"Linux testlxc 5.10.0-11-amd64 #1 SMP Debian 5.10.92-1 (2022-01-18) x86_64\n"
"\n"
"The programs included with the Debian GNU/Linux system are free software;\n"
"the exact distribution terms for each program are described in the\n"
"individual files in /usr/share/doc/*/copyright.\n"
"\n"
"Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\n"
"permitted by applicable law.\n"
"Last login: Wed Mar  9 01:45:21 UTC 2022 on console\n"
"root@testlxc:~# </computeroutput><userinput>ps auxwf\n"
"</userinput><computeroutput>USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n"
"root           1  0.0  0.2  18964 11464 ?        Ss   01:36   0:00 /sbin/init\n"
"root          45  0.0  0.2  31940 10396 ?        Ss   01:37   0:00 /lib/systemd/systemd-journald\n"
"root          71  0.0  0.1  99800  5724 ?        Ssl  01:37   0:00 /sbin/dhclient -4 -v -i -pf /run/dhclient.eth0.pid [..]\n"
"root          97  0.0  0.1  13276  6980 ?        Ss   01:37   0:00 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups\n"
"root         160  0.0  0.0   6276  3928 pts/0    Ss   01:46   0:00 /bin/login -p --\n"
"root         169  0.0  0.0   7100  3824 pts/0    S    01:51   0:00  \\_ -bash\n"
"root         172  0.0  0.0   9672  3348 pts/0    R+   01:51   0:00      \\_ ps auxwf\n"
"root         164  0.0  0.0   5416  2128 pts/1    Ss+  01:49   0:00 /sbin/agetty -o -p -- \\u --noclear [...]\n"
"root@testlxc:~# </computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>lxc-console -n testlxc\n</userinput><computeroutput><![CDATA[Connected to tty 1\nType <Ctrl+a q> to exit the console, <Ctrl+a Ctrl+a> to enter Ctrl+a itself\n\nDebian GNU/Linux 11 testlxc tty1\n\ntestlxc login: ]]></computeroutput><userinput>root</userinput><computeroutput>\nPassword: \nLinux testlxc 5.10.0-11-amd64 #1 SMP Debian 5.10.92-1 (2022-01-18) x86_64\n\nThe programs included with the Debian GNU/Linux system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\n\nDebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\npermitted by applicable law.\nLast login: Wed Mar  9 01:45:21 UTC 2022 on console\nroot@testlxc:~# </computeroutput><userinput>ps auxwf\n</userinput><computeroutput>USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.2  18964 11464 ?        Ss   01:36   0:00 /sbin/init\nroot          45  0.0  0.2  31940 10396 ?        Ss   01:37   0:00 /lib/systemd/systemd-journald\nroot          71  0.0  0.1  99800  5724 ?        Ssl  01:37   0:00 /sbin/dhclient -4 -v -i -pf /run/dhclient.eth0.pid [..]\nroot          97  0.0  0.1  13276  6980 ?        Ss   01:37   0:00 sshd: /usr/sbin/sshd -D [listener] 0 of 10-100 startups\nroot         160  0.0  0.0   6276  3928 pts/0    Ss   01:46   0:00 /bin/login -p --\nroot         169  0.0  0.0   7100  3824 pts/0    S    01:51   0:00  \\_ -bash\nroot         172  0.0  0.0   9672  3348 pts/0    R+   01:51   0:00      \\_ ps auxwf\nroot         164  0.0  0.0   5416  2128 pts/1    Ss+  01:49   0:00 /sbin/agetty -o -p -- \\u --noclear [...]\nroot@testlxc:~# </computeroutput>"

msgid "We are now in the container; our access to the processes is restricted to only those started from the container itself, and our access to the filesystem is similarly restricted to the dedicated subset of the full filesystem (<filename>/var/lib/lxc/testlxc/rootfs</filename>). We can exit the console with <keycombo action=\"simul\"><keycap>Control</keycap> <keycap>a</keycap></keycombo> <keycombo><keycap>q</keycap></keycombo>."
msgstr "Ora ci si trova nel contenitore; l'accesso ai processi è ristretto solo a quelli avviati dal contenitore stesso e l'accesso al filesystem è analogamente ristretto al sottoinsieme dedicato del filesystem completo (<filename>/var/lib/lxc/testlxc/rootfs</filename>). Si può uscire dalla console con <keycombo action=\"simul\"><keycap>Control</keycap> <keycap>a</keycap></keycombo> <keycombo><keycap>q</keycap></keycombo>."

msgid "Note that we ran the container as a background process, thanks to <command>lxc-start</command> starting using the <option>--daemon</option> option by default. We can interrupt the container with a command such as <command>lxc-stop --name=testlxc</command>."
msgstr "Da notare che il contenitore è stato eseguito come processo in background, grazie all'avvio di <command>lxc-start</command> che usa in modo predefinito l'opzione <option>--daemon</option>. Si può interrompere l'esecuzione del contenitore con un comando del tipo <command>lxc-stop --name=testlxc</command>."

msgid "<primary>LXC</primary><secondary><command>lxc-stop</command></secondary>"
msgstr "<primary>LXC</primary><secondary><command>lxc-stop</command></secondary>"

msgid "The <emphasis role=\"pkg\">lxc</emphasis> package contains an initialization script that can automatically start one or several containers when the host boots (it relies on <command>lxc-autostart</command> which starts containers whose <literal>lxc.start.auto</literal> option is set to 1). Finer-grained control of the startup order is possible with <literal>lxc.start.order</literal> and <literal>lxc.group</literal>: by default, the initialization script first starts containers which are part of the <literal>onboot</literal> group and then the containers which are not part of any group. In both cases, the order within a group is defined by the <literal>lxc.start.order</literal> option."
msgstr "Il pacchetto <emphasis role=\"pkg\">lxc</emphasis> contiene uno script di inizializzazione che può avviare automaticamente uno o più contenitori quando si avvia l'host (si basa su <command>lxc-autostart</command> che avvia i contenitori che hanno l'opzione <literal>lxc.start.auto</literal> impostata a 1). Un controllo più dettagliato dell'ordine di avvio è possibile con <literal>lxc.start.order</literal> e <literal>lxc.group</literal>: per impostazione predefinita, lo script di inizializzazione avvia prima i contenitori che fanno parte del gruppo <literal>onboot</literal> e poi i contenitori che non fanno parte di alcun gruppo. In entrambi i casi, l'ordine all'interno di un gruppo è definito dall'opzione <literal>lxc.start.order</literal>."

msgid "<emphasis>GOING FURTHER</emphasis> Mass virtualization"
msgstr "<emphasis>APPROFONDIMENTO</emphasis> Virtualizzazione di massa"

msgid "Since LXC is a very lightweight isolation system, it can be particularly adapted to massive hosting of virtual servers. The network configuration will probably be a bit more advanced than what we described above, but the “rich” configuration using <literal>tap</literal> and <literal>veth</literal> interfaces should be enough in many cases."
msgstr "Poiché LXC è un sistema di isolamento molto leggero, si può adattare in particolare all'hosting massiccio di server virtuali. La configurazione di rete probabilmente sarà un po' più avanzata di quella descritta sopra, ma la configurazione «ricca» che usa le interfacce <literal>tap</literal> e <literal>veth</literal> dovrebbe bastare in molti casi."

msgid "It may also make sense to share part of the filesystem, such as the <filename>/usr</filename> and <filename>/lib</filename> subtrees, so as to avoid duplicating the software that may need to be common to several containers. This will usually be achieved with <literal>lxc.mount.entry</literal> entries in the containers configuration file. An interesting side-effect is that the processes will then use less physical memory, since the kernel is able to detect that the programs are shared. The marginal cost of one extra container can then be reduced to the disk space dedicated to its specific data, and a few extra processes that the kernel must schedule and manage."
msgstr "Può anche avere senso condividere parte del file system, come i sottoalberi <filename>/usr</filename> e <filename>/lib</filename>, così da evitare di duplicare software che dovrebbe essere in comune a diversi contenitori. Questo di solito si può fare aggiungendo delle voci <literal>lxc.mount.entry</literal> nei file di configurazione dei contenitori. Un effetto collaterale interessante è che in questo caso i processi useranno meno memoria fisica, dal momento che il kernel può rilevare che i programmi sono condivisi. Il costo marginale di un contenitore in più può quindi essere ridotto allo spazio su disco dedicato ai suoi dati specifici e alcuni processi aggiuntivi che il kernel deve ordinare e gestire."

msgid "We haven't described all the available options, of course; more comprehensive information can be obtained from the <citerefentry> <refentrytitle>lxc</refentrytitle> <manvolnum>7</manvolnum> </citerefentry> and <citerefentry> <refentrytitle>lxc.container.conf</refentrytitle> <manvolnum>5</manvolnum></citerefentry> manual pages and the ones they reference."
msgstr "Ovviamente non si sono descritte tutte le opzioni disponibili; informazioni più complete si possono ottenere dalle pagine di manuale <citerefentry> <refentrytitle>lxc</refentrytitle> <manvolnum>7</manvolnum> </citerefentry> e <citerefentry> <refentrytitle>lxc.container.conf</refentrytitle> <manvolnum>5</manvolnum></citerefentry> e da quelle a cui esse puntano."

msgid "Virtualization with KVM"
msgstr "Virtualizzazione con KVM"

msgid "<primary>Kernel-based Virtual Machine</primary><see>KVM</see>"
msgstr "<primary>Kernel-based Virtual Machine (Macchina Virtuale basata sul Kernel)</primary><see>KVM</see>"

msgid "KVM, which stands for <emphasis>Kernel-based Virtual Machine</emphasis>, is first and foremost a kernel module providing most of the infrastructure that can be used by a virtualizer, but it is not a virtualizer by itself. Actual control for the virtualization is handled by a QEMU-based application. Don't worry if this section mentions <command>qemu-*</command> commands: it is still about KVM."
msgstr "KVM, che sta per <emphasis>Kernel-based Virtual Machine (Macchina Virtuale basata su Kernel)</emphasis>, è prima di tutto un modulo del kernel che fornisce la maggior parte dell'infrastruttura che può essere usata da un virtualizzatore, ma di per sé non è un virtualizzatore. Il controllo effettivo della virtualizzazione è gestito da un'applicazione basata su QEMU. Non c'è da preoccuparsi se questa sezione menziona comandi <command>qemu-*</command>: si parla comunque di KVM."

msgid "Unlike other virtualization systems, KVM was merged into the Linux kernel right from the start. Its developers chose to take advantage of the processor instruction sets dedicated to virtualization (Intel-VT and AMD-V), which keeps KVM lightweight, elegant and not resource-hungry. The counterpart, of course, is that KVM doesn't work on any computer but only on those with appropriate processors. For x86-based computers, you can verify that you have such a processor by looking for “vmx” or “svm” in the CPU flags listed in <filename>/proc/cpuinfo</filename>."
msgstr "Contrariamente ad altri sistemi di virtualizzazione, KVM è stato incluso nel kernel Linux fin dall'inizio.I suoi sviluppatori hanno scelto di sfruttare le istruzioni dei processori dedicate alla virtualizzazione (Intel-VT e AMD-V), cosa che mantiene KVM leggero, elegante e parco di risorse. Il rovescio della medaglia, ovviamente, è che KVM non funziona su tutti i computer ma solo su quelli con procesori adatti. Per i computer x86-based, è possibile verificare di avere un tale processore cercando vmx” o “svm” tra i flag della CPU elencati in <filename>/proc/cpuinfo</filename>."

msgid "<primary><filename>/proc</filename></primary><secondary><filename>/proc/cpuinfo</filename></secondary>"
msgstr "<primary><filename>/proc</filename></primary><secondary><filename>/proc/cpuinfo</filename></secondary>"

msgid "With Red Hat actively supporting its development, KVM has more or less become the reference for Linux virtualization."
msgstr "Con il supporto attivo al suo sviluppo da parte di Red Hat, KVM sembra destinato a diventare il punto di riferimento per la virtualizzazione in Linux."

msgid "<primary><command>virt-install</command></primary>"
msgstr "<primary><command>virt-install</command></primary>"

msgid "Unlike such tools as VirtualBox, KVM itself doesn't include any user-interface for creating and managing virtual machines. The virtual <emphasis role=\"pkg\">qemu-kvm</emphasis> package only provides an executable able to start a virtual machine, as well as an initialization script that loads the appropriate kernel modules."
msgstr "Contrariamente a strumenti come VirtualBox, KVM di per sé non include nessuna interfaccia utente per creare e gestire macchine virtuali. Il pacchetto virtuale <emphasis role=\"pkg\">qemu-kvm</emphasis> fornisce solo un eseguibile in grado di avviare una macchina virtuale, oltre a uno script di inizializzazione che carica i moduli appropriati del kernel."

msgid "<primary>libvirt</primary>"
msgstr "<primary>libvirt</primary>"

msgid "<primary>OpenVZ</primary>"
msgstr "<primary>OpenVZ</primary>"

msgid "<primary>UML</primary>"
msgstr "<primary>UML</primary>"

msgid "Fortunately, Red Hat also provides another set of tools to address that problem, by developing the <emphasis>libvirt</emphasis> library and the associated <emphasis>virtual machine manager</emphasis> tools. libvirt allows managing virtual machines in a uniform way, independently of the virtualization system involved behind the scenes (it currently supports QEMU, KVM, Xen, LXC, OpenVZ, VirtualBox, VMWare, and UML). <command>virt-manager</command> is a graphical interface that uses <emphasis>libvirt</emphasis> to create and manage virtual machines."
msgstr "Per fortuna, Red Hat fornisce anche un altro insieme di strumenti per affrontare questo problema, sviluppando la libreria <emphasis>libvirt</emphasis> e gli strumenti <emphasis>virtual machine manager</emphasis> associati. libvirt permette di gestire macchine virtuali in modo uniforme, indipendentemente dal sistema di virtualizzazione dietro le quinte (attualmente supporta QEMU, KVM, Xen, LXC, OpenVZ, VirtualBox, VMWare e UML). <command>virt-manager</command> è un'interfaccia grafica che usa <emphasis>libvirt</emphasis> per creare e gestire macchine virtuali."

msgid "<primary><emphasis role=\"pkg\">virtinst</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">virtinst</emphasis></primary>"

msgid "<primary>daemon</primary><secondary>libvirtd</secondary>"
msgstr "<primary>demone</primary><secondary>libvirtd</secondary>"

msgid "<primary>service</primary><secondary><filename>libvirtd.service</filename></secondary>"
msgstr "<primary>servizio</primary><secondary><filename>libvirtd.service</filename></secondary>"

msgid "We first install the required packages, with <command>apt-get install libvirt-clients libvirt-daemon-system qemu-kvm virtinst virt-manager virt-viewer</command>. <emphasis role=\"pkg\">libvirt-daemon-system</emphasis> provides the <command>libvirtd</command> daemon, which allows (potentially remote) management of the virtual machines running of the host, and starts the required VMs when the host boots. <emphasis role=\"pkg\">libvirt-clients</emphasis> provides the <command>virsh</command> command-line tool, which allows controlling the <command>libvirtd</command>-managed machines."
msgstr "Prima di tutto si installano i pacchetti richiesti, con <command>apt-get install libvirt-clients libvirt-daemon-system qemu-kvm virtinst virt-manager virt-viewer</command>. <emphasis role=\"pkg\">libvirt-daemon-system</emphasis> fornisce il demone <command>libvirtd</command>, che permette di gestire (potenzialmente da remoto) le macchine virtuali che girano sull'host e fa partire le VM richieste all'avvio dell'host. <emphasis role=\"pkg\">libvirt-clients</emphasis> fornisce lo strumento a riga di comando <command>virsh</command>, che permette di controllare le macchine gestite da <command>libvirtd</command>."

msgid "<primary><command>virt-viewer</command></primary>"
msgstr "<primary><command>virt-viewer</command></primary>"

msgid "The <emphasis role=\"pkg\">virtinst</emphasis> package provides <command>virt-install</command>, which allows creating virtual machines from the command line. Finally, <emphasis role=\"pkg\">virt-viewer</emphasis> allows accessing a VM's graphical console."
msgstr "Il pacchetto <emphasis role=\"pkg\">virtinst</emphasis> fornisce <command>virt-install</command>, che permette di creare macchine virtuali da riga di comando. Infine, <emphasis role=\"pkg\">virt-viewer</emphasis> permette di accedere alla console grafica di una VM."

msgid "Just as in Xen and LXC, the most frequent network configuration involves a bridge grouping the network interfaces of the virtual machines (see <xref linkend=\"sect.lxc.network\" />)."
msgstr "Proprio come in Xen e LXC, la configurazione di rete più frequente richiede un bridge che raggruppa le interfacce di rete delle macchine virtuali (vedere <xref linkend=\"sect.lxc.network\" />)."

msgid "Alternatively, and in the default configuration provided by KVM, the virtual machine is assigned a private address (in the 192.168.122.0/24 range), and NAT is set up so that the VM can access the outside network."
msgstr "In alternativa e nella configurazione predefinita fornita da KVM, alla macchina virtuale è assegnato un indirizzo privato (nell'intervallo 192.168.122.0/24) e viene impostato il NAT cosicché la VM possa accedere alla rete esterna."

msgid "The rest of this section assumes that the host has an <literal>eth0</literal> physical interface and a <literal>br0</literal> bridge, and that the former is connected to the latter."
msgstr "Il resto di questa sezione assume che l'host abbia un'interfaccia fisica <literal>eth0</literal> e un bridge <literal>br0</literal> e che la prima sia connessa al secondo."

msgid "Installation with <command>virt-install</command>"
msgstr "Installazione con <command>virt-install</command>"

msgid "Creating a virtual machine is very similar to installing a normal system, except that the virtual machine's characteristics are described in a seemingly endless command line."
msgstr "Creare una macchina virtuale è molto simile a installare un sistema normale, tranne che le caratteristiche della macchina virtuale sono descritte da una riga di comando che sembra infinita."

msgid "Practically speaking, this means we will use the Debian installer, by booting the virtual machine on a virtual DVD-ROM drive that maps to a Debian DVD image stored on the host system. The VM will export its graphical console over the VNC protocol (see <xref linkend=\"sect.remote-desktops\" /> for details), which will allow us to control the installation process."
msgstr "In pratica, questo vuol dire che si userà l'installer Debian, avviando la macchina virtuale su un lettore DVD-ROM virtuale che viene mappato su un'immagine DVD di Debian memorizzata sul sistema host. La VM esporterà la sua console grafica sul protocollo VNC (vedere <xref linkend=\"sect.remote-desktops\" /> per i dettagli), il che consentirà di controllare il processo di installazione."

msgid "We first need to tell <command>libvirtd</command> where to store the disk images, unless the default location (<filename>/var/lib/libvirt/images/</filename>) is fine."
msgstr "Innanzitutto bisogna indicare a <command>libvirtd</command> dove memorizzare le immagini dei dischi, se non va bene la posizione predefinita (<filename>/var/lib/libvirt/images/</filename>)."

msgid ""
"<computeroutput># </computeroutput><userinput>mkdir /srv/kvm\n"
"</userinput><computeroutput># </computeroutput><userinput>virsh pool-create-as srv-kvm dir --target /srv/kvm\n"
"</userinput><computeroutput>Pool srv-kvm created\n"
"\n"
"# </computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>mkdir /srv/kvm\n</userinput><computeroutput># </computeroutput><userinput>virsh pool-create-as srv-kvm dir --target /srv/kvm\n</userinput><computeroutput>Pool srv-kvm created\n\n# </computeroutput>"

msgid "<emphasis>TIP</emphasis> Add your user to the libvirt group"
msgstr "<emphasis>SUGGERIMENTO</emphasis> Aggiungi il tuo utente al gruppo libvirt"

msgid "<primary>group</primary><secondary><literal>libvirt</literal></secondary>"
msgstr "<primary>gruppo</primary><secondary><literal>libvirt</literal></secondary>"

msgid "All samples in this section assume that you are running commands as root. Effectively, if you want to control a local libvirt daemon, you need either to be root or to be a member of the <literal>libvirt</literal> group (which is not the case by default). Thus if you want to avoid using root rights too often, you can add yourself to the <literal>libvirt</literal> group and run the various commands under your user identity."
msgstr "Tutti gli esempi in questa sezione presuppongono che si eseguano i comandi come root. In effetti, se si desidera controllare un demone libvirt locale, è necessario essere o root o membro del gruppo <literal>libvirt</literal> (che non è il caso di default). Pertanto, se si vuole evitare di usare i privilegi di root troppo spesso, è possibile aggiungere se stessi al gruppo <literal>libvirt</literal> ed eseguire i vari comandi con il proprio utente."

msgid "Let us now start the installation process for the virtual machine, and have a closer look at <command>virt-install</command>'s most important options. This command registers the virtual machine and its parameters in libvirtd, then starts it so that its installation can proceed."
msgstr "Si avvia il processo di installazione per la macchina virtuale e si guardano più da vicino le opzioni più importanti di <command>virt-install</command>. Questo comando registra la macchina virtuale e i suoi parametri in libvirtd, quindi la avvia cosicché la sua installazione può procedere."

msgid ""
"<computeroutput># </computeroutput><userinput>virt-install --connect qemu:///system  <co id=\"virtinst.connect\"></co>\n"
"               --virt-type kvm           <co id=\"virtinst.type\"></co>\n"
"               --name testkvm            <co id=\"virtinst.name\"></co>\n"
"               --memory 2048             <co id=\"virtinst.ram\"></co>\n"
"               --disk /srv/kvm/testkvm.qcow,format=qcow2,size=10  <co id=\"virtinst.disk\"></co>\n"
"               --cdrom /srv/isos/debian-11.2.0-amd64-netinst.iso  <co id=\"virtinst.cdrom\"></co>\n"
"               --network bridge=virbr0   <co id=\"virtinst.network\"></co>\n"
"               --graphics vnc            <co id=\"virtinst.vnc\"></co>\n"
"               --os-type linux           <co id=\"virtinst.os\"></co>\n"
"               --os-variant debiantesting\n"
"</userinput><computeroutput>\n"
"\n"
"Starting install...\n"
"Allocating 'testkvm.qcow'\n"
"\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>virt-install --connect qemu:///system  <co id=\"virtinst.connect\"></co>\n               --virt-type kvm           <co id=\"virtinst.type\"></co>\n               --name testkvm            <co id=\"virtinst.name\"></co>\n               --memory 2048             <co id=\"virtinst.ram\"></co>\n               --disk /srv/kvm/testkvm.qcow,format=qcow2,size=10  <co id=\"virtinst.disk\"></co>\n               --cdrom /srv/isos/debian-11.2.0-amd64-netinst.iso  <co id=\"virtinst.cdrom\"></co>\n               --network bridge=virbr0   <co id=\"virtinst.network\"></co>\n               --graphics vnc            <co id=\"virtinst.vnc\"></co>\n               --os-type linux           <co id=\"virtinst.os\"></co>\n               --os-variant debiantesting\n</userinput><computeroutput>\n\nStarting install...\nAllocating 'testkvm.qcow'\n\n</computeroutput>"

msgid "The <literal>--connect</literal> option specifies the “hypervisor” to use. Its form is that of an URL containing a virtualization system (<literal>xen://</literal>, <literal>qemu://</literal>, <literal>lxc://</literal>, <literal>openvz://</literal>, <literal>vbox://</literal>, and so on) and the machine that should host the VM (this can be left empty in the case of the local host). In addition to that, and in the QEMU/KVM case, each user can manage virtual machines working with restricted permissions, and the URL path allows differentiating “system” machines (<literal>/system</literal>) from others (<literal>/session</literal>)."
msgstr "L'opzione <literal>--connect</literal> specifica l'«ipervisore» da usare. La sua forma è quella di un URL contenente un sistema di virtualizzazione (<literal>xen://</literal>, <literal>qemu://</literal>, <literal>lxc://</literal>, <literal>openvz://</literal>, <literal>vbox://</literal> e così via) e la macchina che deve ospitare la VM (questo può essere lasciato vuoto nel caso dell'host locale). Inoltre e nel caso di QEMU/KVM ciascun utente può gestire macchine virtuali che funzionano con permessi ristretti e il percorso nell'URL permette di differenziare le macchine «di sistema» (<literal>/system</literal>) dalle altre (<literal>/session</literal>)."

msgid "Since KVM is managed the same way as QEMU, the <literal>--virt-type kvm</literal> allows specifying the use of KVM even though the URL looks like QEMU."
msgstr "Poiché KVM è gestito allo stesso modo di QEMU, <literal>--virt-type kvm</literal> permette di specificare l'uso di KVM anche se l'URL sembra quello di QEMU."

msgid "The <literal>--name</literal> option defines a (unique) name for the virtual machine."
msgstr "L'opzione <literal>--name</literal> definisce un nome (unico) per la macchina virtuale."

msgid "The <literal>--memory</literal> option allows specifying the amount of RAM (in MB) to allocate for the virtual machine."
msgstr "L'opzione <literal>--memory</literal> permette di specificare la quantità di RAM (in MB) da allocare per la macchina virtuale."

msgid "<primary><literal>qcow2</literal></primary>"
msgstr "<primary><literal>qcow2</literal></primary>"

msgid "The <literal>--disk</literal> specifies the location of the image file that is to represent our virtual machine's hard disk; that file is created, unless present, with a size (in GB) specified by the <literal>size</literal> parameter. The <literal>format</literal> parameter allows choosing among several ways of storing the image file. The default format (<literal>qcow2</literal>) allows starting with a small file that only grows when the virtual machine starts actually using space."
msgstr "<literal>--disk</literal> specifica la posizione del file immagine che deve rappresentare il disco fisso della macchina virtuale; quel file è creato, se non presente, con una dimensione (in GB) specificata dal parametro <literal>size</literal>. Il parametro <literal>format</literal> permette di scegliere fra vari modi di memorizzare il file immagine. Il formato predefinito (<literal>qcow2</literal>) permette di iniziare con un file piccolo che cresce solo quando la macchina virtuale comincia effettivamente ad usare spazio."

msgid "The <literal>--cdrom</literal> option is used to indicate where to find the optical disk to use for installation. The path can be either a local path for an ISO file, an URL where the file can be obtained, or the device file of a physical CD-ROM drive (i.e. <literal>/dev/cdrom</literal>)."
msgstr "L'opzione <literal>--cdrom</literal> è usata per indicare dove trovare il disco ottico da usare per l'installazione. Il percorso può essere un percorso locale di un file ISO, un URL dove reperire il file o il device di un lettore CD-ROM fisico (es. <literal>/dev/cdrom</literal>)."

msgid "<primary>network</primary><secondary><literal>virbr</literal> interface</secondary>"
msgstr "<primary>rete</primary><secondary><literal>virbr</literal> interfaccia</secondary>"

msgid "<primary>libvirt</primary><secondary><literal>virbr</literal></secondary>"
msgstr "<primary>libvirt</primary><secondary><literal>virbr</literal></secondary>"

msgid "<primary><literal>virbr</literal>, network interface</primary>"
msgstr "<primary><literal>virbr</literal>, interfaccia di rete</primary>"

msgid "The <literal>--network</literal> specifies how the virtual network card integrates in the host's network configuration. The default behavior (which we explicitly forced in our example) is to integrate it into any pre-existing network bridge. If no such bridge exists, the virtual machine will only reach the physical network through NAT, so it gets an address in a private subnet range (192.168.122.0/24)."
msgstr "<literal>--network</literal> specifica come la scheda di rete virtuale si integra nella configurazione di rete dell'host. Il comportamento predefinito (che in questo esempio è esplicitamente forzato) è di integrarla in un qualunque bridge di rete preesistente. Se non esiste un tale bridge, la macchina virtuale raggiungerà la rete fisica solo tramite NAT, quindi riceve un indirizzo in un intervallo di una sottorete privata (192.168.122.0/24)."

msgid "The default network configuration, which contains the definition for a <literal>virbr0</literal> bridge interface, can be edited using <command>virsh net-edit default</command> and started via <command>virsh net-start default</command> if not already done automatically during system start."
msgstr "La configurazione di rete predefinita, che contiene la definizione per un'interfaccia bridge <literal>virbr0</literal>, può essere modificata con <command>virsh net-edit default</command> e avviata con <command>virsh net-start default</command> se non è già stata eseguita automaticamente durante l'avvio del sistema."

msgid "<literal>--graphics vnc</literal> states that the graphical console should be made available using VNC. The default behavior for the associated VNC server is to only listen on the local interface; if the VNC client is to be run on a different host, establishing the connection will require setting up an SSH tunnel (see <xref linkend=\"sect.ssh-port-forwarding\" />). Alternatively, <literal>--graphics vnc,listen=0.0.0.0</literal> can be used so that the VNC server is accessible from all interfaces; note that if you do that, you really should design your firewall accordingly."
msgstr "<literal>--graphics vnc</literal> indica che la console grafica deve essere resa disponibile tramite VNC. Il comportamento predefinito per il server VNC associato è di soltanto restare in ascolto sull'interfaccia locale; se il client VNC deve girare su un host diverso, si dovrà impostare un tunnel SSH per stabilire la connessione (vedere <xref linkend=\"sect.ssh-port-forwarding\" />). In alternativa, si può usare <literal>--graphics vnc,listen=0.0.0.0</literal> in modo che il server VNC sia accessibile da tutte le interfacce; notare che in questo caso, sarebbe veramente necessario configurare un firewall di conseguenza."

msgid "The <literal>--os-type</literal> and <literal>--os-variant</literal> options allow optimizing a few parameters of the virtual machine, based on some of the known features of the operating system mentioned there."
msgstr "Le opzioni <literal>--os-type</literal> e <literal>--os-variant</literal> permettono di ottimizzare alcuni parametri della macchina virtuale, basandosi su alcune delle funzionalità note del sistema operativo lì menzionato."

msgid "The full list of OS types can be shown using the <command>osinfo-query os</command> command from the <emphasis role=\"pkg\">libosinfo-bin</emphasis> package."
msgstr "L'elenco completo dei tipi di sistema operativo (OS - Operative System) può essere visualizzato usando il comando <command>osinfo-query os</command> presente nel pacchetto <emphasis role=\"pkg\">libosinfo-bin</emphasis>."

msgid "At this point, the virtual machine is running, and we need to connect to the graphical console to proceed with the installation process. If the previous operation was run from a graphical desktop environment, this connection should be automatically started. If not, or if we operate remotely, <command>virt-viewer</command> can be run from any graphical environment to open the graphical console (note that the root password of the remote host is asked twice because the operation requires 2 SSH connections):"
msgstr "A questo punto la macchina virtuale è in esecuzione e bisogna connettersi alla console grafica per procedere con il processo di installazione. Se la precedente operazione è stata lanciata da un ambiente desktop grafico, questa connessione dovrebbe essere avviata automaticamente. In caso contrario, o in caso si operi da remoto, si può eseguire <command>virt-viewer</command> da qualunque ambiente grafico per aprire la console grafica (notare che la password di root dell'host remoto viene chiesta due volte perché l'operazione richiede 2 connessioni SSH):"

msgid ""
"<computeroutput>$ </computeroutput><userinput>virt-viewer --connect qemu+ssh://root@<replaceable>server</replaceable>/system testkvm\n"
"</userinput><computeroutput>root@server's password: \n"
"root@server's password: </computeroutput>"
msgstr ""
"<computeroutput>$ </computeroutput><userinput>virt-viewer --connect qemu+ssh://root@<replaceable>server</replaceable>/system testkvm\n"
"</userinput><computeroutput>root@server's password: \n"
"root@server's password: </computeroutput>"

msgid "Connecting to installer session using <command>virt-viewer</command>"
msgstr "Connessione alla sessione di installazione mediante <command>virt-viewer</command>"

msgid "When the installation process ends, the virtual machine is restarted, now ready for use."
msgstr "Al termine del processo di installazione, la macchina virtuale viene riavviata ed è ora pronta all'uso."

msgid "Managing Machines with <command>virsh</command>"
msgstr "Gestire macchine con <command>virsh</command>"

msgid "Now that the installation is done, let us see how to handle the available virtual machines. The first thing to try is to ask <command>libvirtd</command> for the list of the virtual machines it manages:"
msgstr "Ora che l'installazione è terminata, si passa a come gestire le macchine virtuali disponibili. La prima cosa da provare è chiedere a <command>libvirtd</command> la lista delle macchine virtuali che gestisce:"

msgid ""
"<computeroutput># </computeroutput><userinput>virsh -c qemu:///system list --all\n"
" Id Name                 State\n"
"----------------------------------\n"
"  8 testkvm              shut off\n"
"</userinput>"
msgstr "<computeroutput># </computeroutput><userinput>virsh -c qemu:///system list --all\n Id Name                 State\n----------------------------------\n  8 testkvm              shut off\n</userinput>"

msgid "Let's start our test virtual machine:"
msgstr "Si avvia la macchina virtuale di prova:"

msgid ""
"<computeroutput># </computeroutput><userinput>virsh -c qemu:///system start testkvm\n"
"</userinput><computeroutput>Domain testkvm started</computeroutput>"
msgstr ""
"<computeroutput># </computeroutput><userinput>virsh -c qemu:///system start testkvm\n"
"</userinput><computeroutput>Domain testkvm started</computeroutput>"

msgid "We can now get the connection instructions for the graphical console (the returned VNC display can be given as parameter to <command>vncviewer</command>):"
msgstr "Si possono ora ottenere le istruzioni per connettersi alla console grafica (il display VNC restituito può essere passato come parametro a <command>vncviewer</command>):"

msgid ""
"<computeroutput># </computeroutput><userinput>virsh -c qemu:///system vncdisplay testkvm\n"
"</userinput><computeroutput>127.0.0.1:0</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>virsh -c qemu:///system vncdisplay testkvm\n</userinput><computeroutput>127.0.0.1:0</computeroutput>"

msgid "Other available <command>virsh</command> subcommands include:"
msgstr "Altri sottocomandi disponibili di <command>virsh</command> includono:"

msgid "<literal>reboot</literal> to restart a virtual machine;"
msgstr "<literal>reboot</literal> per riavviare una macchina virtuale;"

msgid "<literal>shutdown</literal> to trigger a clean shutdown;"
msgstr "<literal>shutdown</literal> per provocare uno spegnimento pulito;"

msgid "<literal>destroy</literal>, to stop it brutally;"
msgstr "<literal>destroy</literal> per fermarla brutalmente;"

msgid "<literal>suspend</literal> to pause it;"
msgstr "<literal>suspend</literal> per metterla in pausa;"

msgid "<literal>resume</literal> to unpause it;"
msgstr "<literal>resume</literal> per farla uscire dalla pausa;"

msgid "<literal>autostart</literal> to enable (or disable, with the <literal>--disable</literal> option) starting the virtual machine automatically when the host starts;"
msgstr "<literal>autostart</literal> per abilitare (o disabilitare, con l'opzione <literal>--disable</literal>) l'avvio automatico della macchina virtuale all'avvio dell'host;"

msgid "<literal>undefine</literal> to remove all traces of the virtual machine from <command>libvirtd</command>."
msgstr "<literal>undefine</literal> per rimuovere ogni traccia della macchina virtuale da <command>libvirtd</command>."

msgid "All these subcommands take a virtual machine identifier as a parameter."
msgstr "Tutti questi sottocomandi accettano un identificatore di macchina virtuale come parametro."

msgid "Installing an RPM based chroot in Debian with yum"
msgstr "Installazione in Debian di un chroot basato su RPM usando yum"

msgid "<primary>RPM</primary>"
msgstr "<primary>RPM</primary>"

msgid "<primary>chroot</primary>"
msgstr "<primary>chroot</primary>"

msgid "<primary><command>yum</command></primary>"
msgstr "<primary><command>yum</command></primary>"

msgid "<primary><command>rpm</command></primary>"
msgstr "<primary><command>rpm</command></primary>"

msgid "If a chroot is meant to run Debian (or one of its derivatives), the system can be initialized with <command>debootstrap</command>. But if it is to be installed with an RPM-based system (such as Fedora, CentOS or Scientific Linux), the setup will need to be done using the <command>yum</command> utility, available as <command>yum4</command> in the <emphasis role=\"pkg\">nextgen-yum4</emphasis> package, since the original program has been removed from Debian before the <emphasis role=\"distribution\">Bullseye</emphasis> release due to being unmaintained, outdated, and obsoleted by <command>dnf</command>."
msgstr "Se un chroot deve eseguire Debian (o una delle sue derivate), il sistema può essere inizializzato con <command>debootstrap</command>. Ma se deve essere installato con un sistema basato su RPM (come Fedora, CentOS o Scientific Linux), la configurazione dovrà essere effettuata utilizzando l'utilità <command>yum</command>, disponibile come <command>yum4</command> nel pacchetto <emphasis role=\"pkg\">nextgen-yum4</emphasis>, poiché il programma originale è stato rimosso da Debian prima del rilascio di <emphasis role=\"distribution\">Bullseye</emphasis> perché non mantenuto, superato e obsoleto da <command>dnf</command>."

msgid "The procedure requires using <command>rpm</command> to extract an initial set of files, including notably <command>yum</command> configuration files, and then calling <command>yum4</command> to extract the remaining set of packages. But since we call <command>yum4</command> from outside the chroot, we need to make some temporary changes. In the sample below, the target chroot is <filename>/srv/centos</filename>."
msgstr "La procedura richiede l'uso di <command>rpm</command> per estrarre un set iniziale di file, tra cui in particolare i file di configurazione di <command>yum</command>, e quindi di eseguire <command>yum4</command> per estrarre il rimanente gruppo di pacchetti. Ma dal momento che viene eseguito <command>yum4</command> da fuori dalla chroot, si ha bisogno di fare alcune modifiche temporanee. Nell'esempio sottostante, la destinazione del chroot è <filename>/srv/centos</filename>."

msgid ""
"<computeroutput># </computeroutput><userinput>rootdir=\"/srv/centos\"\n"
"</userinput><computeroutput># </computeroutput><userinput>mkdir -p \"$rootdir\" /etc/rpm\n"
"</userinput><computeroutput># </computeroutput><userinput>echo \"%_dbpath /var/lib/rpm\" &gt; /etc/rpm/macros.dbpath\n"
"</userinput><computeroutput># </computeroutput><userinput>wget http://mirror.centos.org/centos/7/os/x86_64/Packages/centos-release-7-9.2009.0.el7.centos.x86_64.rpm\n"
"</userinput><computeroutput># </computeroutput><userinput>rpm --nodeps --root \"$rootdir\" -i centos-release-7-9.2009.0.el7.centos.x86_64.rpm\n"
"</userinput><computeroutput>rpm: RPM should not be used directly install RPM packages, use Alien instead!\n"
"rpm: However assuming you know what you are doing...\n"
"warning: centos-release-7-9.2009.0.el7.centos.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\n"
"# </computeroutput><userinput>sed -i -e \"s,gpgkey=file:///etc/,gpgkey=file://${rootdir}/etc/,g\" $rootdir/etc/yum.repos.d/*.repo\n"
"</userinput><computeroutput># </computeroutput><userinput>yum4 --assumeyes --installroot $rootdir groupinstall core\n"
"</userinput><computeroutput>[...]\n"
"# </computeroutput><userinput>sed -i -e \"s,gpgkey=file://${rootdir}/etc/,gpgkey=file:///etc/,g\" $rootdir/etc/yum.repos.d/*.repo\n"
"</userinput><computeroutput># </computeroutput><userinput>chroot /srv/centos/\n"
"</userinput><computeroutput>[root@testsystem /]# </computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>rootdir=\"/srv/centos\"\n</userinput><computeroutput># </computeroutput><userinput>mkdir -p \"$rootdir\" /etc/rpm\n</userinput><computeroutput># </computeroutput><userinput>echo \"%_dbpath /var/lib/rpm\" &gt; /etc/rpm/macros.dbpath\n</userinput><computeroutput># </computeroutput><userinput>wget http://mirror.centos.org/centos/7/os/x86_64/Packages/centos-release-7-9.2009.0.el7.centos.x86_64.rpm\n</userinput><computeroutput># </computeroutput><userinput>rpm --nodeps --root \"$rootdir\" -i centos-release-7-9.2009.0.el7.centos.x86_64.rpm\n</userinput><computeroutput>rpm: RPM should not be used directly install RPM packages, use Alien instead!\nrpm: However assuming you know what you are doing...\nwarning: centos-release-7-9.2009.0.el7.centos.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\n# </computeroutput><userinput>sed -i -e \"s,gpgkey=file:///etc/,gpgkey=file://${rootdir}/etc/,g\" $rootdir/etc/yum.repos.d/*.repo\n</userinput><computeroutput># </computeroutput><userinput>yum4 --assumeyes --installroot $rootdir groupinstall core\n</userinput><computeroutput>[...]\n# </computeroutput><userinput>sed -i -e \"s,gpgkey=file://${rootdir}/etc/,gpgkey=file:///etc/,g\" $rootdir/etc/yum.repos.d/*.repo\n</userinput><computeroutput># </computeroutput><userinput>chroot /srv/centos/\n</userinput><computeroutput>[root@testsystem /]# </computeroutput>"

msgid "Automated Installation"
msgstr "Installazione automatica"

msgid "<primary>deployment</primary>"
msgstr "<primary>allestimento</primary>"

msgid "<primary>installation</primary><secondary>automated installation</secondary>"
msgstr "<primary>installazione</primary><secondary>installazione automatica</secondary>"

msgid "The Falcot Corp administrators, like many administrators of large IT services, need tools to install (or reinstall) quickly, and automatically if possible, their new machines."
msgstr "Gli amministratori della Falcot Corp, come molti amministratori di grandi servizi IT, hanno bisogno di strumenti per installare (o reinstallare) rapidamente e se possibile automaticamente le loro nuove macchine."

msgid "These requirements can be met by a wide range of solutions. On the one hand, generic tools such as SystemImager handle this by creating an image based on a template machine, then deploy that image to the target systems; at the other end of the spectrum, the standard Debian installer can be preseeded with a configuration file giving the answers to the questions asked during the installation process. As a sort of middle ground, a hybrid tool such as FAI (<emphasis>Fully Automatic Installer</emphasis>) installs machines using the packaging system, but it also uses its own infrastructure for tasks that are more specific to massive deployments (such as starting, partitioning, configuration and so on)."
msgstr "Questi requisiti possono essere soddisfatti da una vasta gamma di soluzioni. Da un lato, strumenti generici come SystemImager gestiscono il compito creando un'immagine basata su una macchina modello, quindi allestiscono quell'immagine sui sistemi destinazione; dall'altro lato dello spettro, l'installatore standard di Debian può essere preimpostato con un file di configurazione che dà le risposte alle domande poste durante il processo di installazione. A metà strada, uno strumento ibrido come FAI (<emphasis>Fully Automatic Installer</emphasis>) installa le macchine usando il sistema di pacchettizzazione, ma usa anche la propria infrastruttura per compiti più specifici su allestimenti di massa (come avviare, partizionare, configurare e così via)."

msgid "Each of these solutions has its pros and cons: SystemImager works independently from any particular packaging system, which allows it to manage large sets of machines using several distinct Linux distributions. It also includes an update system that doesn't require a reinstallation, but this update system can only be reliable if the machines are not modified independently; in other words, the user must not update any software on their own, or install any other software. Similarly, security updates must not be automated, because they have to go through the centralized reference image maintained by SystemImager. This solution also requires the target machines to be homogeneous, otherwise many different images would have to be kept and managed (an amd64 image won't fit on a powerpc machine, and so on)."
msgstr "Ciascuna di queste soluzioni ha i suoi pro e contro: SystemImager funziona indipendentemente da qualunque particolare sistema di pacchettizzazione, il che gli permette di gestire grandi gruppi di macchine che usano più distribuzioni distinte di Linux. Inoltre include un sistema di aggiornamento che non richiede di reinstallare, ma questo sistema di aggiornamento è affidabile solo se le macchine non sono state modificate in modo indipendente; in altre parole, l'utente non deve aggiornare o installare alcun software da solo. In modo simile, gli aggiornamenti di sicurezza non devono essere automatizzati, perché devono passare dall'immagine centralizzata di riferimento mantenuta da SystemImager. Questa soluzione richiede inoltre che le macchine destinazione siano omogenee, altrimenti si dovrebbero mantenere e gestire molte immagini differenti (un'immagine amd64 non sarebbe adatta su una macchina powerpc e così via)."

msgid "On the other hand, an automated installation using debian-installer can adapt to the specifics of each machine: the installer will fetch the appropriate kernel and software packages from the relevant repositories, detect available hardware, partition the whole hard disk to take advantage of all the available space, install the corresponding Debian system, and set up an appropriate bootloader. However, the standard installer will only install standard Debian versions, with the base system and a set of pre-selected “tasks”; this precludes installing a particular system with non-packaged applications. Fulfilling this particular need requires customizing the installer… Fortunately, the installer is very modular, and there are tools to automate most of the work required for this customization, most importantly <emphasis role=\"pkg\">simple-cdd</emphasis> (CDD being an acronym for <emphasis>Custom Debian Derivative</emphasis>). Even this solution, however, only handles initial installations; this is usually not a problem since the APT tools allow efficient deployment of updates later on."
msgstr "D'altro canto, un'installazione automatica usando debian-installer può adattarsi alle specifiche di ciascuna macchina: l'installatore preleverà il kernel e i pacchetti software appropriati dai relativi archivi, rileverà l'hardware disponibile, partizionerà l'intero disco fisso per sfruttare tutto lo spazio disponibile, installerà il sistema Debian corrispondente, e imposterà un bootloader appropriato. Tuttavia, l'installatore standard installerà solo versioni standard di Debian, con il sistema base e un insieme di \"task\" preselezionati; questo impedisce di installare un sistema particolare con applicazioni non pacchettizzate. Per soddisfare questa esigenza particolare è necessario personalizzare l'installatore… Fortunatamente, l'installatore è molto modulare ed esistono strumenti per automatizzare la maggior parte del lavoro richiesto per questa personalizzazione, il più importante dei quali è <emphasis role=\"pkg\">simple-cdd</emphasis> (CDD è un acronimo di <emphasis>Custom Debian Derivatives</emphasis>). Anche questa soluzione, tuttavia, gestisce solo le installazioni iniziali; ciò di solito non è un problema dal momento che gli strumenti APT permettono in seguito una efficiente distribuzione degli aggiornamenti."

msgid "We will only give a rough overview of FAI, and skip SystemImager altogether (which is no longer in Debian, but available as a third-party package), in order to focus more intently on debian-installer and <emphasis role=\"pkg\">simple-cdd</emphasis>, which are more interesting in a Debian-only context."
msgstr "Si illustrerà solo una panoramica approssimativa di FAI e si tralascerà del tutto SystemImager (che non è più in Debian, ma è disponibile come pacchetto di terze parti), per focalizzarsi maggiormente su debian-installer e <emphasis role=\"pkg\">simple-cdd</emphasis>, che sono più interessanti in un contesto unicamente Debian."

msgid "Fully Automatic Installer (FAI)"
msgstr "Fully Automatic Installer (FAI)"

msgid "<primary>Fully Automatic Installer</primary><see>FAI</see>"
msgstr "<primary>Fully Automatic Installer (Installatore Completamente Automatico)</primary><see>FAI</see>"

msgid "<primary>FAI</primary>"
msgstr "<primary>FAI</primary>"

msgid "<foreignphrase>Fully Automatic Installer</foreignphrase> is probably the oldest automated deployment system for Debian, which explains its status as a reference; but its very flexible nature only just compensates for the complexity it involves."
msgstr "<foreignphrase>Fully Automatic Installer</foreignphrase> è probabilmente il più vecchio sistema di allestimento automatico per Debian, il che spiega il suo status di punto di riferimento; ma la sua natura molto flessibile compensa appena la complessità che esso comporta."

msgid "<primary>FAI</primary><secondary><emphasis role=\"pkg\">fai-server</emphasis></secondary>"
msgstr "<primary>FAI</primary><secondary><emphasis role=\"pkg\">fai-server</emphasis></secondary>"

msgid "<primary>FAI</primary><secondary><emphasis role=\"pkg\">fai-quickstart</emphasis></secondary>"
msgstr "<primary>FAI</primary><secondary><emphasis role=\"pkg\">fai-quickstart</emphasis></secondary>"

msgid "FAI requires a server system to store deployment information and allow target machines to boot from the network. This server requires the <emphasis role=\"pkg\">fai-server</emphasis> package (or <emphasis role=\"pkg\">fai-quickstart</emphasis>, which also brings the required elements for a standard configuration)."
msgstr "FAI richiede un sistema server per memorizzare le informazioni sull'allestimento e permettere alle macchine destinazione di avviarsi dalla rete. Questo server richiede il pacchetto <emphasis role=\"pkg\">fai-server</emphasis> (o <emphasis role=\"pkg\">fai-quickstart</emphasis>, che fornisce anch'esso gli elementi richiesti per una configurazione standard)."

msgid "<primary><filename>/etc</filename></primary><secondary><filename>/etc/fai/</filename></secondary><see>FAI</see>"
msgstr "<primary><filename>/etc</filename></primary><secondary><filename>/etc/fai/</filename></secondary><see>FAI</see>"

msgid "<primary>FAI</primary><secondary><filename>/etc/fai/nfsroot.conf</filename></secondary>"
msgstr "<primary>FAI</primary><secondary><filename>/etc/fai/nfsroot.conf</filename></secondary>"

msgid "FAI uses a specific approach for defining the various installable profiles. Instead of simply duplicating a reference installation, FAI is a full-fledged installer, fully configurable via a set of files and scripts stored on the server; the default location <filename>/srv/fai/config/</filename> according to <filename>/etc/fai/nfsroot.conf</filename> is not automatically created, so the administrator needs to create it along with the relevant files. Most of the times, these files will be customized from the example files available in the documentation for the <emphasis role=\"pkg\">fai-doc</emphasis> package, more particularly the <filename>/usr/share/doc/fai-doc/examples/simple/</filename> directory."
msgstr "FAI usa un approccio specifico per definire i vari profili installabili. Invece di duplicare semplicemente un'installazione di riferimento, FAI è un installatore completo di tutto punto, interamente configurabile tramite un insieme di file e script memorizzati sul server; la posizione predefinita <filename>/srv/fai/config/</filename> presente in <filename>/etc/fai/nfsroot.conf</filename> non è creata automaticamente, quindi l'amministratore deve crearla insieme con i relativi file. Il più delle volte questi file saranno personalizzati a partire dai file di esempio disponibili nella documentazione del pacchetto <emphasis role=\"pkg\">fai-doc</emphasis>, più in particolare la directory <filename>/usr/share/doc/fai-doc/examples/simple/</filename>."

msgid "<primary>FAI</primary><secondary><command>fai-setup</command></secondary>"
msgstr "<primary>FAI</primary><secondary><command>fai-setup</command></secondary>"

msgid "<primary>FAI</primary><secondary><command>fai-cd</command></secondary>"
msgstr "<primary>FAI</primary><secondary><command>fai-cd</command></secondary>"

msgid "Once the profiles are defined, the <command>fai-setup</command> command generates the elements required to start an FAI installation; this mostly means preparing or updating a minimal system (NFS-root) used during installation. An alternative is to generate a dedicated boot CD with <command>fai-cd</command>."
msgstr "Una volta definiti i profili, il comando <command>fai-setup</command> genera gli elementi richiesti per avviare un'installazione FAI; questo vuol dire perlopiù preparare o aggiornare un sistema minimale (NFS-root) usato durante l'installazione. Un'alternativa è generare un CD di avvio dedicato con <command>fai-cd</command>."

msgid "Creating all these configuration files requires some understanding of the way FAI works. A typical installation process is made of the following steps:"
msgstr "La creazione di tutti questi file di configurazione richiede una certa comprensione di come funziona FAI. Un tipico processo di installazione è composto dai seguenti passi:"

msgid "fetching a kernel from the network, and booting it;"
msgstr "prelevare un kernel dalla rete e avviarlo;"

msgid "mounting the root filesystem from NFS;"
msgstr "montare il filesystem di root da NFS;"

msgid "<primary>FAI</primary><secondary><command>fai</command></secondary>"
msgstr "<primary>FAI</primary><secondary><command>fai</command></secondary>"

msgid "executing <command>/usr/sbin/fai</command>, which controls the rest of the process (the next steps are therefore initiated by this script);"
msgstr "eseguire <command>/usr/sbin/fai</command>, che controlla il resto del processo (i passi successivi sono quindi iniziati da questo script);"

msgid "copying the configuration space from the server into <filename>/fai/</filename>;"
msgstr "copiare lo spazio di configurazione dal server su <filename>/fai/</filename>;"

msgid "running <command>fai-class</command>. The <filename>/fai/class/[0-9][0-9]*</filename> scripts are executed in turn, and return names of “classes” that apply to the machine being installed; this information will serve as a base for the following steps. This allows for some flexibility in defining the services to be installed and configured."
msgstr "eseguire <command>fai-class</command>. Gli script <filename>/fai/class/[0-9][0-9]*</filename> sono eseguiti in successione e restituiscono nomi di «classi» che si applicano alla macchina che viene installata; questa informazione servirà come base per i passi successivi. Ciò permette una certa flessibilità nel definire i servizi da installare e configurare."

msgid "fetching a number of configuration variables, depending on the relevant classes;"
msgstr "prelevare un certo numero di variabili di configurazione, a seconda delle relative classi;"

msgid "partitioning the disks and formatting the partitions, based on information provided in <filename>/fai/disk_config/<replaceable>class</replaceable></filename>;"
msgstr "partizionare i dischi e formattare le partizioni, in base alle informazioni fornite in <filename>/fai/disk_config/<replaceable>classe</replaceable></filename>;"

msgid "mounting said partitions;"
msgstr "montare le suddette partizioni;"

msgid "installing the base system;"
msgstr "installare il sistema di base;"

msgid "<primary>FAI</primary><secondary><command>fai-debconf</command></secondary>"
msgstr "<primary>FAI</primary><secondary><command>fai-debconf</command></secondary>"

msgid "preseeding the Debconf database with <command>fai-debconf</command>;"
msgstr "preimpostare il database di Debconf con <command>fai-debconf</command>;"

msgid "fetching the list of available packages for APT;"
msgstr "prelevare la lista dei pacchetti disponibili per APT;"

msgid "installing the packages listed in <filename>/fai/package_config/<replaceable>class</replaceable></filename>;"
msgstr "installare i pacchetti elencati in <filename>/fai/package_config/<replaceable>classe</replaceable></filename>;"

msgid "executing the post-configuration scripts, <filename>/fai/scripts/<replaceable>class</replaceable>/[0-9][0-9]*</filename>;"
msgstr "eseguire gli script di post-configurazione, <filename>/fai/scripts/<replaceable>classe</replaceable>/[0-9][0-9]*</filename>;"

msgid "recording the installation logs, unmounting the partitions, and rebooting."
msgstr "registrare i log di installazione, smontare le partizioni e riavviare."

msgid "Preseeding Debian-Installer"
msgstr "Preimpostare Debian-Installer"

msgid "<primary>preseed</primary>"
msgstr "<primary>preimpostazione</primary>"

msgid "<primary>preconfiguration</primary>"
msgstr "<primary>preconfigurazione</primary>"

msgid "<primary>installation</primary><secondary>preseeding</secondary>"
msgstr "<primary>installation</primary><secondary>preimpostazione</secondary>"

msgid "At the end of the day, the best tool to install Debian systems should logically be the official Debian installer. This is why, right from its inception, debian-installer has been designed for automated use, taking advantage of the infrastructure provided by <emphasis role=\"pkg\">debconf</emphasis>. The latter allows, on the one hand, to reduce the number of questions asked (hidden questions will use the provided default answer), and on the other hand, to provide the default answers separately, so that installation can be non-interactive. This last feature is known as <foreignphrase>preseeding</foreignphrase>."
msgstr "A conti fatti, il miglior strumento per installare i sistemi Debian dovrebbe logicamente essere l'installatore ufficiale Debian. Per questo, fin dalla sua nascita, debian-installer è stato progettato per un uso automatizzato, sfruttando l'infrastruttura fornita da <emphasis role=\"pkg\">debconf</emphasis>. Quest'ultimo permette da un lato di ridurre il numero delle domande poste (le domande nascoste useranno la risposta predefinita) e dall'altro di fornire le risposte predefinite separatamente, cosicché l'installazione possa essere non interattiva. Quest'ultima funzionalità è nota come <foreignphrase>preimpostazione</foreignphrase>."

msgid "<emphasis>GOING FURTHER</emphasis> Debconf with a centralized database"
msgstr "<emphasis>APPROFONDIMENTO</emphasis> Debconf con un database centralizzato"

msgid "<primary><emphasis role=\"pkg\">debconf-doc</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">debconf-doc</emphasis></primary>"

msgid "Preseeding allows to provide a set of answers to Debconf questions at installation time, but these answers are static and do not evolve as time passes. Since already-installed machines may need upgrading, and new answers may become required, the <filename>/etc/debconf.conf</filename> configuration file can be set up so that Debconf uses external data sources (such as an LDAP directory server, or a remote file accessed via NFS or Samba). Several external data sources can be defined at the same time, and they complement one another. The local database is still used (for read-write access), but the remote databases are usually restricted to reading. The <citerefentry><refentrytitle>debconf.conf</refentrytitle> <manvolnum>5</manvolnum></citerefentry> manual page describes all the possibilities in detail (you need the <emphasis role=\"pkg\">debconf-doc</emphasis> package)."
msgstr "Preimpostare significa fornire un insieme di risposte alle domande di Debconf al momento dell'installazione, ma queste risposte sono statiche e non evolvono col passare del tempo. Poiché macchine già installate possono richiedere degli aggiornamenti e possono essere necessarie nuove risposte, il file di configurazione <filename>/etc/debconf.conf</filename> può essere impostato in modo che Debconf usi fonti esterne di dati (come un server di directory LDAP o un file remoto montato via NFS o Samba). Si possono definire contemporaneamente più fonti esterne di dati e queste si completano a vicenda. Il database locale è ancora usato (per un accesso in lettura e scrittura), ma i database remoti sono di solito ristretti alla lettura. La pagina di manuale <citerefentry><refentrytitle>debconf.conf</refentrytitle> <manvolnum>5</manvolnum></citerefentry> descrive in dettaglio tutte le possibilità (c'è bisogno del pacchetto <emphasis role=\"pkg\">debconf-doc</emphasis>)."

msgid "<primary><command>debconf</command></primary>"
msgstr "<primary><command>debconf</command></primary>"

msgid "Using a Preseed File"
msgstr "Usare un file di preimpostazione"

msgid "There are several places where the installer can get a preseeding file:"
msgstr "Ci sono diversi posti da cui l'installatore può ottenere un file di preimpostazione:"

msgid "<primary><filename>preseed.cfg</filename></primary>"
msgstr "<primary><filename>preseed.cfg</filename></primary>"

msgid "in the initrd used to start the machine; in this case, preseeding happens at the very beginning of the installation, and all questions can be avoided. The file just needs to be called <filename>preseed.cfg</filename> and stored in the initrd root."
msgstr "nell'initrd usato per avviare la macchina; in questo caso, la preimpostazione avviene proprio all'inizio dell'installazione e si possono evitare tutte le domande. Il file deve solo essere chiamato <filename>preseed.cfg</filename> e memorizzato nella root dell'initrd."

msgid "on the boot media (CD or USB key); preseeding then happens as soon as the media is mounted, which means right after the questions about language and keyboard layout. The <literal>preseed/file</literal> boot parameter can be used to indicate the location of the preseeding file (for instance, <filename>/cdrom/preseed.cfg</filename> when the installation is done off a CD-ROM, or <filename>/hd-media/preseed.cfg</filename> in the USB-key case)."
msgstr "sul supporto di avvio (CD o chiave USB); la preimpostazione in questo caso avviene appena il supporto viene montato, ossia subito dopo le domande su lingua e impostazione di tastiera. Si può usare il parametro di avvio <literal>preseed/file</literal> per indicare la posizione del file di preimpostazione (per esempio, <filename>/cdrom/preseed.cfg</filename> quando l'installazione viene fatta da CD-ROM o <filename>/hd-media/preseed.cfg</filename> nel caso di una chiave USB)."

msgid "from the network; preseeding then only happens after the network is (automatically) configured; the relevant boot parameter is then <literal>preseed/url=http://<replaceable>server</replaceable>/preseed.cfg</literal> (HTTPS, FTPS, SFTP, etc. are not supported)."
msgstr "dalla rete; la preconfigurazione in questo caso avviene solo dopo che la rete è (automaticamente) configurata; il parametro di avvio relativo è allora <literal>preseed/url=http://<replaceable>server</replaceable>/preseed.cfg</literal> (non sono supportati: HTTPS, FTPS, SFTP, ecc.)."

msgid "At a glance, including the preseeding file in the initrd looks like the most interesting solution; however, it is rarely used in practice, because generating an installer initrd is rather complex. The other two solutions are much more common, especially since boot parameters provide another way to preseed the answers to the first questions of the installation process. The usual way to save the bother of typing these boot parameters by hand at each installation is to save them into the configuration for <command>isolinux</command> (in the CD-ROM case) or <command>syslinux</command> (USB key)."
msgstr "A prima vista, includere il file di preimpostazione nell'initrd sembra la soluzione più interessante; tuttavia, è raramente usata in pratica perché generare un initrd per l'installatore è piuttosto complesso. Le altre due soluzioni sono molto più comuni, soprattutto dal momento che i parametri di avvio forniscono un altro modo per preimpostare le risposte alle prime domande del processo di installazione. Il modo consueto di risparmiare la fatica di scrivere questi parametri di avvio a mano a ogni installazione è di salvarli nella configurazione di <command>isolinux</command> (nel caso di un CD-ROM) or <command>syslinux</command> (nel caso di una chiave USB)."

msgid "Creating a Preseed File"
msgstr "Creare un file di preimpostazione"

msgid "A preseed file is a plain text file, where each line contains the answer to one Debconf question. A line is split across four fields separated by whitespace (spaces or tabs), as in, for instance, <literal>d-i mirror/suite string stable</literal>:"
msgstr "Un file di preimpostazione è un file di testo semplice in cui ogni riga contiene la risposta a una domanda di Debconf. Una linea è divisa in quattro campi separati da spazi vuoti (spazi o tabulazioni) come, ad esempio, <literal>d-i mirror/suite string stable</literal>:"

msgid "the first field is the “owner” of the question; “d-i” is used for questions relevant to the installer, but it can also be a package name for questions coming from Debian packages;"
msgstr "il primo campo è il «proprietario» della domanda; «d-i» viene usato per domande relative all'installatore, ma può anche essere il nome di un pacchetto per domande provenienti da pacchetti Debian;"

msgid "the second field is an identifier for the question (the template name);"
msgstr "il secondo campo è un identificatore per la domanda (il nome del modello);"

msgid "third, the type of question;"
msgstr "terzo, il tipo di domanda;"

msgid "the fourth and last field contains the value for the answer. Note that it must be separated from the third field with a single space; if there are more than one, the following space characters are considered part of the value."
msgstr "il quarto e ultimo campo contiene il valore della risposta. Notare che deve essere separato dal terzo campo con uno spazio singolo, se vi sono più di uno, i seguenti spazi sono considerati parte del valore."

msgid "The simplest way to write a preseed file is to install a system by hand. Then <command>debconf-get-selections --installer</command> will provide the answers concerning the installer. Answers about other packages can be obtained with <command>debconf-get-selections</command>. However, a cleaner solution is to write the preseed file by hand, starting from an example and the reference documentation: with such an approach, only questions where the default answer needs to be overridden can be preseeded; using the <literal>priority=critical</literal> boot parameter will instruct Debconf to only ask critical questions, and use the default answer for others."
msgstr "Il modo più semplice per scrivere un file di preimpostazione è di installare un sistema a mano. Quindi <command>debconf-get-selections --installer</command> fornirà le risposte riguardanti l'installatore. Le risposte riguardo altri pacchetti si possono ottenere con <command>debconf-get-selections</command>. Tuttavia, una soluzione più pulita è di scrivere il file di preimpostazione a mano, a partire da un esempio e dalla documentazione di riferimento: con questo approccio, si possono preimpostare solo le domande a cui bisogna modificare le risposte predefinite; il parametro <literal>priority=critical</literal> dirà a Debconf di porre solo domande critiche e usare la risposta predefinita per le altre."

msgid "Pre-setting a value in a preseed file automatically instructs the Debian installer to not ask that question. This happens, because loading the preseed file does not just set the given value(s), but also marks each of the affected dialogs as “seen“ by the user. Thus it is possible to pre-set a question's value and still present the dialog to the user by resetting the “seen“ flag. Beware that order in this case matters and that the value has to be preseeded before setting the dialog to “unseen“ as shown in the following example:"
msgstr "Preconfigurare un valore in un file di preconfigurazione istruisce automaticamente l'installatore Debian a non porre questa domanda. Questo succede perché caricare il file di preconfigurazione non imposta soltanto il(i) valore(i) dato(i), ma imposta ogni finestra di dialogo come \"vista\" dall'utente. È quindi possibile preimpostare il valore di una domanda, ma comunque presentare la finestra di dialogo all'utente resettando il flag \"visto\". Fare attenzione che l'ordine è importante in questo caso e che il valore deve essere preimpostato prima di impostare la finestra di dialogo a \"non vista\", come mostrato nel seguente esempio:"

msgid ""
"d-i netcfg/hostname string worker\n"
"d-i netcfg/hostname seen false"
msgstr "d-i netcfg/hostname string worker\nd-i netcfg/hostname seen false"

msgid "<primary><command>debconf-get-selections</command></primary>"
msgstr "<primary><command>debconf-get-selections</command></primary>"

msgid "<emphasis>DOCUMENTATION</emphasis> Installation guide appendix"
msgstr "<emphasis>DOCUMENTAZIONE</emphasis> Appendice alla guida di installazione"

msgid "<primary>preseed</primary><secondary>all templates</secondary>"
msgstr "<primary>preconfigurazione</primary><secondary>tutti i modelli</secondary>"

msgid "The installation guide, available online, includes detailed documentation on the use of a preseed file in an appendix. It also includes a detailed and commented sample file, which can serve as a base for local customizations. There are also collections of all debconf templates extracted from each component and suite of Debian: <ulink type=\"block\" url=\"https://www.debian.org/releases/stable/amd64/apb\" /> <ulink type=\"block\" url=\"https://www.debian.org/releases/stable/example-preseed.txt\" /> <ulink type=\"block\" url=\"https://preseed.debian.net/\" />"
msgstr "La guida di installazione, disponibile in linea, include in un'appendice la documentazione dettagliata sull'uso di un file di preconfigurazione. Inoltre, include un file di esempio dettagliato e commentato, che può servire come base per personalizzazioni locali. Ci sono anche raccolte di tutti i modelli debconf estratti da ogni componente della suite di Debian: <ulink type=\"block\" url=\"https://www.debian.org/releases/stable/amd64/apb\" /> <ulink type=\"block\" url=\"https://www.debian.org/releases/stable/example-preseed.txt\" /> <ulink type=\"block\" url=\"https://preseed.debian.net/\" />"

msgid "Preseeding an installation is often not as straightforward as one would wish. It sometimes requires to understand how packages process the given values in their scripts. Don't hesitate to ask on the <email>debian-cd@lists.debian.org</email> mailing list or in the <literal>#debian-cd</literal> IRC channel if you require help. Also be aware that some complex setups still cannot be achieved by preseeding."
msgstr "Preconfigurare un'installazione non è spesso così semplice come si vorrebbe. Alcune volte è necessario capire come i pacchetti elaborano il valore indicato nei loro script. Se si ha bisogno di aiuto non esitare a chiederlo sulla mailing list <email>debian-cd@lists.debian.org</email> o sul canale IRC <literal>#debian-cd</literal>. Inoltre si tenga presente che alcune configurazioni complesse non possono ancora essere realizzate tramite preconfigurazione."

msgid "<primary>mailing lists</primary><secondary><email>debian-cd@lists.debian.org</email></secondary>"
msgstr "<primary>mailing lists</primary><secondary><email>debian-cd@lists.debian.org</email></secondary>"

msgid "Creating a Customized Boot Media"
msgstr "Creare un supporto di avvio personalizzato"

msgid "Knowing where to store the preseed file is all very well, but the location isn't everything: one must, one way or another, alter the installation boot media to change the boot parameters and add the preseed file."
msgstr "Sapere dove memorizzare il file di preimpostazione è cosa buona e giusta, ma la posizione non è tutto; in un modo o nell'altro, bisogna alterare il supporto di avvio dell'installazione per cambiare i parametri di avvio e aggiungere il file di preimpostazione."

msgid "Booting From the Network"
msgstr "Avviare dalla rete"

msgid "<primary>PXE</primary>"
msgstr "<primary>PXE</primary>"

msgid "When a computer is booted from the network, the server sending the initialization elements also defines the boot parameters. Thus, the change needs to be made in the PXE configuration for the boot server; more specifically, in its <filename>/tftpboot/pxelinux.cfg/default</filename> configuration file. Setting up network boot is a prerequisite; see the Installation Guide for details. <ulink type=\"block\" url=\"https://www.debian.org/releases/stable/amd64/ch04s05\" />"
msgstr "Quando un computer è avviato dalla rete, il server che manda gli elementi di inizializzazione definisce anche i parametri di avvio. Pertanto, la modifica deve essere fatta nella configurazione di PXE per l'avvio del server; più specificamente, nel suo file di configurazione <filename>/tftpboot/pxelinux.cfg/default</filename>. Impostare l'avvio dalla rete è un prerequisito; vedere la Guida all'installazione per i dettagli. <ulink type=\"block\" url=\"https://www.debian.org/releases/stable/amd64/ch04s05\" />"

msgid "Preparing a Bootable USB Key"
msgstr "Preparare una chiavetta USB avviabile"

msgid "<primary><filename>syslinux.cfg</filename></primary>"
msgstr "<primary><filename>syslinux.cfg</filename></primary>"

msgid "<primary>syslinux</primary>"
msgstr "<primary>syslinux</primary>"

msgid "<primary>isolinux</primary>"
msgstr "<primary>isolinux</primary>"

msgid "<primary><filename>grub.cfg</filename></primary>"
msgstr "<primary><filename>grub.cfg</filename></primary>"

msgid "Once a bootable key has been prepared (see <xref linkend=\"sect.install-usb\" />), a few extra operations are needed. Assuming the key contents are available under <filename>/media/usbdisk/</filename>, copy the preseed file to <filename>/media/usbdisk/preseed.cfg</filename>."
msgstr "Una volta preparata una chiavetta USB avviabile (vedere <xref linkend=\"sect.install-usb\" />), sono necessarie alcune operazioni aggiuntive. Supponendo che il suo contenuto sia disponibili in <filename>/media/usbdisk/</filename>, copiate il file preseed in <filename>/media/usbdisk/preseed.cfg</filename>."

msgid "If you have been using a hybrid ISO image to create the bootable USB stick, then you have to edit <filename>/media/usbdisk/boot/grub/grub.cfg</filename> (for the EFI boot screen):"
msgstr "Se si sta utilizzando un'immagine ISO ibrida per creare la chiavetta USB avviabile, allora bisogna modificare <filename>/media/usbdisk/boot/grub/grub.cfg</filename> (per la schermata di avvio EFI):"

msgid "boot/grub/grub.cfg file and preseeding parameters"
msgstr "file boot/grub/grub.cfg e parametri di preconfigurazione"

msgid ""
"menuentry --hotkey=i 'Install' {\n"
"    set background_color=black\n"
"    linux    /install.amd/vmlinuz preseed/file=/cdrom/preseed.cfg locale=en_US.UTF-8 keymap=us language=us country=US vga=788 --- quiet \n"
"    initrd   /install.amd/initrd.gz\n"
"}"
msgstr "menuentry --hotkey=i 'Install' {\n    set background_color=black\n    linux    /install.amd/vmlinuz preseed/file=/cdrom/preseed.cfg locale=en_US.UTF-8 keymap=us language=us country=US vga=788 --- quiet \n    initrd   /install.amd/initrd.gz\n}"

msgid "And you have to edit <filename>/media/usbdisk/isolinux/isolinux.cfg</filename> (for BIOS boot) or one of the files it utilizes - e.g. <filename>/media/usbdisk/isolinux/txt.cfg</filename> - to add required boot parameters:"
msgstr "E si deve modificare <filename>/media/usbdisk/isolinux/isolinux.cfg</filename> (per l'avvio da BIOS) o uno dei file che utilizza - ad esempio <filename>/media/usbdisk/isolinux/txt.cfg</filename> - per aggiungere i parametri di avvio richiesti:"

msgid "isolinux/txt.cfg file and preseeding parameters"
msgstr "file isolinux/txt.cfg e parametri di preconfigurazione"

msgid ""
"label install\n"
"        menu label ^Install\n"
"        kernel [...]\n"
"        append preseed/file=/cdrom/preseed.cfg locale=en_US.UTF-8 keymap=us language=us country=US vga=788 initrd=/install.amd/initrd.gz --- quiet"
msgstr "label install\n        menu label ^Install\n        kernel [...]\n        append preseed/file=/cdrom/preseed.cfg locale=en_US.UTF-8 keymap=us language=us country=US vga=788 initrd=/install.amd/initrd.gz --- quiet"

msgid "If you have been using the <filename>hd-media</filename> installer image for a custom USB stick, edit <filename>/media/usbdisk/syslinux.cfg</filename> and add the required boot parameters as shown in the example below:"
msgstr "Se si è utilizzata l'immagine del programma di installazione <filename>hd-media</filename> per una chiavetta USB personalizzata, modificare <filename>/media/usbdisk/syslinux.cfg</filename> e aggiungere i parametri di avvio richiesti come mostrato nel seguente esempio:"

msgid "syslinux.cfg file and preseeding parameters"
msgstr "file syslinux.cfg e parametri di preimpostazione"

msgid ""
"default vmlinuz\n"
"append preseed/file=/hd-media/preseed.cfg locale=en_US.UTF-8 keymap=us language=us country=US vga=788 initrd=initrd.gz  --"
msgstr ""
"default vmlinuz\n"
"append preseed/file=/hd-media/preseed.cfg locale=en_US.UTF-8 keymap=us language=us country=US vga=788 initrd=initrd.gz  --"

msgid "Creating a CD-ROM Image"
msgstr "Creare un'immagine CD-ROM"

msgid "<primary><emphasis role=\"pkg\">debian-cd</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">debian-cd</emphasis></primary>"

msgid "<primary><command>genisoimage</command></primary>"
msgstr "<primary><command>genisoimage</command></primary>"

msgid "<primary><command>mkisofs</command></primary>"
msgstr "<primary><command>mkisofs</command></primary>"

msgid "<primary><command>xorriso</command></primary>"
msgstr "<primary><command>xorriso</command></primary>"

msgid "A USB key is a read-write media, so it was easy for us to add a file there and change a few parameters. In the CD-ROM case, the operation is more complex, since we need to regenerate a full ISO image. This task is handled by <emphasis role=\"pkg\">debian-cd</emphasis>, but this tool is rather awkward to use: it needs a local mirror, and it requires an understanding of all the options provided by <filename>/usr/share/debian-cd/CONF.sh</filename>; even then, <command>make</command> must be invoked several times. <filename>/usr/share/debian-cd/README</filename> is therefore a very recommended read."
msgstr "Una chiave USB è un supporto leggibile e scrivibile, quindi è stato facile aggiungervi un file e cambiare alcuni parametri. Nel caso di un CD-ROM, l'operazione è più complessa, dal momento che si deve rigenerare un'immagine ISO completa. Questo compito è gestito da <emphasis role=\"pkg\">debian-cd</emphasis>, ma questo strumento è piuttosto scomodo da usare: ha bisogno di un mirror locale e richiede una comprensione di tutte le opzioni fornite da <filename>/usr/share/debian-cd/CONF.sh</filename>; anche così, bisogna invocare <command>make</command> più volte. Pertanto si raccomanda vivamente di leggere <filename>/usr/share/debian-cd/README</filename>."

msgid "Having said that, <emphasis role=\"pkg\">debian-cd</emphasis> always operates in a similar way: an “image” directory with the exact contents of the CD-ROM is generated, then converted to an ISO file with a tool such as <command>genisoimage</command>, <command>mkisofs</command> or <command>xorriso</command>. The image directory is finalized after debian-cd's <command>make image-trees</command> step. At that point, we insert the preseed file into the appropriate directory (usually <filename>$TDIR/$CODENAME/CD1/</filename>, $TDIR and $CODENAME being parameters defined by the <filename>CONF.sh</filename> configuration file). The CD-ROM uses <command>isolinux</command> as its bootloader, and its configuration file must be adapted from what debian-cd generated, in order to insert the required boot parameters (the specific files are <filename>$TDIR/$CODENAME/CD1/isolinux/isolinux.cfg</filename> and <filename>$TDIR/$CODENAME/CD1/boot/grub/grub.cfg</filename> as shown above). Then the “normal” process can be resumed, and we can go on to generating the ISO image with <command>make image CD=1</command> (or <command>make images</command> if several CD-ROMs are generated)."
msgstr "Detto questo, <emphasis role=\"pkg\">debian-cd</emphasis> opera sempre in un modo simile: viene generata una directory \"immagine\" con l'esatto contenuto del CD-ROM, quindi convertita in un file ISO con uno strumento come <command>genisoimage</command>, <command>mkisofs</command> o <command>xorriso</command>. La directory dell'immagine viene completata dopo il passaggio <command>make image-trees</command> di debian-cd. A quel punto, si inserisce il file di preconfigurazione nella directory appropriata (di solito <filename>$TDIR/$CODENAME/CD1/</filename>, dove $TDIR è uno dei parametri definiti dal file di configurazione <filename>CONF.sh</filename>). Il CD-ROM usa <command>isolinux</command> come bootloader ed il suo file di configurazione dev'essere adattato partendo da quello generato da debian-cd, per poter inserire i parametri di avvio richiesti (i file specifici sono <filename>$TDIR/$CODENAME/CD1/isolinux/isolinux.cfg</filename> e <filename>$TDIR/$CODENAME/CD1/boot/grub/grub.cfg</filename> come mostrato sopra). Quindi si può riprendere il \"normale\" processo generando l'immagine ISO con <command>make image CD=1</command> (o <command>make images</command> se si generano più CD-ROM)."

msgid "Simple-CDD: The All-In-One Solution"
msgstr "Simple-CDD: la soluzione completa"

msgid "<primary><emphasis role=\"pkg\">simple-cdd</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">simple-cdd</emphasis></primary>"

msgid "Simply using a preseed file is not enough to fulfill all the requirements that may appear for large deployments. Even though it is possible to execute a few scripts at the end of the normal installation process, the selection of the set of packages to install is still not quite flexible (basically, only “tasks” can be selected); more important, this only allows installing official Debian packages, and precludes locally-generated ones."
msgstr "Usare semplicemente un file di preimpostazione non basta per soddisfare tutti i requisiti che possono verificarsi per allestimenti su larga scala. Anche se è possibile eseguire alcuni script alla fine del normale processo di installazione, la selezione dell'insieme di pacchetti da installare non è ancora molto flessibile (fondamentalmente si possono scegliere solo «task»); cosa più importante, ciò permette di installare solo pacchetti Debian ufficiali e preclude quelli generati localmente."

msgid "On the other hand, debian-cd is able to integrate external packages, and debian-installer can be extended by inserting new steps in the installation process. By combining these capabilities, it should be possible to create a customized installer that fulfills our needs; it should even be able to configure some services after unpacking the required packages. Fortunately, this is not a mere hypothesis, since this is exactly what <emphasis role=\"pkg\">simple-cdd</emphasis> does."
msgstr "D'altro canto, debian-cd è in grado di integrare pacchetti esterni e debian-installer può essere esteso inserendo nuovi passi nel processo di installazione. Combinando queste capacità, dovrebbe essere possibile creare un installatore personalizzato che soddisfi ogni necessità e sia perfino in grado di configurare alcuni servizi dopo aver spacchettato i pacchetti richiesti. Per fortuna questa non è solo un'ipotesi, dal momento che è proprio ciò che fa <emphasis role=\"pkg\">simple-cdd</emphasis>."

msgid "The purpose of this tool is to allow anyone to easily create a distribution derived from Debian, by selecting a subset of the available packages, preconfiguring them with Debconf, adding specific software, and executing custom scripts at the end of the installation process. This matches the “universal operating system” philosophy, since anyone can adapt it to their own needs."
msgstr "Lo scopo di questo strumento è di consentire a chiunque di creare facilmente una distribuzione derivata da Debian, scegliendo un sottoinsieme dei pacchetti disponibili, preconfigurandoli con Debconf, aggiungendo software specifico ed eseguendo script personalizzati alla fine del processo di installazione. Ciò si accorda con la filosofia del «sistema operativo universale», visto che chiunque può adattarlo ai propri bisogni."

msgid "Creating Profiles"
msgstr "Creare profili"

msgid "Simple-CDD defines “profiles” that match the FAI “classes” concept, and a machine can have several profiles (determined at installation time). A profile is defined by a set of <filename>profiles/<replaceable>profile</replaceable>.*</filename> files:"
msgstr "Simple-CDD definisce «profili» che corrispondono al concetto di «classi» in FAI e una macchina può avere diversi profili (determinati al momento dell'installazione). Un profilo è definito da un insieme di file <filename>profiles/<replaceable>profilo</replaceable>.*</filename>:"

msgid "the <filename>.description</filename> file contains a one-line description for the profile;"
msgstr "il file <filename>.description</filename> contiene una descrizione di una riga del profilo;"

msgid "the <filename>.packages</filename> file lists packages that will automatically be installed if the profile is selected;"
msgstr "il file <filename>.packages</filename> elenca i pacchetti che saranno automaticamente installati se il profilo viene scelto;"

msgid "the <filename>.downloads</filename> file lists packages that will be stored onto the installation media, but not necessarily installed;"
msgstr "il file <filename>.downloads</filename> elenca i pacchetti che verranno memorizzati sul supporto di installazione, ma non necessariamente installati;"

msgid "the <filename>.preseed</filename> file contains preseeding information for Debconf questions (for the installer and/or for packages);"
msgstr "il file <filename>.preseed</filename> contiene informazioni di preimpostazione per le domande di Debconf (per l'installatore e/o per i pacchetti);"

msgid "the <filename>.postinst</filename> file contains a script that will be run at the end of the installation process;"
msgstr "il file <filename>.postinst</filename> contiene uno script che sarà eseguito al termine del processo di installazione;"

msgid "lastly, the <filename>.conf</filename> file allows changing some parameters based on the profiles to be included in an image."
msgstr "infine, il file <filename>.conf</filename> permette di cambiare alcuni parametri in base ai profili da includere in un'immagine."

msgid "The <literal>default</literal> profile has a particular role, since it is always selected; it contains the bare minimum required for Simple-CDD to work. The only thing that is usually customized in this profile is the <literal>simple-cdd/profiles</literal> preseed parameter: this allows avoiding the question, introduced by Simple-CDD, about what profiles to install."
msgstr "Il profilo <literal>default</literal> ha un ruolo particolare, dal momento che è sempre selezionato; contiene il minimo indispensabile richiesto perché Simple-CDD funzioni. L'unica cosa personalizzata di solito in questo profilo è il parametro di preimpostazione <literal>simple-cdd/profiles</literal>: questo permette di evitare la domanda, introdotta da Simple-CDD, su quali profili installare."

msgid "Note also that the commands will need to be invoked from the parent directory of the <filename>profiles</filename> directory."
msgstr "Notare inoltre che i comandi dovranno essere invocati dalla directory madre della directory <filename>profiles</filename>."

msgid "Configuring and Using <command>build-simple-cdd</command>"
msgstr "Configurare e usare <command>build-simple-cdd</command>"

msgid "<primary><command>build-simple-cdd</command></primary>"
msgstr "<primary><command>build-simple-cdd</command></primary>"

msgid "<emphasis>QUICK LOOK</emphasis> Detailed configuration file"
msgstr "<emphasis>SGUARDO VELOCE</emphasis> File di configurazione dettagliato"

msgid "An example of a Simple-CDD configuration file, with most possible parameters, is included in the package (<filename>/usr/share/doc/simple-cdd/examples/simple-cdd.conf.detailed</filename>). This can be used as a starting point when creating a custom configuration file. Unfortunately not everything is documented there, so some variables are only listed and explained in <filename>/usr/lib/python3/dist-packages/simple_cdd/variables.py</filename>."
msgstr "Un esempio di un file di configurazione di Simple-CDD, con la maggior parte dei parametri possibili, è incluso nel pacchetto (<filename>/usr/share/doc/simple-cdd/examples/simple-cdd.conf.detailed</filename>). Questo può essere usato come punto di partenza per creare un file di configurazione personalizzato. Sfortunatamente non tutto è qui documentato, alcune variabili sono elencate e spiegate solamente in <filename>/usr/lib/python3/dist-packages/simple_cdd/variables.py</filename>."

msgid "It is further important to familiarize yourself with the variables understood by <filename>/usr/share/debian-cd/CONF.sh</filename>."
msgstr "È inoltre importante familiarizzare con le variabili comprese da <filename>/usr/share/debian-cd/CONF.sh</filename>."

msgid "Simple-CDD requires many parameters to operate fully. They will most often be gathered in a configuration file, which <command>build-simple-cdd</command> can be pointed at with the <literal>--conf</literal> option, but they can also be specified via dedicated parameters given to <command>build-simple-cdd</command>. Here is an overview of how this command behaves, and how its parameters are used:"
msgstr "Simple-CDD richiede molti parametri per operare appieno. Questi verranno perlopiù riuniti in un file di configurazione, a cui si può far puntare <command>build-simple-cdd</command> con l'opzione <literal>--conf</literal>, ma possono anche essere specificati tramite parametri dedicati dati a <command>build-simple-cdd</command>. Ecco una panoramica di come si comporta questo comando e di come i suoi parametri vengono usati:"

msgid "the <literal>profiles</literal> parameter lists the profiles that will be included on the generated CD-ROM image;"
msgstr "il parametro <literal>profiles</literal> elenca i profili che saranno inclusi nell'immagine CD-ROM generata;"

msgid "based on the list of required packages, Simple-CDD downloads the appropriate files from the server mentioned in <literal>server</literal>, and gathers them into a partial mirror (which will later be given to debian-cd);"
msgstr "in base alla lista dei pacchetti richiesti, Simple-CDD scarica i file appropriati dal server menzionato in <literal>server</literal> e li riunisce in un mirror parziale (che in seguito sarà dato a debian-cd);"

msgid "the custom packages mentioned in <literal>local_packages</literal> are also integrated into this local mirror;"
msgstr "i pacchetti personalizzati menzionati in <literal>local_packages</literal> sono anch'essi integrati in questo mirror locale;"

msgid "debian-cd is then executed (within a default location that can be configured with the <literal>debian_cd_dir</literal> variable), with the list of packages to integrate;"
msgstr "quindi viene eseguito debian cd (da una posizione predefinita che può essere configurata con la variabile <literal>debian_cd_dir</literal>), con la lista dei pacchetti da integrare;"

msgid "once debian-cd has prepared its directory, Simple-CDD applies some changes to this directory:"
msgstr "una volta che debian-cd ha preparato la sua directory, simple-CDD applica alcuni cambiamenti a questa directory:"

msgid "files containing the profiles are added in a <filename>simple-cdd</filename> subdirectory (that will end up on the CD-ROM);"
msgstr "i file contenenti i profili sono aggiunti in una sottodirectory <filename>simple-cdd</filename> (che sarà inclusa nel CD-ROM);"

msgid "other files listed in the <literal>all_extras</literal> parameter are also added;"
msgstr "altri file elencati nel parametro <literal>all_extras</literal> sono aggiunti anch'essi;"

msgid "the boot parameters are adjusted so as to enable the preseeding. Questions concerning language and country can be avoided if the required information is stored in the <literal>language</literal> and <literal>country</literal> variables."
msgstr "i parametri di avvio sono regolati per abilitare la preimpostazione. Si possono evitare le domande su lingua e nazione se l'informazione richiesta è memorizzata nelle variabili <literal>language</literal> e <literal>country</literal>."

msgid "debian-cd then generates the final ISO image."
msgstr "quindi debian-cd genera l'immagine ISO finale."

msgid "Generating an ISO Image"
msgstr "Generare un'immagine ISO"

msgid "Once we have written a configuration file and defined our profiles, the remaining step is to invoke <command>build-simple-cdd --conf simple-cdd.conf</command>. After a few minutes, we get the required image in <filename>images/debian-11-amd64-CD-1.iso</filename>."
msgstr "Una volta scritto un file di configurazione e definiti i profili, il passo rimanente è invocare <command>build-simple-cdd --conf simple-cdd.conf</command>. Dopo pochi minuti, si ottiene l'immagine richiesta in <filename>images/debian-11-amd64-CD-1.iso</filename>."

msgid "<primary>monitoring</primary>"
msgstr "<primary>monitoraggio</primary>"

msgid "<primary>Munin</primary>"
msgstr "<primary>Munin</primary>"

msgid "<primary>Nagios</primary>"
msgstr "<primary>Nagios</primary>"

msgid "Monitoring is a generic term, and the various involved activities have several goals: on the one hand, following usage of the resources provided by a machine allows anticipating saturation and the subsequent required upgrades; on the other hand, alerting the administrator as soon as a service is unavailable or not working properly means that the problems that do happen can be fixed sooner."
msgstr "Monitoraggio è un termine generico, e le diverse attività implicate hanno diversi scopi: da una parte, seguire l'uso delle risorse fornite da una macchina permette di prevedere la saturazione e i conseguenti aggiornamenti richiesti; dall'altra, avvisare l'amministratore appena un servizio è indisponibile o non funziona correttamente significa che il problema può essere risolto più celermente."

msgid "<emphasis>Munin</emphasis> covers the first area, by displaying graphical charts for historical values of a number of parameters (used RAM, occupied disk space, processor load, network traffic, Apache/MySQL load, and so on). <emphasis>Nagios</emphasis> covers the second area, by regularly checking that the services are working and available, and sending alerts through the appropriate channels (e-mails, text messages, and so on). Both have a modular design, which makes it easy to create new plug-ins to monitor specific parameters or services."
msgstr "<emphasis>Munin</emphasis> copre la prima area, visualizzando diagrammi grafici per i valori storici di un certo numero di parametri (RAM usata, spazio disco occupato, carico del processore, traffico di rete, carico di Apache/MySQL e così via). <emphasis>Nagios</emphasis> copre la seconda area, controllando regolarmente che i servizi siano funzionanti e disponibili e inviando avvisi tramite i canali appropriati (email, messaggi di testo e così via). Entrambi hanno una struttura modulare, il che rende facile creare nuovi plugin per monitorare specifici parametri o servizi."

msgid "<emphasis>ALTERNATIVE</emphasis> Zabbix, an integrated monitoring tool"
msgstr "<emphasis>ALTERNATIVA</emphasis> Zabbix, uno strumento integrato di monitoraggio"

msgid "<primary>Zabbix</primary>"
msgstr "<primary>Zabbix</primary>"

msgid "Although Munin and Nagios are in very common use, they are not the only players in the monitoring field, and each of them only handles half of the task (graphing on one side, alerting on the other). Zabbix, on the other hand, integrates both parts of monitoring; it also has a web interface for configuring the most common aspects. It has grown by leaps and bounds during the last few years, and can now be considered a viable contender. On the monitoring server, you would install <emphasis role=\"pkg\">zabbix-server-pgsql</emphasis> (or <emphasis role=\"pkg\">zabbix-server-mysql</emphasis>), possibly together with <emphasis role=\"pkg\">zabbix-frontend-php</emphasis> to have a web interface. On the hosts to monitor you would install <emphasis role=\"pkg\">zabbix-agent</emphasis> feeding data back to the server. <ulink type=\"block\" url=\"https://zabbix.com/\" />"
msgstr "Sebbene Munin e Nagios siano comunemente molto usati, non sono gli unici attori nel campo del monitoraggio, e ciascuno di loro gestisce solo metà del compito (creare grafici da un lato, avvisare dall'altro). Zabbix, d'altra parte, integra entrambe le parti del monitoraggio; ha anche un'interfaccia web per configurare gli aspetti più comuni. Negli ultimi anni ha fatto grandi passi in avanti e si può ora considerare un concorrente all'altezza. Sul server di monitoraggio, si dovrebbe installare<emphasis role=\"pkg\">zabbix-server-pgsql</emphasis> (o <emphasis role=\"pkg\">zabbix-server-mysql</emphasis>), eventualmente insieme ad <emphasis role=\"pkg\">zabbix-frontend-php</emphasis> per avere un'interfaccia web. Sugli host da controllare si dovrebbe installare <emphasis role=\"pkg\">zabbix-agent</emphasis> per inviare i dati al server. <ulink type=\"block\" url=\"https://zabbix.com/\" />"

msgid "<emphasis>ALTERNATIVE</emphasis> Icinga, a Nagios fork"
msgstr "<emphasis>ALTERNATIVE</emphasis> Icinga, un fork di Nagios"

msgid "<primary>Icinga</primary>"
msgstr "<primary>Icinga</primary>"

msgid "Spurred by divergences in opinions concerning the development model for Nagios (which is controlled by a company), a number of developers forked Nagios and use Icinga as their new name. Icinga is still compatible — so far — with Nagios configurations and plugins, but it also adds extra features. <ulink type=\"block\" url=\"https://icinga.com/\" />"
msgstr "Spinti da divergenze sulle opinioni riguardo il modello di sviluppo per Nagios (che è controllato da un'azienda), alcuni sviluppatori hanno fatto un fork di Nagios e usano Icinga come nuovo nome. Icinga, per ora, è ancora compatibile con le configurazioni e i plugin di Nagios, ma aggiunge anche ulteriori funzionalità. <ulink type=\"block\" url=\"https://www.icinga.orgcom/\" />"

msgid "Setting Up Munin"
msgstr "Impostazione di Munin"

msgid "<primary>Munin</primary><secondary>grapher</secondary>"
msgstr "<primary>Munin</primary><secondary>graficatore</secondary>"

msgid "The purpose of Munin is to monitor many machines; therefore, it quite naturally uses a client/server architecture. The central host — the grapher — collects data from all the monitored hosts, and generates historical graphs."
msgstr "Lo scopo di Munin è di monitorare molte macchine; è quindi assai naturale che usi un'architettura client/server. L'host centrale, il graficatore, raccoglie dati da tutti gli host monitorari e genera grafici storici."

msgid "Configuring Hosts To Monitor"
msgstr "Configurare gli host da monitorare"

msgid "<primary>server</primary><secondary>munin-node</secondary>"
msgstr "<primary>server</primary><secondary>munin-node</secondary>"

msgid "The first step is to install the <emphasis role=\"pkg\">munin-node</emphasis> package. The daemon installed by this package listens on port 4949 and sends back the data collected by all the active plugins. Each plugin is a simple program returning a description of the collected data as well as the latest measured value. Plugins are stored in <filename>/usr/share/munin/plugins/</filename>, but only those with a symbolic link in <filename>/etc/munin/plugins/</filename> are really used."
msgstr "Il primo passo è installare il pacchetto <emphasis role=\"pkg\">munin-node</emphasis>. Il demone installato da questo pacchetto ascolta sulla porta 4949 e rimanda i dati raccolti da tutti i plugin attivi. Ciascun plugin è un semplice programma che restituisce una descrizione dei dati raccolti insieme all'ultimo valore misurato. I plugin sono memorizzati in <filename>/usr/share/munin/plugins/</filename>, ma solo quelli con un collegamento simbolico in <filename>/etc/munin/plugins/</filename> vengono effettivamente usati."

msgid "<primary><filename>/etc</filename></primary><secondary><filename>/etc/munin/</filename></secondary><see>Munin</see>"
msgstr "<primary><filename>/etc</filename></primary><secondary><filename>/etc/munin/</filename></secondary><see>Munin</see>"

msgid "<primary>Munin</primary><secondary><filename>/etc/munin/plugins/</filename></secondary>"
msgstr "<primary>Munin</primary><secondary><filename>/etc/munin/plugins/</filename></secondary>"

msgid "<primary>Munin</primary><secondary>plugins</secondary>"
msgstr "<primary>Munin</primary><secondary>plugin</secondary>"

msgid "When the package is installed, a set of active plugins is determined based on the available software and the current configuration of the host. However, this auto-configuration depends on a feature that each plugin must provide, and it is usually a good idea to review and tweak the results by hand. Browsing the Plugin Gallery can be interesting even though not all plugins have comprehensive documentation. <ulink type=\"block\" url=\"https://gallery.munin-monitoring.org\" />"
msgstr "Quando il pacchetto è installato, un insieme di plugin attivi è determinato in base al software disponibile e alla configurazione attuale dell'host. Tuttavia, questa autoconfigurazione dipende da una funzionalità che ogni plugin deve fornire ed è normalmente una buona idea rivedere e adattare i risultati manualmente. Sfogliare la galleria dei plugin può essere interessante anche se non tutti i plugin sono correlati con documentazione completa. <ulink type=\"block\" url=\"https://gallery.munin-monitoring.org\" />"

msgid "However, all plugins are scripts and most are rather simple and well-commented. Browsing <filename>/etc/munin/plugins/</filename> is therefore a good way of getting an idea of what each plugin is about and determining which should be removed. Similarly, enabling an interesting plugin found in <filename>/usr/share/munin/plugins/</filename> is a simple matter of setting up a symbolic link with <command>ln -sf /usr/share/munin/plugins/<replaceable>plugin</replaceable> /etc/munin/plugins/</command>. Note that when a plugin name ends with an underscore “_”, the plugin requires a parameter. This parameter must be stored in the name of the symbolic link; for instance, the “if_” plugin must be enabled with a <filename>if_eth0</filename> symbolic link, and it will monitor network traffic on the eth0 interface."
msgstr "Tuttavia, tutti i plugin sono script e la maggior parte di essi sono piuttosto semplici e ben commentati. Sfogliare <filename>/etc/munin/plugins/</filename> è perciò un buon modo per avere un'idea di cosa si occupa ciascun plugin e determinare quali debbano essere rimossi. Allo stesso modo, abilitare un plugin interessante trovato in <filename>/usr/share/munin/plugins/</filename> si riduce a impostare un collegamento simbolico con <command>ln -sf /usr/share/munin/plugins/<replaceable>plugin</replaceable> /etc/munin/plugins/</command>. Notare che quando il nome di un plugin termina con una sottolineatura \"_\", il plugin richiede un parametro che deve essere memorizzato nel nome del collegamento simbolico; per esempio, il plugin \"if_\" deve essere abilitato con un collegamento simbolico <filename>if_eth0</filename>, e monitorerà il traffico di rete sull'interfaccia eth0."

msgid "<primary>Munin</primary><secondary><filename>/etc/munin/munin-node.conf</filename></secondary>"
msgstr "<primary>Munin</primary><secondary><filename>/etc/munin/munin-node.conf</filename></secondary>"

msgid "<primary>service</primary><secondary><filename>munin-node.service</filename></secondary>"
msgstr "<primary>servizio</primary><secondary><filename>munin-node.service</filename></secondary>"

msgid "Once all plugins are correctly set up, the daemon configuration must be updated to describe access control for the collected data. This involves <literal>allow</literal> directives in the <filename>/etc/munin/munin-node.conf</filename> file. The default configuration is <literal>allow ^127\\.0\\.0\\.1$</literal>, and only allows access to the local host. An administrator will usually add a similar line containing the IP address of the grapher host, then restart the daemon with <command>systemctl restart munin-node</command>."
msgstr "Una volta impostati correttamente tutti i plugin, si deve aggiornare la configurazione del demone per descrivere il controllo dell'accesso ai dati raccolti. Questo richiede delle direttive <literal>allow</literal> nel file <filename>/etc/munin/munin-node.conf</filename>. La configurazione predefinita è <literal>allow ^127\\.0\\.0\\.1$</literal> e permette accesso solo all'host locale. Un amministratore di solito aggiungerà una riga simile contenente l'indirizzo IP dell'host graficatore, quindi riavvierà il demone con <command>systemctl restart munin-node</command>."

msgid "<emphasis>GOING FURTHER</emphasis> Creating local plugins"
msgstr "<emphasis>APPROFONDIMENTO</emphasis> Creare plugin locali"

msgid "<primary>Munin</primary><secondary><command>munin-run</command></secondary>"
msgstr "<primary>Munin</primary><secondary><command>munin-run</command></secondary>"

msgid "Munin does include detailed documentation on how plugins should behave, and how to develop new plugins. <ulink type=\"block\" url=\"https://guide.munin-monitoring.org/en/latest/plugin/writing.html\" />"
msgstr "Munin include una dettagliata documentazione su come i plugin dovrebbero comportarsi, e come sviluppare nuovi plugin. <ulink type=\"block\" url=\"https://guide.munin-monitoring.org/en/latest/plugin/writing.html\" />"

msgid "A plugin is best tested when run in the same conditions as it would be when triggered by munin-node; this can be simulated by running <command>munin-run <replaceable>plugin</replaceable></command> as root. A potential second parameter given to this command (such as <literal>config</literal>) is passed to the plugin as a parameter."
msgstr "Un plugin si collauda meglio quando viene avviato nelle stesse condizioni in cui si troverebbe se fosse attivato da munin-node; ciò si può simulare lanciando <command>munin-run <replaceable>plugin</replaceable></command> da root. Un potenziale secondo parametro (come <literal>config</literal>) viene passato al plugin come parametro."

msgid "When a plugin is invoked with the <literal>config</literal> parameter, it must describe itself by returning a set of fields:"
msgstr "Quando un plugin è invocato con il parametro <literal>config</literal>, deve descriversi restituendo un insieme di campi:"

msgid ""
"<computeroutput># </computeroutput><userinput>munin-run load config\n"
"</userinput><computeroutput>graph_title Load average\n"
"graph_args --base 1000 -l 0\n"
"graph_vlabel load\n"
"graph_scale no\n"
"graph_category system\n"
"load.label load\n"
"graph_info The load average of the machine describes how many processes are in the run-queue (scheduled to run \"immediately\").\n"
"load.info 5 minute load average\n"
"</computeroutput>"
msgstr "<computeroutput># </computeroutput><userinput>munin-run load config\n</userinput><computeroutput>graph_title Load average\ngraph_args --base 1000 -l 0\ngraph_vlabel load\ngraph_scale no\ngraph_category system\nload.label load\ngraph_info The load average of the machine describes how many processes are in the run-queue (scheduled to run \"immediately\").\nload.info 5 minute load average\n</computeroutput>"

msgid "The various available fields are described by the “Plugin reference” available as part of the “Munin guide”. <ulink type=\"block\" url=\"https://munin.readthedocs.org/en/latest/reference/plugin.html\" />"
msgstr "I diversi campi disponibili sono descritti dal “Plugin reference” disponibile come parte della “guida Munin”. <ulink type=\"block\" url=\"https://munin.readthedocs.org/en/latest/reference/plugin.html\" />"

msgid "When invoked without a parameter, the plugin simply returns the last measured values; for instance, executing <command>sudo munin-run load</command> could return <literal>load.value 0.12</literal>."
msgstr "Quando viene invocato senza un parametro, il plugin restituisce semplicemente gli ultimi valori misurati; per esempio, l'esecuzione di <command>sudo munin-run load</command> può restituire <literal>load.value 0.12</literal>."

msgid "Finally, when a plugin is invoked with the <literal>autoconf</literal> parameter, it should return “yes” (and a 0 exit status) or “no” (with a 1 exit status) according to whether the plugin should be enabled on this host."
msgstr "Infine, quando un plugin viene invocato con il parametro <literal>autoconf</literal>, deve restituire «yes» (e uno stato di uscita 0) o «no» (con uno stato di uscita 1) a seconda se il plugin deve essere abilitato o meno su questo host."

msgid "Configuring the Grapher"
msgstr "Configurare il graficatore"

msgid "<primary>Munin</primary><secondary><command>munin-cron</command></secondary>"
msgstr "<primary>Munin</primary><secondary><command>munin-cron</command></secondary>"

msgid "<primary>Munin</primary><secondary><filename>/etc/munin/munin.conf</filename></secondary>"
msgstr "<primary>Munin</primary><secondary><filename>/etc/munin/munin.conf</filename></secondary>"

msgid "The “grapher” is simply the computer that aggregates the data and generates the corresponding graphs. The required software is in the <emphasis role=\"pkg\">munin</emphasis> package. The standard configuration runs <command>munin-cron</command> (once every 5 minutes), which gathers data from all the hosts listed in <filename>/etc/munin/munin.conf</filename> (only the local host is listed by default), saves the historical data in RRD files (<emphasis>Round Robin Database</emphasis>, a file format designed to store data varying in time) stored under <filename>/var/lib/munin/</filename> and generates an HTML page with the graphs in <filename>/var/cache/munin/www/</filename>."
msgstr "Il «graficatore» è semplicemente il computer che aggrega i dati e genera i grafici corrispondenti. Il software richiesto si trova nel pacchetto <emphasis role=\"pkg\">munin</emphasis>. La configurazione standard esegue <command>munin-cron</command> (una volta ogni 5 minuti), che raccoglie i dati da tutti gli host elencati in <filename>/etc/munin/munin.conf</filename> (solo l'host locale è elencato in modo predefinito), salva i dati storici in file RRD (<emphasis>Round Robin Database</emphasis>, un formato di file progettato per memorizzare dati variabili nel tempo) memorizzati sotto <filename>/var/lib/munin/</filename> e genera una pagina HTML con i grafici in <filename>/var/cache/munin/www/</filename>."

msgid "All monitored machines must therefore be listed in the <filename>/etc/munin/munin.conf</filename> configuration file. Each machine is listed as a full section with a name matching the machine and at least an <literal>address</literal> entry giving the corresponding IP address."
msgstr "Tutte le macchine monitorate devono quindi essere elencate nel file di configurazione <filename>/etc/munin/munin.conf</filename>. Ciascuna macchina è elencata come una sezione completa con un nome che corrisponde alla macchina e almeno una voce <literal>address</literal> che dà il corrispondente indirizzo IP."

msgid ""
"[ftp.falcot.com]\n"
"    address 192.168.0.12\n"
"    use_node_name yes"
msgstr ""
"[ftp.falcot.com]\n"
"    address 192.168.0.12\n"
"    use_node_name yes"

msgid "Sections can be more complex, and describe extra graphs that could be created by combining data coming from several machines. The samples provided in the configuration file are good starting points for customization."
msgstr "Le sezioni possono essere più complesse e descrivere ulteriori grafici che possono essere creati combinando dati provenienti da diverse macchine. Gli esempi forniti nel file di configurazione sono dei buoni punti di partenza per la personalizzazione."

msgid "The last step is to publish the generated pages; this involves configuring a web server so that the contents of <filename>/var/cache/munin/www/</filename> are made available on a website. Access to this website will often be restricted, using either an authentication mechanism or IP-based access control. See <xref linkend=\"sect.http-web-server\" /> for the relevant details."
msgstr "L'ultimo passo è pubblicare le pagine generate; questo richiede di configurare un server web in modo che i contenuti di <filename>/var/cache/munin/www/</filename> siano resi disponibili su un sito web. L'accesso a questo sito web sarà spesso ristretto, usando un meccanismo di autenticazione o un controllo di accesso basato sull'IP. Vedere <xref linkend=\"sect.http-web-server\" /> per i dettagli relativi."

msgid "Setting Up Nagios"
msgstr "Impostazione di Nagios"

msgid "<primary><emphasis role=\"pkg\">nagios4</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">nagios4</emphasis></primary>"

msgid "<primary><emphasis role=\"pkg\">monitoring-plugins</emphasis></primary>"
msgstr "<primary><emphasis role=\"pkg\">monitoring-plugins</emphasis></primary>"

msgid "Unlike Munin, Nagios does not necessarily require installing anything on the monitored hosts; most of the time, Nagios is used to check the availability of network services. For instance, Nagios can connect to a web server and check that a given web page can be obtained within a given time."
msgstr "Contrariamente a Munin, Nagios non richiede necessariamente di installare alcunché sugli host monitorati; la maggior parte delle volte, Nagios viene usato per controllare la disponibilità dei servizi di rete. Per esempio, Nagios può connettersi a un sito web e controllare che una data pagina web possa essere ottenuta entro un certo tempo."

msgid "Installing"
msgstr "Installazione"

msgid "The first step in setting up Nagios is to install the <emphasis role=\"pkg\">nagios4</emphasis> and <emphasis role=\"pkg\">monitoring-plugins</emphasis> packages. Installing the packages configures the web interface and the Apache server. The <literal>authz_groupfile</literal> and <literal>auth_digest</literal> Apache modules must be enabled, for that execute:"
msgstr "Il primo passo per configurare Nagios è di installare i pacchetti <emphasis role=\"pkg\">nagios4</emphasis> e <emphasis role=\"pkg\">monitoring-plugins</emphasis>. Installando i pacchetti, configurando l'interfaccia web e il server Apache. I moduli Apache <literal>authz_groupfile</literal> e <literal>auth_digest</literal> devono essere abilitati, per fare questo eseguire:"

msgid ""
"<computeroutput># </computeroutput><userinput>a2enmod authz_groupfile\n"
"</userinput><computeroutput>Considering dependency authz_core for authz_groupfile:\n"
"Module authz_core already enabled\n"
"Module authz_core already enabled\n"
"Enabling module authz_groupfile.\n"
"To activate the new configuration, you need to run:\n"
"  systemctl restart apache2\n"
"# </computeroutput><userinput>a2enmod auth_digest\n"
"</userinput><computeroutput>Considering dependency authn_core for auth_digest:\n"
"Module authn_core already enabled\n"
"Enabling module auth_digest.\n"
"To activate the new configuration, you need to run:\n"
"  systemctl restart apache2\n"
"# </computeroutput><userinput>systemctl restart apache2\n"
"</userinput>"
msgstr "<computeroutput># </computeroutput><userinput>a2enmod authz_groupfile\n</userinput><computeroutput>Considering dependency authz_core for authz_groupfile:\nModule authz_core already enabled\nModule authz_core already enabled\nEnabling module authz_groupfile.\nTo activate the new configuration, you need to run:\n  systemctl restart apache2\n# </computeroutput><userinput>a2enmod auth_digest\n</userinput><computeroutput>Considering dependency authn_core for auth_digest:\nModule authn_core already enabled\nEnabling module auth_digest.\nTo activate the new configuration, you need to run:\n  systemctl restart apache2\n# </computeroutput><userinput>systemctl restart apache2\n</userinput>"

msgid "<primary><filename>/etc</filename></primary><secondary><filename>/etc/nagios4/</filename></secondary><see>Nagios</see>"
msgstr "<primary><filename>/etc</filename></primary><secondary><filename>/etc/nagios4/</filename></secondary><see>Nagios</see>"

msgid "<primary>Nagios</primary><secondary><filename>/etc/nagios4/hdigest.users</filename></secondary>"
msgstr "<primary>Nagios</primary><secondary><filename>/etc/nagios4/hdigest.users</filename></secondary>"

msgid "Adding other users is a simple matter of inserting them in the <filename>/etc/nagios4/hdigest.users</filename> file."
msgstr "Per aggiungere nuovi utenti è sufficiente inserirli nel file <filename>/etc/nagios4/hdigest.users</filename>."

msgid "Pointing a browser at <literal>http://<replaceable>server</replaceable>/nagios4/</literal> displays the web interface; in particular, note that Nagios already monitors some parameters of the machine where it runs. However, some interactive features such as adding comments to a host do not work. These features are disabled in the default configuration for Nagios, which is very restrictive for security reasons."
msgstr "Visitando <literal>http://<replaceable>server</replaceable>/nagios4/</literal> con un navigatore viene visualizzata l'interfaccia web; in particolare, notare che Nagios monitora già alcuni parametri della macchina su cui gira. Tuttavia, alcune funzionalità interattive come l'aggiunta di commenti per un host non funzionano. Queste funzionalità sono disabilitate nella configurazione predefinita di Nagios, che è molto restrittiva, per ragioni di sicurezza."

msgid "<primary>Nagios</primary><secondary><filename>/etc/nagios4/nagios.cfg</filename></secondary>"
msgstr "<primary>Nagios</primary><secondary><filename>/etc/nagios4/nagios.cfg</filename></secondary>"

msgid "Enabling some features involves editing <filename>/etc/nagios4/nagios.cfg</filename>. We also need to set up write permissions for the directory used by Nagios, with commands such as the following:"
msgstr "L'abilitazione di alcune funzionalità richiede la modifica di <filename>/etc/nagios3/nagios.cfg</filename>. Bisogna anche impostare i permessi in scrittura per la directory usata da Nagios, con comandi come i seguenti:"

msgid ""
"<computeroutput># </computeroutput><userinput>systemctl stop nagios4\n"
"</userinput><computeroutput># </computeroutput><userinput>dpkg-statoverride --update --add nagios www-data 2710 /var/lib/nagios4/rw\n"
"</userinput><computeroutput># </computeroutput><userinput>dpkg-statoverride --update --add nagios nagios 751 /var/lib/nagios4\n"
"</userinput><computeroutput># </computeroutput><userinput>systemctl start nagios4\n"
"</userinput>"
msgstr "<computeroutput># </computeroutput><userinput>systemctl stop nagios4\n</userinput><computeroutput># </computeroutput><userinput>dpkg-statoverride --update --add nagios www-data 2710 /var/lib/nagios4/rw\n</userinput><computeroutput># </computeroutput><userinput>dpkg-statoverride --update --add nagios nagios 751 /var/lib/nagios4\n</userinput><computeroutput># </computeroutput><userinput>systemctl start nagios4\n</userinput>"

msgid "Configuring"
msgstr "Configurazione"

msgid "The Nagios web interface is rather nice, but it does not allow configuration, nor can it be used to add monitored hosts and services. The whole configuration is managed via files referenced in the central configuration file, <filename>/etc/nagios4/nagios.cfg</filename>."
msgstr "L'interfaccia web di Nagios è abbastanza carina, ma non permette la configurazione né può essere usata per aggiungere host e servizi da monitorare. L'intera configurazione viene gestita tramite file indicati nel file di configurazione centrale, <filename>/etc/nagios4/nagios.cfg</filename>."

msgid "These files should not be dived into without some understanding of the Nagios concepts. The configuration lists objects of the following types:"
msgstr "Questi file non dovrebbero essere studiati senza una qualche comprensione dei concetti alla base di Nagios. La configurazione elenca oggetti dei seguenti tipi:"

msgid "a <emphasis>host</emphasis> is a machine to be monitored;"
msgstr "un <emphasis>host</emphasis> è una macchina da monitorare;"

msgid "a <emphasis>hostgroup</emphasis> is a set of hosts that should be grouped together for display, or to factor some common configuration elements;"
msgstr "un <emphasis>hostgroup</emphasis> è un insieme di host che dovrebbero essere raggruppati insieme per la visualizzazione o per sfruttare elementi comuni di configurazione;"

msgid "a <emphasis>service</emphasis> is a testable element related to a host or a host group. It will most often be a check for a network service, but it can also involve checking that some parameters are within an acceptable range (for instance, free disk space or processor load);"
msgstr "un <emphasis>service</emphasis> è un elemento controllabile relativo a un host o a un gruppo di host. Molto spesso sarà un controllo di un servizio di rete, ma può anche richiedere di controllare che certi parametri siano all'interno di un intervallo accettabile (per esempio, lo spazio libero sul disco o il carico del processore);"

msgid "a <emphasis>servicegroup</emphasis> is a set of services that should be grouped together for display;"
msgstr "un <emphasis>servicegroup</emphasis> è un insieme di servizi che dovrebbero essere raggruppati insieme per la visualizzazione;"

msgid "a <emphasis>contact</emphasis> is a person who can receive alerts;"
msgstr "un <emphasis>contact</emphasis> è una persona che può ricevere avvisi;"

msgid "a <emphasis>contactgroup</emphasis> is a set of such contacts;"
msgstr "un <emphasis>contactgroup</emphasis> è un insieme di tali contatti;"

msgid "a <emphasis>timeperiod</emphasis> is a range of time during which some services have to be checked;"
msgstr "un <emphasis>timeperiod</emphasis> è un intervallo di tempo durante il quale alcuni servizi devono essere controllati;"

msgid "a <emphasis>command</emphasis> is the command line invoked to check a given service."
msgstr "un <emphasis>command</emphasis> è la riga di comando invocata per controllare un dato servizio."

msgid "According to its type, each object has a number of properties that can be customized. A full list would be too long to include, but the most important properties are the relations between the objects."
msgstr "Secondo il suo tipo, ciascun oggetto ha un certo numero di proprietà che possono essere personalizzate. Una lista completa sarebbe troppo lunga da includere, ma le proprietà più importanti sono le relazioni fra gli oggetti."

msgid "A <emphasis>service</emphasis> uses a <emphasis>command</emphasis> to check the state of a feature on a <emphasis>host</emphasis> (or a <emphasis>hostgroup</emphasis>) within a <emphasis>timeperiod</emphasis>. In case of a problem, Nagios sends an alert to all members of the <emphasis>contactgroup</emphasis> linked to the service. Each member is sent the alert according to the channel described in the matching <emphasis>contact</emphasis> object."
msgstr "Un <emphasis>service</emphasis> usa un <emphasis>command</emphasis> per controllare lo stato di una funzionalità su un <emphasis>host</emphasis> (o un <emphasis>hostgroup</emphasis>) entro un <emphasis>timeperiod</emphasis>. In caso di problema, Nagios manda un avviso a tutti i membri del <emphasis>contactgroup</emphasis> collegato al servizio. Ciascun membro riceve l'avviso a seconda del canale descritto nell'oggetto <emphasis>contact</emphasis> corrispondente."

msgid "An inheritance system allows easy sharing of a set of properties across many objects without duplicating information. Moreover, the initial configuration includes a number of standard objects; in many cases, defining new hosts, services and contacts is a simple matter of deriving from the provided generic objects. The files in <filename>/etc/nagios4/conf.d/</filename> are a good source of information on how they work."
msgstr "Un sistema di ereditarietà permette di condividere facilmente un insieme di proprietà fra molti oggetti senza duplicare informazioni. Inoltre, la configurazione iniziale include un certo numero di oggetti standard; in molti casi, definire nuovi host, servizi e contatti è una semplice derivazione dagli oggetti generici forniti. I file in <filename>/etc/nagios4/conf.d/</filename> sono una buona fonte di informazione sul loro funzionamento."

msgid "<primary>Nagios</primary><secondary><filename>/etc/nagios4/conf.d/</filename></secondary>"
msgstr "<primary>Nagios</primary><secondary><filename>/etc/nagios4/conf.d/</filename></secondary>"

msgid "The Falcot Corp administrators use the following configuration:"
msgstr "Gli amministratori della Falcot Corp usano la seguente configurazione:"

msgid "<filename>/etc/nagios4/conf.d/falcot.cfg</filename> file"
msgstr "file <filename>/etc/nagios4/conf.d/falcot.cfg</filename>"

msgid ""
"define contact{\n"
"    name                            generic-contact\n"
"    service_notification_period     24x7\n"
"    host_notification_period        24x7\n"
"    service_notification_options    w,u,c,r\n"
"    host_notification_options       d,u,r\n"
"    service_notification_commands   notify-service-by-email\n"
"    host_notification_commands      notify-host-by-email\n"
"    register                        0 ; Template only\n"
"}\n"
"define contact{\n"
"    use             generic-contact\n"
"    contact_name    rhertzog\n"
"    alias           Raphael Hertzog\n"
"    email           hertzog@debian.org\n"
"}\n"
"define contact{\n"
"    use             generic-contact\n"
"    contact_name    rmas\n"
"    alias           Roland Mas\n"
"    email           lolando@debian.org\n"
"}\n"
"\n"
"define contactgroup{\n"
"    contactgroup_name     falcot-admins\n"
"    alias                 Falcot Administrators\n"
"    members               rhertzog,rmas\n"
"}\n"
"\n"
"define host{\n"
"    use                   generic-host ; Name of host template to use\n"
"    host_name             www-host\n"
"    alias                 www.falcot.com\n"
"    address               192.168.0.5\n"
"    contact_groups        falcot-admins\n"
"    hostgroups            debian-servers,ssh-servers\n"
"}\n"
"define host{\n"
"    use                   generic-host ; Name of host template to use\n"
"    host_name             ftp-host\n"
"    alias                 ftp.falcot.com\n"
"    address               192.168.0.12\n"
"    contact_groups        falcot-admins\n"
"    hostgroups            debian-servers,ssh-servers\n"
"}\n"
"\n"
"# 'check_ftp' command with custom parameters\n"
"define command{\n"
"    command_name          check_ftp2\n"
"    command_line          /usr/lib/nagios/plugins/check_ftp -H $HOSTADDRESS$ -w 20 -c 30 -t 35\n"
"}\n"
"\n"
"# Generic Falcot service\n"
"define service{\n"
"    name                  falcot-service\n"
"    use                   generic-service\n"
"    contact_groups        falcot-admins\n"
"    register              0\n"
"}\n"
"\n"
"# Services to check on www-host\n"
"define service{\n"
"    use                   falcot-service\n"
"    host_name             www-host\n"
"    service_description   HTTP\n"
"    check_command         check_http\n"
"}\n"
"define service{\n"
"    use                   falcot-service\n"
"    host_name             www-host\n"
"    service_description   HTTPS\n"
"    check_command         check_https\n"
"}\n"
"define service{\n"
"    use                   falcot-service\n"
"    host_name             www-host\n"
"    service_description   SMTP\n"
"    check_command         check_smtp\n"
"}\n"
"\n"
"# Services to check on ftp-host\n"
"define service{\n"
"    use                   falcot-service\n"
"    host_name             ftp-host\n"
"    service_description   FTP\n"
"    check_command         check_ftp2\n"
"}"
msgstr "define contact{\n    name                            generic-contact\n    service_notification_period     24x7\n    host_notification_period        24x7\n    service_notification_options    w,u,c,r\n    host_notification_options       d,u,r\n    service_notification_commands   notify-service-by-email\n    host_notification_commands      notify-host-by-email\n    register                        0 ; Template only\n}\ndefine contact{\n    use             generic-contact\n    contact_name    rhertzog\n    alias           Raphael Hertzog\n    email           hertzog@debian.org\n}\ndefine contact{\n    use             generic-contact\n    contact_name    rmas\n    alias           Roland Mas\n    email           lolando@debian.org\n}\n\ndefine contactgroup{\n    contactgroup_name     falcot-admins\n    alias                 Falcot Administrators\n    members               rhertzog,rmas\n}\n\ndefine host{\n    use                   generic-host ; Name of host template to use\n    host_name             www-host\n    alias                 www.falcot.com\n    address               192.168.0.5\n    contact_groups        falcot-admins\n    hostgroups            debian-servers,ssh-servers\n}\ndefine host{\n    use                   generic-host ; Name of host template to use\n    host_name             ftp-host\n    alias                 ftp.falcot.com\n    address               192.168.0.12\n    contact_groups        falcot-admins\n    hostgroups            debian-servers,ssh-servers\n}\n\n# 'check_ftp' command with custom parameters\ndefine command{\n    command_name          check_ftp2\n    command_line          /usr/lib/nagios/plugins/check_ftp -H $HOSTADDRESS$ -w 20 -c 30 -t 35\n}\n\n# Generic Falcot service\ndefine service{\n    name                  falcot-service\n    use                   generic-service\n    contact_groups        falcot-admins\n    register              0\n}\n\n# Services to check on www-host\ndefine service{\n    use                   falcot-service\n    host_name             www-host\n    service_description   HTTP\n    check_command         check_http\n}\ndefine service{\n    use                   falcot-service\n    host_name             www-host\n    service_description   HTTPS\n    check_command         check_https\n}\ndefine service{\n    use                   falcot-service\n    host_name             www-host\n    service_description   SMTP\n    check_command         check_smtp\n}\n\n# Services to check on ftp-host\ndefine service{\n    use                   falcot-service\n    host_name             ftp-host\n    service_description   FTP\n    check_command         check_ftp2\n}"

msgid "This configuration file describes two monitored hosts. The first one is the web server, and the checks are made on the HTTP (80) and secure-HTTP (443) ports. Nagios also checks that an SMTP server runs on port 25. The second host is the FTP server, and the check includes making sure that a reply comes within 20 seconds. Beyond this delay, a <emphasis>warning</emphasis> is emitted; beyond 30 seconds, the alert is deemed critical. The Nagios web interface also shows that the SSH service is monitored: this comes from the hosts belonging to the <literal>ssh-servers</literal> hostgroup. The matching standard service is defined in <filename>/etc/nagios4/conf.d/services_nagios2.cfg</filename>."
msgstr "Questo file di configurazione descrive due host monitorati. Il primo è il server web, ed i controlli sono fatti sulle porte HTTP (80) e HTTP sicuro (443). Nagios controlla inoltre che sulla porta 25 giri un server SMTP. Il secondo host è un server FTP, e il controllo include di accertarsi che arrivi una risposta entro 20 secondi. Oltre questo ritardo, viene emesso un <emphasis>warning</emphasis>; oltre i 30 secondi, l'avviso è considerato critico. L'interfaccia web di Nagios mostra anche che il servizio SSH è monitorato: ciò è determinato dagli host che appartengono all'hostgroup <literal>ssh-servers</literal>. Il servizio standard corrispondente è definito in <filename>/etc/nagios4/conf.d/services_nagios2.cfg</filename>."

msgid "Note the use of inheritance: an object is made to inherit from another object with the “use <replaceable>parent-name</replaceable>”. The parent object must be identifiable, which requires giving it a “name <replaceable>identifier</replaceable>” property. If the parent object is not meant to be a real object, but only to serve as a parent, giving it a “register 0” property tells Nagios not to consider it, and therefore to ignore the lack of some parameters that would otherwise be required."
msgstr "Notare l'uso dell'ereditarietà: un oggetto eredita da un altro oggetto tramite «use <replaceable>nome-genitore</replaceable>». L'oggetto genitore deve essere identificabile, il che richiede di dargli una proprietà «name <replaceable>identificatore</replaceable>». Se l'oggetto genitore non deve essere un oggetto reale, ma deve solo servire da genitore, una proprietà «register 0» dice a Nagios di non considerarlo e quindi di ignorare l'assenza di alcuni parametri che altrimenti sarebbero richiesti."

msgid "<emphasis>DOCUMENTATION</emphasis> List of object properties"
msgstr "<emphasis>DOCUMENTAZIONE</emphasis> Elenco delle proprietà degli oggetti"

msgid "A more in-depth understanding of the various ways in which Nagios can be configured can be obtained from the documentation hosted on <ulink url=\"https://assets.nagios.com/downloads/nagioscore/docs/nagioscore/4/en/\" />. It includes a list of all object types, with all the properties they can have. It also explains how to create new plugins."
msgstr "Si può avere una comprensione più approfondita dei vari modi in cui si può configurare Nagios leggendo la documentazione ospitata su <ulink url=\"https://assets.nagios.com/downloads/nagioscore/docs/nagioscore/4/en/\" />. Include una lista di tutti i tipi di oggetto, con tutte le proprietà che possono avere. Inoltre spiega come creare nuovi plugin."

msgid "<emphasis>GOING FURTHER</emphasis> Remote tests with NRPE"
msgstr "<emphasis>APPROFONDIMENTO</emphasis> Test a distanza con NRPE"

msgid "<primary>Nagios Remote Plugin Executor</primary><see>NRPE</see>"
msgstr "<primary>Nagios Remote Plugin Executor</primary><see>NRPE</see>"

msgid "<primary>NRPE</primary>"
msgstr "<primary>NRPE</primary>"

msgid "<primary>Nagios</primary><secondary><emphasis role=\"pkg\">nagios-nrpe-plugin</emphasis></secondary>"
msgstr "<primary>Nagios</primary><secondary><emphasis role=\"pkg\">nagios-nrpe-plugin</emphasis></secondary>"

msgid "<primary>Nagios</primary><secondary><emphasis role=\"pkg\">nagios-nrpe-server</emphasis></secondary>"
msgstr "<primary>Nagios</primary><secondary><emphasis role=\"pkg\">nagios-nrpe-server</emphasis></secondary>"

msgid "<primary>Nagios</primary><secondary><filename>/etc/nagios/nrpe.cfg</filename></secondary>"
msgstr "<primary>Nagios</primary><secondary><filename>/etc/nagios/nrpe.cfg</filename></secondary>"

msgid "<primary><command>check_nrpe</command></primary>"
msgstr "<primary><command>check_nrpe</command></primary>"

msgid "Many Nagios plugins allow checking some parameters local to a host; if many machines need these checks while a central installation gathers them, the NRPE (<emphasis>Nagios Remote Plugin Executor</emphasis>) plugin needs to be deployed. The <emphasis role=\"pkg\">nagios-nrpe-plugin</emphasis> package needs to be installed on the Nagios server, and <emphasis role=\"pkg\">nagios-nrpe-server</emphasis> on the hosts where local tests need to run. The latter gets its configuration from <filename>/etc/nagios/nrpe.cfg</filename>. This file should list the tests that can be started remotely, and the IP addresses of the machines allowed to trigger them. On the Nagios side, enabling these remote tests is a simple matter of adding matching services using the new <command>check_nrpe</command> command."
msgstr "Molti plugin di Nagios permettono di controllare alcuni parametri locali di un host; se molte macchine hanno bisogno di questi controlli con un'installazione centrale che li riunisca, bisogna installare il plugin NRPE (<emphasis>Nagios Remote Plugin Executor</emphasis>). Bisogna installare il pacchetto <emphasis role=\"pkg\">nagios-nrpe-plugin</emphasis> sul server Nagios e <emphasis role=\"pkg\">nagios-nrpe-server</emphasis> sugli host in cui bisogna eseguire i controlli locali. Quest'ultimo riceve la sua configurazione da <filename>/etc/nagios/nrpe.cfg</filename>. Questo file deve elencare i controlli che possono essere avviati da remoto e gli indirizzi IP delle macchine autorizzate ad attivarli. Dalla parte di Nagios, abilitare questi controlli remoti si riduce semplicemente ad aggiungere i servizi corrispondenti usando il nuovo comando <command>check_nrpe</command>."

#~ msgid "<primary><emphasis>VMWare</emphasis></primary>"
#~ msgstr "<primary><emphasis>VMWare</emphasis></primary>"

#~ msgid "<primary><emphasis>Bochs</emphasis></primary>"
#~ msgstr "<primary><emphasis>Bochs</emphasis></primary>"

#~ msgid "<primary><emphasis>QEMU</emphasis></primary>"
#~ msgstr "<primary><emphasis>QEMU</emphasis></primary>"

#~ msgid "<primary><emphasis>KVM</emphasis></primary>"
#~ msgstr "<primary><emphasis>KVM</emphasis></primary>"

#~ msgid "<primary><emphasis>LXC</emphasis></primary>"
#~ msgstr "<primary><emphasis>LXC</emphasis></primary>"

#~ msgid "<emphasis>DOCUMENTATION</emphasis> <command>xl</command> options"
#~ msgstr "<emphasis>DOCUMENTAZIONE</emphasis> opzioni di <command>xl</command>"

#~ msgid ""
#~ "#auto eth0\n"
#~ "#iface eth0 inet dhcp\n"
#~ "\n"
#~ "auto br0\n"
#~ "iface br0 inet dhcp\n"
#~ "  bridge-ports eth0"
#~ msgstr ""
#~ "#auto eth0\n"
#~ "#iface eth0 inet dhcp\n"
#~ "\n"
#~ "auto br0\n"
#~ "iface br0 inet dhcp\n"
#~ "  bridge-ports eth0"

#~ msgid "The newly-created filesystem now contains a minimal Debian system, and by default the container has no network interface (besides the loopback one). Since this is not really wanted, we will edit the container's configuration file (<filename>/var/lib/lxc/testlxc/config</filename>) and add a few <literal>lxc.network.*</literal> entries:"
#~ msgstr "Il filesystem appena creato contiene ora un sistema Debian minimale, e per impostazione predefinita il contenitore non ha alcuna interfaccia di rete (oltre il loopback uno). Poiché questo non è veramente voluto, è possibile modificare il file di configurazione del contenitore (<filename>/var/lib/lxc/testlxc/config</filename>) e aggiungere un paio di voci <literal>lxc.network.*</literal>:"

#~ msgid "copy the preseed file to <filename>/media/usbdisk/preseed.cfg</filename>"
#~ msgstr "copiare il file di preimpostazione in <filename>/media/usbdisk/preseed.cfg</filename>"

#~ msgid "<primary>simple-cdd</primary>"
#~ msgstr "<primary>simple-cdd</primary>"

#~ msgid ""
#~ "<computeroutput># </computeroutput><userinput>mv /etc/grub.d/20_linux_xen /etc/grub.d/09_linux_xen\n"
#~ "</userinput><computeroutput># </computeroutput><userinput>update-grub\n"
#~ "</userinput>"
#~ msgstr ""
#~ "<computeroutput># </computeroutput><userinput>mv /etc/grub.d/20_linux_xen /etc/grub.d/09_linux_xen\n"
#~ "</userinput><computeroutput># </computeroutput><userinput>update-grub\n"
#~ "</userinput>"

#~ msgid "The first step in setting up Nagios is to install the <emphasis role=\"pkg\">nagios3</emphasis>, <emphasis role=\"pkg\">nagios-plugins</emphasis> and <emphasis role=\"pkg\">nagios3-doc</emphasis> packages. Installing the packages configures the web interface and creates a first <literal>nagiosadmin</literal> user (for which it asks for a password). Adding other users is a simple matter of inserting them in the <filename>/etc/nagios3/htpasswd.users</filename> file with Apache's <command>htpasswd</command> command. If no Debconf question was displayed during installation, <command>dpkg-reconfigure nagios3-cgi</command> can be used to define the <literal>nagiosadmin</literal> password."
#~ msgstr "Il primo passo per impostare Nagios è installare i pacchetti <emphasis role=\"pkg\">nagios3</emphasis>, <emphasis role=\"pkg\">nagios-plugins</emphasis> e <emphasis role=\"pkg\">nagios3-doc</emphasis>. L'installazione dei pacchetti configura l'interfaccia web e crea un primo utente <literal>nagiosadmin</literal> (per il quale chiede una password). Aggiungere altri utenti si riduce semplicemente a inserirli nel file <filename>/etc/nagios3/htpasswd.users</filename> con il comando <command>htpasswd</command> di Apache. Se nessuna domanda di Debconf è stata mostrata durante l'installazione, si può usare <command>dpkg-reconfigure nagios3-cgi</command> per definire la password di <literal>nagiosadmin</literal>."

#, fuzzy
#~ msgid "the <emphasis role=\"distribution\">Jessie</emphasis> standard kernel does not allow limiting the amount of memory available to a container; the feature exists, and is built in the kernel, but it is disabled by default because it has a (slight) cost on overall system performance; however, enabling it is a simple matter of setting the <command>cgroup_enable=memory</command> kernel command-line option at boot time;"
#~ msgstr "il kernel standard di <emphasis role=\"distribution\">Squeeze</emphasis> non consente di limitare la quantità di memoria disponibile per un contenitore; questa funzionalità esiste e può essere abilitata ricompilando il kernel con l'opzione <foreignphrase>Memory Resource Controller</foreignphrase>, ma è ancora considerata in qualche modo sperimentale e ha un (lieve) costo sulle prestazioni generali del sistema, per cui è disabilitata in modalità predefinita;"

#~ msgid "Xen is currently only available for the i386 and amd64 architectures. Moreover, it uses processor instructions that haven't always been provided in all i386-class computers. Note that most of the Pentium-class (or better) processors made after 2001 will work, so this restriction won't apply to very many situations."
#~ msgstr "Attualmente Xen è disponibile solo per le architetture i386 e amd64. Inoltre, usa istruzioni del processore che non sono state sempre disponibili in tutte le macchine di classe i386. Notare che la maggior parte dei processori di classe Pentium (o superiori) realizzati dopo il 2001 funzioneranno, quindi questa restrizione non si applicherà a molte situazioni."

#~ msgid ""
#~ "# /etc/fstab: static file system information.\n"
#~ "[...]\n"
#~ "cgroup            /sys/fs/cgroup           cgroup    defaults        0       0"
#~ msgstr ""
#~ "# /etc/fstab: static file system information.\n"
#~ "[...]\n"
#~ "cgroup            /sys/fs/cgroup           cgroup    defaults        0       0\n"

#~ msgid "<filename>/sys/fs/cgroup</filename> will then be mounted automatically at boot time; if no immediate reboot is planned, the filesystem should be manually mounted with <command>mount /sys/fs/cgroup</command>."
#~ msgstr "<filename>/sys/fs/cgroup</filename> sarà allora montato automaticamente all'avvio; se non si prevede un riavvio immediato, il file system deve essere montato manualmente con <command>mount /sys/fs/cgroup</command>."

#, fuzzy
#~ msgid "The <emphasis role=\"pkg\">lxc</emphasis> package contains an initialization script that can automatically start one or several containers when the host boots; its configuration file, <filename>/etc/default/lxc</filename>, is relatively straightforward; note that the container configuration files need to be stored in <filename>/etc/lxc/auto/</filename>; many users may prefer symbolic links, such as can be created with <command>ln -s /var/lib/lxc/testlxc/config /etc/lxc/auto/testlxc.config</command>."
#~ msgstr "Il pacchetto <emphasis role=\"pkg\">lxc</emphasis> contiene uno script di inizializzazione che può automaticamente avviare uno o più contenitori all'avvio dell'host; il suo file di configurazione, <filename>/etc/default/lxc</filename>, è relativamente semplice; notare che i file di configurazione dei contenitori devono essere memorizzati in <filename>/etc/lxc/</filename>; molti utenti potrebbero preferire dei collegamenti simbolici, come quelli che si possono creare con <command>ln -s /var/lib/lxc/testlxc/config /etc/lxc/testlxc.config</command>."

#~ msgid "<primary><command>Bochs</command></primary>"
#~ msgstr "<primary><command>Bochs</command></primary>"

#~ msgid "<primary><command>QEMU</command></primary>"
#~ msgstr "<primary><command>QEMU</command></primary>"

#~ msgid "<primary><command>VirtualBox</command></primary>"
#~ msgstr "<primary><command>VirtualBox</command></primary>"

#~ msgid "A kernel with the appropriate patches allowing it to work on that hypervisor. In the 2.6.32 case relevant to <emphasis role=\"distribution\">Squeeze</emphasis>, the available hardware will dictate the choice among the various available <emphasis role=\"pkg\">xen-linux-system-2.6.32-5-xen-*</emphasis> packages."
#~ msgstr "Un kernel con le patch appropriate che permettano di farlo funzionare con quell'ipervisore. Nel caso del kernel 2.6.32 incluso in <emphasis role=\"distribution\">Squeeze</emphasis>, l'hardware disponibile determinerà la scelta fra i diversi pacchetti <emphasis role=\"pkg\">xen-linux-system-2.6.32-5-xen-*</emphasis>."

#~ msgid "If the Xen image is not meant to run Debian but another system, another potentially interesting option is <literal>--rpmstrap</literal>, to invoke <command>rpmstrap</command> in order to initialize a new RPM-based system (such as Fedora, CentOS or Mandriva). Other methods include <literal>--copy</literal>, to copy an image from an existing system, and <literal>--tar</literal>, to extract the system image from an archive."
#~ msgstr "Se l'immagine Xen non deve far girare Debian ma un altro sistema, un'altra opzione potenzialmente interessante è <literal>--rpmstrap</literal>, che esegue <command>rpmstrap</command> per inizializzare un nuovo sistema basato su RPM (come Fedora, CentOS o Mandriva). Altri metodi includono <literal>--copy</literal>, per copiare un'immagine da un sistema esistente e <literal>--tar</literal> per estrarre l'immagine del sistema da un archivio."

#~ msgid "Note also that the <command>lxc-debian</command> command as shipped in <emphasis role=\"distribution\">Squeeze</emphasis> unfortunately creates a <emphasis role=\"distribution\">Lenny</emphasis> system, and not a <emphasis role=\"distribution\">Squeeze</emphasis> system as one could expect. This problem can be worked around by simply installing a newer version of the package (starting from 0.7.3-1)."
#~ msgstr "Notare inoltre che il comando <command>lxc-debian</command> fornito da <emphasis role=\"distribution\">Squeeze</emphasis> purtroppo crea un sistema <emphasis role=\"distribution\">Lenny</emphasis> e non un sistema <emphasis role=\"distribution\">Squeeze</emphasis> come ci si aspetterebbe. Questo problema si può aggirare semplicemente installando una versione più recente del pacchetto (a partire dalla 0.7.3-1)."

#~ msgid "The newly-created filesystem now contains a minimal Debian system, adapted to the aforementioned “simple” network configuration. In the “rich” configuration, the <filename>/var/lib/lxc/testlxc/rootfs/etc/network/interfaces</filename> file will need some modifications; more important, though, is that the network interface that the container sees must not be the host's physical interface. This can be configured by adding a few <literal>lxc.network.*</literal> entries to the container's configuration file, <filename>/var/lib/lxc/testlxc/config</filename>:"
#~ msgstr "Il file system appena creato contiene ora un sistema Debian minimale, adattato alla suddetta configurazione di rete «semplice». Nella configurazione «ricca», il file <filename>/var/lib/lxc/testlxc/rootfs/etc/network/interfaces</filename> avrà bisogno di alcune modifiche; la cosa più importante, comunque, è che l'interfaccia di rete che il contenitore vede non deve essere l'interfaccia fisica dell'host. Ciò si può configurare aggiungendo alcune voci <literal>lxc.network.*</literal> al file di configurazione del contenitore, <filename>/var/lib/lxc/testlxc/config</filename>:"

#~ msgid "<computeroutput># </computeroutput><userinput>virsh pool-create-as srv-kvm dir --target /srv/kvm</userinput>\n"
#~ msgstr "<computeroutput># </computeroutput><userinput>virsh pool-create-as srv-kvm dir --target /srv/kvm</userinput>\n"
